{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imodelsx.util\n",
    "from copy import deepcopy\n",
    "import re\n",
    "# import sasc.notebook_helper\n",
    "import sasc.viz\n",
    "import scipy.special\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import sasc.analyze_helper\n",
    "import joblib\n",
    "# import viz\n",
    "from sasc.config import RESULTS_DIR\n",
    "\n",
    "setting = 'default'\n",
    "MAIN_DIR = join(RESULTS_DIR, 'stories', setting)\n",
    "EXPT_DIRS = sorted([join(MAIN_DIR, dir_name) for dir_name in os.listdir(MAIN_DIR)])\n",
    "EXPT_DIRS = [x for x in EXPT_DIRS if 'uts03' in x.lower() or 'uts01' in x.lower()]\n",
    "EXPT_DIR = EXPT_DIRS[0]\n",
    "rows = joblib.load(join(EXPT_DIR, f'rows.pkl'))\n",
    "expls = rows.expl.values\n",
    "try:\n",
    "    prompts_paragraphs = joblib.load(\n",
    "        join(EXPT_DIR, \"prompts_paragraphs.pkl\"),\n",
    "    )\n",
    "    prompts = prompts_paragraphs[\"prompts\"]\n",
    "    paragraphs = prompts_paragraphs[\"paragraphs\"]\n",
    "except:\n",
    "    prompts = open(join(EXPT_DIR, \"prompts.txt\"), 'r').read().split('\\n\\n')\n",
    "    paragraphs = open(join(EXPT_DIR, \"story.txt\"), 'r').read().split('\\n\\n')\n",
    "    assert len(prompts) == len(paragraphs), f\"{len(prompts)} != {len(paragraphs)}\"\n",
    "# voxel_nums = rows.module_num.values\n",
    "# subjects = rows.subject.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module** <> Story Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for EXPT_DIR in EXPT_DIRS:\n",
    "    scores_data = joblib.load(\n",
    "        join(EXPT_DIR, f\"scores_mod_ngram_length={0}.pkl\"))\n",
    "    s = scores_data[\"scores_mean\"].T\n",
    "    # z-score each column\n",
    "    s = (s - s.mean(axis=0)) / s.std(axis=0)\n",
    "\n",
    "    # s = scipy.special.softmax(s, axis=0)\n",
    "    # s = (s - s.min()) / (s.max() - s.min())\n",
    "    # rows = joblib.load(join(EXPT_DIR, f'rows1_rep.pkl'))\n",
    "    rows = joblib.load(join(EXPT_DIR, f\"rows.pkl\"))\n",
    "    expls = rows.expl.values\n",
    "\n",
    "    if setting == 'default':\n",
    "        expls_order = sasc.analyze_helper.sort_expls_semantically(expls)\n",
    "        s = s[expls_order][:, expls_order]  # [:, expls_order]\n",
    "        expls = expls[expls_order]\n",
    "\n",
    "    sasc.viz.heatmap(s, expls, ylab=\"Story\", xlab=\"Module\")\n",
    "\n",
    "    # calculate mean of diagonal - mean of off-diagonal for s\n",
    "    diag_diff = (\n",
    "        np.mean(np.diag(s))\n",
    "        - (\n",
    "            np.mean(s[np.triu_indices_from(s, k=1)])\n",
    "            + np.mean(s[np.tril_indices_from(s, k=-1)])\n",
    "        )\n",
    "        / 2\n",
    "    ).round(5)\n",
    "    if not setting == 'default':\n",
    "        plt.title(os.path.basename(EXPT_DIR) + ' diag_diff=' + str(diag_diff))\n",
    "    res[os.path.basename(EXPT_DIR)] = diag_diff\n",
    "\n",
    "    # plt.savefig(join(EXPT_DIR, f\"story_module_match.png\"), dpi=300)\n",
    "    plt.savefig(join(EXPT_DIR, f\"story_module_match.pdf\"), bbox_inches=\"tight\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "# sasc.viz.save_figs_to_single_pdf('../results/expl_story_match.pdf')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data** <> Story Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EXPT_DIR in EXPT_DIRS:\n",
    "    d = joblib.load(join(EXPT_DIR, \"scores_data.pkl\"))\n",
    "    s = d[\"scores_mean\"].T\n",
    "    # normalize each column\n",
    "    s = (s - s.mean(axis=0)) / \\\n",
    "        s.std(axis=0)\n",
    "\n",
    "    rows = joblib.load(join(EXPT_DIR, f\"rows.pkl\"))\n",
    "    expls = rows.expl.values\n",
    "    if setting == 'default':\n",
    "        expls_order = sasc.analyze_helper.sort_expls_semantically(expls)\n",
    "        s = s[expls_order][:, expls_order]  # [:, expls_order]\n",
    "        expls = expls[expls_order]\n",
    "    # {\"scores_mean\": scores_mean, \"scores_all\": scores_all},\n",
    "    sasc.viz.heatmap(s, expls, ylab=\"Story\", diverging=True,\n",
    "                     xlab=\"Explanation\", clab='Ngram matching score (normalized)')\n",
    "\n",
    "    plt.savefig(join(EXPT_DIR, f\"story_data_match.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module** <> Story Heatmap when varying ngram lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EXPT_DIR in EXPT_DIRS:\n",
    "    # keys: scores_mod, scores_max_mod, all_scores, all_ngrams\n",
    "    # ngram_lengths = [10, 50, 100, 384]\n",
    "    ngram_lengths = [0]\n",
    "    for ngram_length in ngram_lengths:\n",
    "        scores_mod_dict = joblib.load(\n",
    "            join(EXPT_DIR, f'scores_mod_ngram_length={ngram_length}.pkl'))\n",
    "        # rows = joblib.load(join(EXPT_DIR, f'rows1_rep.pkl'))\n",
    "        rows = joblib.load(join(EXPT_DIR, f'rows.pkl'))\n",
    "        expls = rows.expl.values\n",
    "\n",
    "        s = scores_mod_dict['scores_mean'].T\n",
    "        # normalize each column\n",
    "        s = (s - s.mean(axis=0)) / s.std(axis=0)\n",
    "\n",
    "        if setting == 'default':\n",
    "            expls_order = sasc.analyze_helper.sort_expls_semantically(expls)\n",
    "            s = s[expls_order][:, expls_order]  # [:, expls_order]\n",
    "            expls = expls[expls_order]\n",
    "\n",
    "        sasc.viz.heatmap(s, expls, ylab='Story',\n",
    "                         xlab='Module (fit to fMRI voxel)', clab='Mean module response')\n",
    "\n",
    "        n = s.shape[0]\n",
    "        # plt.plot([0, n], [0, n], '--', color='gray', alpha=0.1)\n",
    "        # plt.title(f'Model window: {ngram_length} words', fontsize='small')\n",
    "        # plt.savefig(\n",
    "        # join(EXPT_DIR, f'mod_story_match_ngram_length={ngram_length}.png'), dpi=300)\n",
    "        plt.savefig(join(\n",
    "            EXPT_DIR, f'mod_story_match_ngram_length={ngram_length}.pdf'), bbox_inches='tight')\n",
    "        # plt.show()\n",
    "# sasc.viz.save_figs_to_single_pdf('../results/expl_mod_match.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best voxels table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_diffs = defaultdict(list)\n",
    "for EXPT_DIR in EXPT_DIRS:\n",
    "    ngram_length = 0\n",
    "    scores_mod_dict = joblib.load(\n",
    "        join(EXPT_DIR, f'scores_mod_ngram_length={ngram_length}.pkl'))\n",
    "    rows = joblib.load(join(EXPT_DIR, f'rows.pkl'))\n",
    "    expls = rows.expl.values\n",
    "\n",
    "    s = scores_mod_dict['scores_mean'].T\n",
    "    s = scipy.special.softmax(s, axis=0)\n",
    "\n",
    "    BLOCK_SIZE = 4\n",
    "    for i in range(0, rows.shape[0]):\n",
    "        row = rows.iloc[i]\n",
    "        s_row = s[i]\n",
    "        block_idxs = range((i // BLOCK_SIZE) * BLOCK_SIZE,\n",
    "                           (i // BLOCK_SIZE + 1) * BLOCK_SIZE)\n",
    "        diff = s_row[i] - np.mean([s_row[j]\n",
    "                                  for j in range(s_row.shape[0]) if j not in block_idxs])\n",
    "        vox_diffs[(row.module_num, row.expl)].append(diff)\n",
    "vox_diffs = {k: np.mean(v) for k, v in vox_diffs.items()}\n",
    "vox_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all rows\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(pd.DataFrame(vox_diffs.items()).sort_values(\n",
    "        1, ascending=False).head(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
