{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import imodelsx.util\n",
    "import sasc.viz\n",
    "import pickle as pkl\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import norm\n",
    "from sasc.config import CACHE_DIR, RESULTS_DIR, cache_ngrams_dir, regions_idxs_dir\n",
    "import sasc.modules.fmri_module\n",
    "ngrams_list = joblib.load(join(cache_ngrams_dir, 'fmri_UTS02_ngrams.pkl'))\n",
    "rois_dict = joblib.load(join(regions_idxs_dir, 'rois_S02.jbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get predictions from embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # embs = joblib.load(join(cache_ngrams_dir, 'fmri_embs.pkl'))\n",
    "# embs = joblib.load(join(cache_ngrams_dir, 'fmri_embs_llama.pkl'))\n",
    "# mod = sasc.modules.fmri_module.fMRIModule(\n",
    "#     subject=\"UTS02\",\n",
    "#     # checkpoint=\"facebook/opt-30b\",\n",
    "#     checkpoint=\"huggyllama/llama-30b\",\n",
    "#     init_model=False,\n",
    "#     restrict_weights=False,\n",
    "# )\n",
    "# voxel_preds = mod(embs=embs, return_all=True)\n",
    "# outputs_dict = {\n",
    "#     k: voxel_preds[:, np.array(rois_dict[k])].mean(axis=1)\n",
    "#     for k in rois_dict\n",
    "# }\n",
    "# joblib.dump(outputs_dict, join(\n",
    "#     # cache_ngrams_dir, 'rois_ngram_outputs_dict.pkl'))\n",
    "#     cache_ngrams_dir, 'rois_ngram_outputs_dict_llama.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dict = joblib.load(\n",
    "    join(cache_ngrams_dir, 'rois_ngram_outputs_dict.pkl'))\n",
    "df_opt = pd.DataFrame(outputs_dict, index=ngrams_list)\n",
    "outputs_dict = joblib.load(\n",
    "    join(cache_ngrams_dir, 'rois_ngram_outputs_dict_llama.pkl'))\n",
    "df_llama = pd.DataFrame(outputs_dict, index=ngrams_list)\n",
    "df = df_opt + df_llama\n",
    "ROIS_LOC = ['RSC', 'OPA', 'PPA']\n",
    "for k in ROIS_LOC:\n",
    "    df_opt[k + '_only'] = df_opt[k] - \\\n",
    "        df_opt[[c for c in ROIS_LOC if c != k]].mean(axis=1)\n",
    "    df_llama[k + '_only'] = df_llama[k] - \\\n",
    "        df_llama[[c for c in ROIS_LOC if c != k]].mean(axis=1)\n",
    "    df[k + '_only'] = df[k] - \\\n",
    "        df[[c for c in ROIS_LOC if c != k]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_scores = {\n",
    "    k: np.corrcoef(df_opt[k], df_llama[k])[0, 1]\n",
    "    for k in df.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascending = False  # should be false to get driving ngrams\n",
    "top_ngrams_dict = {}\n",
    "for k in df.columns:\n",
    "    top_ngrams_dict[k] = df.sort_values(\n",
    "        k, ascending=ascending).index[:100].tolist()\n",
    "    # if k in ROIS_LOC:\n",
    "\n",
    "    # top_ngrams_dict[k + '_only'] = df.sort_values(\n",
    "    # k + '_only', ascending=ascending).index[:100].tolist()\n",
    "top_ngrams_df = pd.DataFrame(top_ngrams_dict)\n",
    "top_ngrams_df.to_csv('top_ngrams_by_roi.csv')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    rois = ['RSC', 'OPA', 'PPA', 'IPS', 'pSTS', 'sPMv',\n",
    "            'EBA', 'OFA'] + ['RSC_only', 'OPA_only', 'PPA_only']\n",
    "    display(top_ngrams_df[rois])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = imodelsx.llm.get_llm('gpt-4-turbo-0125-spot')\n",
    "\n",
    "explanations = {}\n",
    "for k in top_ngrams_df.columns:\n",
    "\n",
    "    s = '- ' + '\\n- '.join(top_ngrams_df[k].iloc[:60])\n",
    "    prompt = f'''Here is a list of phrases:\n",
    "    {s}\n",
    "\n",
    "    What is a common theme among these phrases? Return only a concise phrase.'''\n",
    "\n",
    "    explanations[k] = gpt4(prompt)\n",
    "json.dump(explanations, open('explanations_by_roi.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export selected rois to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"RSC\": ['drove from vermont', 'moved to vermont', 'drove to washington', 'here in manhattan', 'here in boston', 'was in boston', 'off into vancouver', 'moved to chicago', 'back in manhattan', 'went to boston', 'was in mexico', 'back in boston', 'sitting in indianapolis', 'arrived in indianapolis', 'came to florida', 'i left vermont', 'here in houston', 'was in pennsylvania', 'moved to brooklyn', 'arrived in tokyo', 'moved to london', 'off in vancouver', 'traveled to marrakesh', 'moved to washington', \"'m in michigan\", 'back in brooklyn', 'i drove to', 'back in israel', 'in lower manhattan', 'nineties new york', 'hometown in texas', 'went to manchester', 'it was summer', 'upstate new york', 'suburbs of baltimore', 'camp in upstate', 'we were downtown', 'in nashville tennessee', 'drove out to', 'in downriver michigan', 'normal suburban pittsburgh', 'in upstate', 'were in paris', 'living in chicago', 'i drove out', 'i drove home', 'an hour south', 'go to vancouver', 'back in alabama', 'i flew home'], \n",
      "\"OPA\": ['onto the railing', 'against the railing', 'on the railing', 'towards the river', 'onto the sidewalk', 'towards the doors', 'towards the door', 'outside the windows', 'towards the ceiling', 'long hallway toward', 'to the horizon', 'see the horizon', 'and high rafters', 'towards the street', 'over the gulf', 'to my left', 'path that jutted', 'beautiful moonlit mountains', 'on the ceiling', 'on the windowsill', 'down this embankment', 'we ran upstairs', 'up those stairs', 'above the gulf', 'facing the beach', 'over the embankment', 'up the stairs', 'we go downstairs', 'lights peeking over', 'door behind me', 'railing looking out', 'hundred feet up', 'the door behind', 'down the embankment', 'to the hallway', 'was led upstairs', 'across the street', 'are steps leading', 'cross the bering', 'this long hallway', 'twenty feet above', 'on that distant', 'to the north', 'dangling over the', 'sun was setting', 'to my right', 'the double doors', 'reached the interstate', 'on opposite coasts', 'seats behind'], \n",
      "\"PPA\": ['on the railing', 'on a dock', 'on the windowsill', 'mile of cornfields', 'the windowsill', 'onto the railing', 'outside the windows', 'across the parking', 'contain strip malls', 'against the railing', 'on a rainy', 'the rolling hills', 'beautiful moonlit mountains', 'of the sidewalk', 'giant stone cliffs', 'a strip mall', \"'s sprawling green\", 'lobster pots piled', 'on the sidewalk', 'nondescript office buildings', 'of manicured lawns', 'lakes and manicured', 'the dark driveway', 'there were shelves', 'i remember walking', 'of cornfields', 'and shimmering skyscrapers', 'a private beach', 'there were slats', \"there 's trees\", 'the leafy garden', 'and high rafters', 'at those cliffs', 'our bedroom window', 'of torn fishnet', 'i remember sitting', 'our modest backyard', 'path that jutted', 'down the sidewalk', 'in my dorm', 'at a woodsy', 'or wheat fields', 'a restaurant stoop', 'green expanse of', 'at a picnic', 'the front steps', 'in the parking', 'in the hallway', 'against the windows', 'from my dorm'], \n",
      "\"IPS\": ['there were slats', 'onto the railing', 'on the railing', 'against the railing', 'the back hatch', 'four connected squares', 'in long rows', 'path that jutted', 'the double doors', 'on the sides', 'a long narrow', 'that forms horizontal', 'long rows of', 'sixty foot wide', 'spanding the length', 'put a board', 'sky with clouds', 'between buttered slices', 'were slats', 'nineteen sixty', 'the mirror behind', 'the tops of', 'mile thick ice', 'all four corners', 'see the horizon', 'a long white', 'of nineteen sixty', 'that flips up', 'two mile thick', 'this long hallway', 'sides of the', 'steps leading down', 'soft green expanse', 'along the top', 'two mighty cliffs', 'row of seats', 'the snow bank', 'green expanse of', 'in nineteen sixty', 'this swirling vortex', 'nineteen seventy', 'giant stone cliffs', 'the expanse of', 'the atlantic ocean', 'across the width', 'was nineteen eighty', 'rope hanging from', 'place the blocks', 'of nineteen eighty', 'shirt the suspenders'], \n",
      "\"pSTS\": ['said excuse me', 'says excuse me', 'i stopped midstride', 'room went silent', 'scissors someone shouted', 'i provoked gasps', 'somebody then yelled', 'she started laughing', 'hook excuse me', 'i whirled around', 'asked i laughed', 'exhalation someone shouted', 'retorted rather loudly', 'stopped midstride', 'turned and said', 'hurry she exclaimed', 'behind me grabbed', 'i started yelling', 'script excuse me', 'looks over at', 'say excuse me', 'i started laughing', 'interrupted the conversation', 'breath he yelled', 'moment she gasped', 'said guess what', 'she yelled i', 'eyes and snickered', 'then in unison', 'she hung up', 'crowd fell silent', 'heard another thud', 'started to laugh', 'pull over lemme', 'loudly said oh', 'she said excuse', 'um she laughed', 'suddenly he stops', 'say just kidding', 'adam kept whispering', 'she laughs then', 'i said mmm', 'until she yelled', 'me her number', 'behind me feigning', 'stop she said', 'provoked gasps', 'she shouted back', 'and snickered', 'googling her googling'], \n",
      "\"sPMv\": ['one mississippi two', 'said excuse me', 'mississippi two mississippi', 'said guess what', 'am turning forty', 'april nineteen forty', 'says excuse me', 'say one mississippi', 'two mississippi three', 'october nineteen forty', 'was sixteen seventeen', 'and three mississippi', 'five only twenty', 'april of nineteen', 'mississippi three mississippi', 'hook excuse me', 'july nineteen forty', 'up three down', 'march twentieth nineteen', 'more time passed', 'fifteen meters fifty', \"'re turning ninety\", 'june of nineteen', 'googling her googling', 'then girlfriend now', 'is turning ninety', 'hour thirty forty', 'to nineteen forty', 'on nineteen ninety', 'fifty pounds fifty', 'was july thirtieth', \"'s nineteen forty\", 'twenty minutes thirty', 'say excuse me', 'thirty suddenly four', 'nineteenth nineteen forty', 'forward three years', 'until nineteen sixty', 'say these words', 'september nineteenth nineteen', 'googling myself googling', 'forty years pass', 'weeks became months', 'nineteen ninety', 'nine nineteen seventy', 'of nineteen forty', 'twentieth nineteen ninety', 'year two thousand', 'i was thirty', 'turning ninety'], \n",
      "\"EBA\": ['wraps his arms', 'lifted her dress', 'arms flailing', 'arms around her', 'arms tighten around', 'flying arms flailing', 'hands gripped the', 'grabbed her legs', 'the chopsticks flipped', 'his hands folded', 'grab his arms', 'a hand poking', 'my feet kicking', 'his hand curling', 'grabbed their hands', 'grabbed her hand', 'blanket and yanked', 'her hands gripped', 'his arm around', 'covered my hand', 'i reach under', 'he reached under', 'navigated pushy elbows', 'elbows on knees', 'shoes propped', \"'s hair flying\", 'over his shoulder', 'danced throwing blankets', 'over my shoulder', 'patted his behind', 'skirt up so', 'her head brushed', 'elbows on', 'wrapped my napkin', 'extended my hands', 'his arms around', 'fists clutching', 'hands into my', 'my boots clanking', 'the sheets shuffled', 'hand on his', 'my arms around', 'chopsticks flipped', 'places his hip', 'yanked the comforter', 'over their shoulders', 'her skirt to', 'rough hands groped', 'my arms out', 'my napkin around'], \n",
      "\"OFA\": ['of my childhood', 'newfound self esteem', 'so my shrink', 'hurtful first dates', 'recall many instances', 'it felt magical', 'answered many questions', 'my school days', 'no satisfying fantasies', 'my mom often', 'from our childhood', 'growing up we', 'good friends often', 'shaped their mind', 'everything my parents', 'hurt and confused', 'for something spiritual', 'my whirlwind dating', 'of her thoughts', 'changes your life', 'ways of thinking', 'jumble of emotions', 'games my mother', 'i can remember', 'empathy and understanding', 'crush their spirits', 'shame or regret', 'mom often told', 'on some level', 'in my childhood', 'people whose ideas', 'my crazy childhood', 'absorb the lesson', 'from my mother', 'mother used to', 'like something profound', 'what my mother', 'i remember after', 'of our upbringing', 'my childhood', 'if my mother', 'make them proud', 'my mind lately', 'dysfunctional family', 'and my upbringing', 'as a kid', 'one summer my', 'i felt connected', 'what our mothers', 'as a child'], \n",
      "\"RSC_only\": ['came to florida', 'back in israel', 'moved to london', 'traveled to marrakesh', 'sitting in indianapolis', 'went to boston', 'was in boston', 'moved to vermont', 'was in mexico', 'moved to chicago', 'were in paris', 'was in pennsylvania', 'arrived in tokyo', 'drove from vermont', 'here in boston', 'living in chicago', 'off into vancouver', 'here in houston', 'back in boston', 'back in marrakesh', 'being in canada', \"'m in michigan\", 'home in chicago', 'i left vermont', 'moved to brooklyn', 'were in japan', 'off in vancouver', 'went to india', 'arrived in indianapolis', 'drove to washington', 'went to manchester', 'in new orleans', 'leaving for france', \"'m from detroit\", 'out to ohio', 'lived in texas', 'live near detroit', 'back in manhattan', 'drove out to', 'been to israel', 'we left poland', 'moved to washington', 'back in brooklyn', 'hometown in texas', 'around in mexico', 'to new york', 'go to spain', 'come to morocco', 'move to texas', 'flew from pittsburgh'], \n",
      "\"OPA_only\": ['towards the ceiling', 'onto the railing', 'on the ceiling', 'against the railing', 'feet hanging over', 'on the railing', 'towards the doors', 'seats behind', 'towards the door', 'lights peeking over', 'to my left', 'situated herself behind', 'you sit backward', 'to the horizon', 'maybe twelve feet', 'at the ceiling', 'towards the street', 'of seats behind', 'twenty feet above', 'his back turned', 'see the horizon', 'seats behind the', 'to my right', 'and high rafters', 'about twenty feet', 'door behind me', 'the door behind', 'toward the back', 'over his shoulder', 'feet above the', 'hands went underneath', 'towards the ground', 'his feet hanging', 'feet touch the', 'behind her and', 'stand in front', 'down one side', 'on opposite sides', 'over the ceiling', 'on either side', 'on each side', 'than eight feet', 'over the door', 'along the top', 'over the side', 'over the embankment', 'to duck under', 'the mirror behind', 'down this embankment', 'that forms horizontal'], \n",
      "\"PPA_only2\": ['kind of corny', 'of bready puns', 'like burnt steak', 'pulled a muscle', 'his painting sucked', 'like your shirt', \"'s painting sucked\", 'important like pudding', 'a snake oil', 'had some scarring', 'ithe school motto', 'bready puns', 'liar fake', 'sometimes disrespected me', 'fake name', 'okay snake oil', 'for bad puns', 'of torn fishnet', 'richard had autism', 'tasted pretty bad', 'care a euphemism', 'of corny', 'of semi lame', 'as an insult', 'almost being brainwashed', 'like his nickname', 'salad and stale', 'save the crusts', 'snake oil', 'says um and', 'explains her name', 'stale baked goods', 'your hair smells', 'puns', 'his flannel shirt', 'lip is split', 'of money darning', 'of knock off', 'called baloney', 'burnt steak', 'practiced that answer', \"'s snake oil\", 'slices of bread', 'yeast extract', 'with a puree', \"'s company tagline\", 'he meant it', 'acted like one', 'what snake oil', 'a sandwich rejected'], \n"
     ]
    }
   ],
   "source": [
    "rois = ['RSC', 'OPA', 'PPA', 'IPS', 'pSTS', 'sPMv',\n",
    "        'EBA', 'OFA'] + ['RSC_only', 'OPA_only', 'PPA_only2']  # 'PPA_only1',\n",
    "# pprint({k: explanations[k] for k in rois})\n",
    "explanations_clean = {\n",
    "    'EBA': 'Body parts',\n",
    "    'IPS': 'Descriptive elements of scenes or objects',\n",
    "    'OFA': 'Personal growth and reflection',\n",
    "    'OPA': 'Direction and location descriptions',\n",
    "    'OPA_only': 'Spatial positioning and directions',\n",
    "    'PPA': 'Scenes and settings',\n",
    "    # 'PPA_only1': 'Lying and falsehoods',\n",
    "    'PPA_only2': 'Unappetizing foods',\n",
    "    'RSC': 'Travel and location names',\n",
    "    'RSC_only': 'Location names',\n",
    "    'pSTS': 'Verbal interactions',\n",
    "    'sPMv': 'Time and numbers'}\n",
    "explanation_avoid_suffixes = {\n",
    "    'EBA': ' Avoid mentioning any locations.',\n",
    "    'IPS': ' Avoid mentioning any locations.',\n",
    "    'OFA': ' Avoid mentioning any locations.',\n",
    "    'OPA': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'OPA_only': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'PPA': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    # 'PPA_only1': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'PPA_only2': ' Avoid mentioning any specific location names (like \"New York\" or \"Europe\").',\n",
    "    'RSC': '',\n",
    "    'RSC_only': '',\n",
    "    'pSTS': ' Avoid mentioning any locations.',\n",
    "    'sPMv': ' Avoid mentioning any locations.'\n",
    "}\n",
    "for roi in rois:\n",
    "    print(f'\"{roi}\":', str(\n",
    "        top_ngrams_df[roi.replace('1', '').replace('2', '')].iloc[:50].values.tolist()) + ', ')\n",
    "    # {\n",
    "    # roi:  for roi in rois\n",
    "# })\n",
    "top_ngrams_clean = {\n",
    "    \"RSC\": ['drove from vermont', 'to washington', 'in manhattan', 'here in boston', 'off into vancouver', 'moved to chicago', 'was in mexico', 'arrived in indianapolis', 'came to florida', 'i left vermont'],\n",
    "    \"OPA\": ['onto the railing', 'towards the river', 'onto the sidewalk', 'towards the doors', 'outside the windows', 'long hallway toward', 'to the horizon', 'towards the street', 'over the gulf', 'to my left', 'path that jutted', 'on the ceiling', 'on the windowsill', 'down this embankment', 'up those stairs', 'above the gulf', 'facing the beach'],\n",
    "    \"PPA\": ['mile of cornfields', 'the windowsill', 'the rolling hills', 'beautiful moonlit mountains', 'giant stone cliffs', 'a strip mall', 'nondescript office buildings', 'manicured lawns', 'lakes', 'the dark driveway', 'and shimmering skyscrapers', 'a private beach', 'the leafy garden', 'our modest backyard', 'my dorm'],\n",
    "\n",
    "    \"RSC_only\": ['florida', 'israel', 'london', 'marrakesh', 'indianapolis', 'paris', 'pennsylvania', 'tokyo', 'tenessee', 'boston', 'vermont', 'chicago', 'indianapolis'],\n",
    "    \"OPA_only\": ['towards the ceiling', 'onto the railing', 'feet hanging over', 'towards the doors', 'seats behind', 'towards the door', 'lights peeking over', 'to my left', 'situated herself behind', 'you sit backward', 'to the horizon', 'maybe twelve feet', 'at the ceiling', 'towards the street', 'of seats behind', 'twenty feet above', 'his back turned', 'see the horizon', 'seats behind the', 'to my right', 'and high rafters', 'about twenty feet', 'door behind me', 'the door behind', 'toward the back', 'over his shoulder', 'feet above the', 'hands went underneath', 'towards the ground', 'his feet hanging', 'feet touch the', 'behind her and', 'stand in front', 'down one side', 'on opposite sides', 'over the ceiling', 'on either side'],\n",
    "    # \"PPA_only\": ['kind of corny', 'his painting sucked', 'snake oil', 'liar fake', 'fake name', 'bad puns', 'as an insult', 'called baloney'],\n",
    "    \"PPA_only2\": ['like burnt steak', 'like pudding', 'tasted pretty bad', 'stale baked goods', 'the crusts', 'baloney', 'yeast extract', 'a sandwich rejected',],\n",
    "\n",
    "    \"IPS\": ['there were slats', 'four connected squares', 'in long rows', 'on the sides', 'a long narrow', 'that forms horizontal', 'long rows of', 'sixty foot wide', 'between buttered slices', 'mile thick ice', 'all four corners', 'along the top'],\n",
    "    \"pSTS\": ['said excuse me', 'says excuse me', 'room went silent', 'someone shouted', 'i provoked gasps', 'somebody then yelled', 'she started laughing', 'excuse me', 'asked i laughed', 'exhalation someone shouted', 'retorted rather loudly', 'turned and said', 'hurry she exclaimed', 'i started yelling', 'say excuse me', 'i started laughing', 'interrupted the conversation', 'breath he yelled', 'moment she gasped', 'said guess what'],\n",
    "    \"sPMv\": ['one', 'forty', 'april nineteen forty', 'was sixteen seventeen', 'five only twenty', 'three down', 'march twentieth nineteen', 'more time passed', 'fifteen meters fifty', \"turning ninety\", 'june of nineteen'],\n",
    "    \"EBA\": ['wraps his arms', 'lifted her dress', 'arms flailing', 'hands gripped the', 'grabbed her legs', 'his hands folded', 'my feet kicking', 'navigated pushy elbows', 'elbows on knees', 'over his shoulder'],\n",
    "    \"OFA\": ['of my childhood', 'newfound self esteem', 'so my shrink', 'hurtful first dates', 'recall many instances', 'it felt magical', 'answered many questions', 'my school days', 'no satisfying fantasies', 'my mom often', 'from our childhood', 'growing up we', 'good friends often', 'shaped their mind', 'everything my parents'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {\n",
    "    'roi': rois,\n",
    "    'expl': [explanations_clean[k] for k in rois],\n",
    "    'top_ngrams_module_correct': [top_ngrams_clean[k] for k in rois],\n",
    "    'stability_score': [stability_scores[k.split('_')[0]] for k in rois],\n",
    "    # 'question': questions,\n",
    "    'subject': ['UTS02'] * len(rois),\n",
    "    'voxel_nums': [rois_dict[k.split('_')[0]] for k in rois],\n",
    "    'prompt_suffix': [explanation_avoid_suffixes[k] for k in rois],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rows).to_pickle('rows_roi_uts02_may31.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roi</th>\n",
       "      <th>expl</th>\n",
       "      <th>top_ngrams_module_correct</th>\n",
       "      <th>stability_score</th>\n",
       "      <th>subject</th>\n",
       "      <th>voxel_nums</th>\n",
       "      <th>prompt_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSC</td>\n",
       "      <td>Travel and location names</td>\n",
       "      <td>[drove from vermont, to washington, in manhatt...</td>\n",
       "      <td>0.727578</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[26313, 26368, 26369, 26370, 26423, 26424, 264...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPA</td>\n",
       "      <td>Direction and location descriptions</td>\n",
       "      <td>[onto the railing, towards the river, onto the...</td>\n",
       "      <td>0.683813</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[24026, 27029, 27030, 27031, 27075, 27076, 270...</td>\n",
       "      <td>Avoid mentioning any specific location names ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PPA</td>\n",
       "      <td>Scenes and settings</td>\n",
       "      <td>[mile of cornfields, the windowsill, the rolli...</td>\n",
       "      <td>0.417527</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[9579, 9580, 9634, 11900, 11901, 11902, 11903,...</td>\n",
       "      <td>Avoid mentioning any specific location names ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IPS</td>\n",
       "      <td>Descriptive elements of scenes or objects</td>\n",
       "      <td>[there were slats, four connected squares, in ...</td>\n",
       "      <td>0.635485</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[52728, 52729, 52730, 52781, 52782, 52783, 528...</td>\n",
       "      <td>Avoid mentioning any locations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pSTS</td>\n",
       "      <td>Verbal interactions</td>\n",
       "      <td>[said excuse me, says excuse me, room went sil...</td>\n",
       "      <td>0.601735</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[26011, 26067, 26068, 26123, 26124, 26125, 291...</td>\n",
       "      <td>Avoid mentioning any locations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sPMv</td>\n",
       "      <td>Time and numbers</td>\n",
       "      <td>[one, forty, april nineteen forty, was sixteen...</td>\n",
       "      <td>0.564742</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[71004, 71005, 71006, 71024, 71025, 71053, 710...</td>\n",
       "      <td>Avoid mentioning any locations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA</td>\n",
       "      <td>Body parts</td>\n",
       "      <td>[wraps his arms, lifted her dress, arms flaili...</td>\n",
       "      <td>0.623958</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[10330, 10331, 10370, 10371, 10410, 12693, 126...</td>\n",
       "      <td>Avoid mentioning any locations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OFA</td>\n",
       "      <td>Personal growth and reflection</td>\n",
       "      <td>[of my childhood, newfound self esteem, so my ...</td>\n",
       "      <td>0.574794</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[8133, 8161, 8189, 8190, 8221, 8222, 8223, 822...</td>\n",
       "      <td>Avoid mentioning any locations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RSC_only</td>\n",
       "      <td>Location names</td>\n",
       "      <td>[florida, israel, london, marrakesh, indianapo...</td>\n",
       "      <td>0.727578</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[26313, 26368, 26369, 26370, 26423, 26424, 264...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPA_only</td>\n",
       "      <td>Spatial positioning and directions</td>\n",
       "      <td>[towards the ceiling, onto the railing, feet h...</td>\n",
       "      <td>0.683813</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[24026, 27029, 27030, 27031, 27075, 27076, 270...</td>\n",
       "      <td>Avoid mentioning any specific location names ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PPA_only2</td>\n",
       "      <td>Unappetizing foods</td>\n",
       "      <td>[like burnt steak, like pudding, tasted pretty...</td>\n",
       "      <td>0.417527</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>[9579, 9580, 9634, 11900, 11901, 11902, 11903,...</td>\n",
       "      <td>Avoid mentioning any specific location names ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          roi                                       expl  \\\n",
       "0         RSC                  Travel and location names   \n",
       "1         OPA        Direction and location descriptions   \n",
       "2         PPA                        Scenes and settings   \n",
       "3         IPS  Descriptive elements of scenes or objects   \n",
       "4        pSTS                        Verbal interactions   \n",
       "5        sPMv                           Time and numbers   \n",
       "6         EBA                                 Body parts   \n",
       "7         OFA             Personal growth and reflection   \n",
       "8    RSC_only                             Location names   \n",
       "9    OPA_only         Spatial positioning and directions   \n",
       "10  PPA_only2                         Unappetizing foods   \n",
       "\n",
       "                            top_ngrams_module_correct  stability_score  \\\n",
       "0   [drove from vermont, to washington, in manhatt...         0.727578   \n",
       "1   [onto the railing, towards the river, onto the...         0.683813   \n",
       "2   [mile of cornfields, the windowsill, the rolli...         0.417527   \n",
       "3   [there were slats, four connected squares, in ...         0.635485   \n",
       "4   [said excuse me, says excuse me, room went sil...         0.601735   \n",
       "5   [one, forty, april nineteen forty, was sixteen...         0.564742   \n",
       "6   [wraps his arms, lifted her dress, arms flaili...         0.623958   \n",
       "7   [of my childhood, newfound self esteem, so my ...         0.574794   \n",
       "8   [florida, israel, london, marrakesh, indianapo...         0.727578   \n",
       "9   [towards the ceiling, onto the railing, feet h...         0.683813   \n",
       "10  [like burnt steak, like pudding, tasted pretty...         0.417527   \n",
       "\n",
       "   subject                                         voxel_nums  \\\n",
       "0    UTS02  [26313, 26368, 26369, 26370, 26423, 26424, 264...   \n",
       "1    UTS02  [24026, 27029, 27030, 27031, 27075, 27076, 270...   \n",
       "2    UTS02  [9579, 9580, 9634, 11900, 11901, 11902, 11903,...   \n",
       "3    UTS02  [52728, 52729, 52730, 52781, 52782, 52783, 528...   \n",
       "4    UTS02  [26011, 26067, 26068, 26123, 26124, 26125, 291...   \n",
       "5    UTS02  [71004, 71005, 71006, 71024, 71025, 71053, 710...   \n",
       "6    UTS02  [10330, 10331, 10370, 10371, 10410, 12693, 126...   \n",
       "7    UTS02  [8133, 8161, 8189, 8190, 8221, 8222, 8223, 822...   \n",
       "8    UTS02  [26313, 26368, 26369, 26370, 26423, 26424, 264...   \n",
       "9    UTS02  [24026, 27029, 27030, 27031, 27075, 27076, 270...   \n",
       "10   UTS02  [9579, 9580, 9634, 11900, 11901, 11902, 11903,...   \n",
       "\n",
       "                                        prompt_suffix  \n",
       "0                                                      \n",
       "1    Avoid mentioning any specific location names ...  \n",
       "2    Avoid mentioning any specific location names ...  \n",
       "3                     Avoid mentioning any locations.  \n",
       "4                     Avoid mentioning any locations.  \n",
       "5                     Avoid mentioning any locations.  \n",
       "6                     Avoid mentioning any locations.  \n",
       "7                     Avoid mentioning any locations.  \n",
       "8                                                      \n",
       "9    Avoid mentioning any specific location names ...  \n",
       "10   Avoid mentioning any specific location names ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sum(rows['voxel_nums'], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
