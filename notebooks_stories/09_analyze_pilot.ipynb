{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import story_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num\n",
    "from sasc.config import FMRI_DIR\n",
    "story_data = joblib.load(join(sasc.config.RESULTS_DIR, 'pilot_story_data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and corresponding resps\n",
    "pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230504'\n",
    "resp_np_files = sorted(os.listdir(pilot_data_dir))\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}\n",
    "\n",
    "# pcs = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"loo_pc_UTS02.pkl\"))\n",
    "# pcs['good_voxels'].shape\n",
    "# pcs['pca_projections'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = defaultdict(list)\n",
    "for use_clusters in [False, True]:\n",
    "    for story_num in [0, 1, 2, 3, 4, 5]:\n",
    "        rows = story_data[\"rows\"][story_num]\n",
    "\n",
    "        # get resp_chunks\n",
    "        resp_story = resps_dict[\n",
    "            story_data[\"story_name_new\"][story_num]\n",
    "        ].T  # (voxels, time)\n",
    "        timing = story_data[\"timing\"][story_num]\n",
    "        paragraphs = story_data[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "        assert len(paragraphs) == len(rows)\n",
    "        resp_chunks = story_helper.get_resp_chunks(timing, paragraphs, resp_story)\n",
    "\n",
    "        # calculate mat\n",
    "        mat = np.zeros((len(rows), len(paragraphs)))\n",
    "        for i in range(len(paragraphs)):\n",
    "            if use_clusters == False:\n",
    "                mat[:, i] = resp_chunks[i][rows[\"voxel_num\"].values].mean(axis=1)\n",
    "            elif use_clusters == True:\n",
    "                for r in range(len(rows)):\n",
    "                    cluster_nums = rows.iloc[r][\"cluster_nums\"]\n",
    "                    if isinstance(cluster_nums, np.ndarray):\n",
    "                        vals = resp_chunks[i][cluster_nums].flatten()\n",
    "                        mat[r, i] = np.nanmean(vals)\n",
    "                    else:\n",
    "                        # print(cluster_nums)\n",
    "                        mat[r, i] = np.nan\n",
    "        mat[:, 0] = np.nan  # ignore the first column\n",
    "        # print('mat', mat)\n",
    "\n",
    "        # sort by voxel_num\n",
    "        args = np.argsort(rows[\"voxel_num\"].values)\n",
    "        mat = mat[args, :][:, args]\n",
    "        mats[use_clusters].append(deepcopy(mat))\n",
    "\n",
    "        # plt.imshow(mat)\n",
    "        # plt.colorbar(label=\"Mean response\")\n",
    "        # plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "        # plt.ylabel(\"Voxel\")\n",
    "        # plt.title(f\"{story_data['story_name_new'][story_num][3:-10]}\")\n",
    "        # plt.show()\n",
    "expls = rows.sort_values(by=\"voxel_num\")[\"expl\"].values\n",
    "\n",
    "m = {}\n",
    "for use_clusters in [False, True]:\n",
    "    mats[use_clusters] = np.array(mats[use_clusters])  # (6, 17, 17)\n",
    "    m[use_clusters] = np.nanmean(mats[use_clusters], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make average plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate means\n",
    "use_clusters = True\n",
    "m1 = m[use_clusters]\n",
    "\n",
    "n = m1.shape[0]\n",
    "diag_means = np.diag(m1)\n",
    "diag_mean = np.nanmean(diag_means)\n",
    "\n",
    "# get mean of each row excluding the diagonal\n",
    "off_diag_means = np.nanmean(m1, axis=1) - (diag_means / n)\n",
    "off_diag_mean = np.nanmean(off_diag_means)\n",
    "\n",
    "\n",
    "# make plot\n",
    "x = np.arange(n) - n / 2\n",
    "plt.bar(1, diag_mean, width=0.5, label='Diagonal', alpha=0.1, color='C0')\n",
    "plt.errorbar(1, diag_mean, yerr=np.nanstd(diag_means) / np.sqrt(len(diag_means)), fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5, lw=1)\n",
    "plt.plot(1 + x/50, diag_means, '.', color='C0', alpha=0.5)\n",
    "\n",
    "plt.bar(2, off_diag_mean, width=0.5, label='Off-diagonal', alpha=0.1, color='C1')\n",
    "plt.errorbar(2, off_diag_mean, yerr=np.nanstd(off_diag_means) / np.sqrt(len(off_diag_means)), fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5)\n",
    "plt.plot(2 + x/50, off_diag_means, '.', color='C1')\n",
    "\n",
    "plt.xticks([1, 2], ['Driving paragraph', 'Baseline paragraphs'])\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# annotate the point with the highest mean\n",
    "kwargs = dict(\n",
    "    arrowprops=dict(arrowstyle='->', color='#333'), fontsize='x-small', color='#333'\n",
    ")\n",
    "idx = np.argmax(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the second highest mean\n",
    "idx = np.argsort(diag_means)[-2]\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the lowest mean\n",
    "idx = np.argmin(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx]), **kwargs)\n",
    "plt.tight_layout()\n",
    "print('mean', diag_mean - off_diag_mean)\n",
    "plt.savefig('../results/pilot_means.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between different voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: some voxels didn't have good clusters so they will be missing from these plots...\n",
    "\n",
    "use_clusters = True\n",
    "m1 = m[use_clusters]\n",
    "# cg = sns.clustermap(pd.DataFrame(m, columns=expls, index=expls), method='complete', cmap='viridis', figsize=(10, 10))\n",
    "# plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "# plt.xlabel('Driving paragraph')\n",
    "plt.figure(figsize=(6, 6))\n",
    "# m = softmax(m, axis=0)\n",
    "\n",
    "\n",
    "for r in range(m1.shape[0]):\n",
    "    for c in range(m1.shape[1]):\n",
    "        # outline the diagonal\n",
    "        if r == c:\n",
    "            plt.plot([r - 0.5, r + 0.5], [c - 0.5, c - 0.5], color='gray', lw=1)\n",
    "            plt.plot([r - 0.5, r + 0.5], [c + 0.5, c + 0.5], color='gray', lw=1)\n",
    "            plt.plot([r - 0.5, r - 0.5], [c - 0.5, c + 0.5], color='gray', lw=1)\n",
    "            plt.plot([r + 0.5, r + 0.5], [c - 0.5, c + 0.5], color='gray', lw=1)\n",
    "        \n",
    "\n",
    "\n",
    "plt.imshow(m1)\n",
    "plt.xlabel(\"Driving paragraph\\n(Ideally, diagonal should be brighter)\", fontsize='x-small')\n",
    "plt.ylabel(\"Voxel\", fontsize='x-small')\n",
    "plt.yticks(labels=expls, ticks=np.arange(len(expls)), fontsize='x-small')\n",
    "plt.xticks(labels=expls, ticks=np.arange(len(expls)), rotation=90, fontsize='x-small')\n",
    "plt.show()\n",
    "\n",
    "# plot correlations across all resps\n",
    "# resps_voxels = np.concatenate(\n",
    "#     [resps_dict[story_data[\"story_name_new\"][story_num]].T for story_num in [2, 3, 4]],\n",
    "#     axis=1,\n",
    "# )[rw[\"voxel_num\"].values]\n",
    "# corr = pd.DataFrame(resps_voxels.T, columns=expls).corr().round(2)\n",
    "# sns.clustermap(corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clusters = False\n",
    "mats1 = mats[use_clusters]\n",
    "\n",
    "d = defaultdict(list)\n",
    "for i in range(len(mats1)):\n",
    "    m = mats1[i]\n",
    "    d['driving'].append(np.nanmean(np.diag(m)))\n",
    "    d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "    d['story'].append(story_data['story_name_new'][i][3:-10])\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "# make barplot comparing driving and baseline\n",
    "df = df.melt(id_vars='story', value_vars=['driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "df = df.sort_values(by='story')\n",
    "sns.barplot(data=df, x='story', y='mean', hue='condition')\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = rw.sort_values(by=\"voxel_num\")\n",
    "rw['mean_resp_diff'] = diag_means # - off_diag_means\n",
    "\n",
    "# ax = sns.pairplot(rw, vars=['mean_resp_diff', 'top_score_synthetic', 'fmri_test_corr'], hue='expl')\n",
    "# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1.01, 1))\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rw['top_score_synthetic'], rw['mean_resp_diff'], 'o')\n",
    "plt.ylabel('Mean voxel response')\n",
    "plt.xlabel('Synthetic score')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rw['fmri_test_corr'], rw['mean_resp_diff'], 'o')\n",
    "plt.xlabel('Predicted test correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
