{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "import sasc.viz\n",
    "from sasc import analyze_helper\n",
    "from sasc.config import FMRI_DIR, RESULTS_DIR\n",
    "import dvu\n",
    "dvu.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pilot pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# pilot_name = 'pilot_story_data.pkl'\n",
    "pilot_name = 'pilot3_story_data.pkl'\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(sasc.config.RESULTS_DIR, pilot_name))\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230504'\n",
    "elif pilot_name == 'pilot2_story_data.pkl':\n",
    "    pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230702'\n",
    "elif pilot_name == 'pilot3_story_data.pkl':\n",
    "    pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20231106'\n",
    "\n",
    "\n",
    "# load responses\n",
    "default_story_idxs = np.where(\n",
    "    np.array(stories_data_dict['story_setting']) == 'default')[0]\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in default_story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings_list = stories_data_dict['timing']\n",
    "story_names_list = list(resps_dict.keys())\n",
    "resps = list(resps_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenStory12.npy resp_length 365 story_trs 374 story_length 749.0\n",
      "GenStory13.npy resp_length 430 story_trs 439 story_length 878.7\n"
     ]
    }
   ],
   "source": [
    "TRIM = 5\n",
    "for i in range(len(resps)):\n",
    "    t = timings_list[i]\n",
    "    duration_secs = t['time_running'].max()\n",
    "    print(story_names_list[i], 'resp_length',\n",
    "          resps[i].shape[0], 'story_trs',\n",
    "          int(duration_secs // 2), 'story_length', duration_secs.round(1))  # , 'timings',\n",
    "    diff = int(duration_secs // 2) - resps[i].shape[0]\n",
    "    assert abs(diff - TRIM * 2) <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the alignment w/ paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(paragraphs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(rows)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m resp_chunks \u001b[39m=\u001b[39m analyze_helper\u001b[39m.\u001b[39mget_resps_for_paragraphs(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     timing, paragraphs, resp_story, offset\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(resp_chunks) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(paragraphs)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def remove_repeated_words(paragraph):\n",
    "    words = paragraph.split()\n",
    "    new_words = [words[0]]\n",
    "    for w in words[1:]:\n",
    "        if w != new_words[-1]:\n",
    "            new_words.append(w)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "\n",
    "# for story_num in [0]:\n",
    "for story_num in [default_story_idxs]:\n",
    "    rows = stories_data_dict[\"rows\"][story_num]\n",
    "\n",
    "    # get resp_chunks\n",
    "    resp_story = resps_dict[\n",
    "        stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "            '_resps', '')\n",
    "    ].T  # (voxels, time)\n",
    "    timing = stories_data_dict[\"timing\"][story_num]\n",
    "    paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "    if pilot_name in ['pilot3_story_data.pkl']:\n",
    "        paragraphs = [remove_repeated_words(p) for p in paragraphs]\n",
    "        assert len(paragraphs) == len(rows)\n",
    "    resp_chunks = analyze_helper.get_resps_for_paragraphs(\n",
    "        timing, paragraphs, resp_story, offset=2)\n",
    "    assert len(resp_chunks) == len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>timing</th>\n",
       "      <th>time_running</th>\n",
       "      <th>word_len</th>\n",
       "      <th>ends_in_period</th>\n",
       "      <th>ends_in_comma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upon</td>\n",
       "      <td>0.269606</td>\n",
       "      <td>0.979606</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.264278</td>\n",
       "      <td>1.243884</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time,</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.993884</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>2.113884</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>thick</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>748.316705</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>and</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>748.526705</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>thin,</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>748.656705</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>understanding</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>748.716705</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>that</td>\n",
       "      <td>0.269606</td>\n",
       "      <td>748.986311</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2737 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word    timing  time_running  word_len  ends_in_period  \\\n",
       "0              Once  0.710000      0.710000         4           False   \n",
       "1              upon  0.269606      0.979606         4           False   \n",
       "2                 a  0.264278      1.243884         1           False   \n",
       "3             time,  0.750000      1.993884         5           False   \n",
       "4                in  0.120000      2.113884         2           False   \n",
       "...             ...       ...           ...       ...             ...   \n",
       "2732          thick  0.300000    748.316705         5           False   \n",
       "2733            and  0.210000    748.526705         3           False   \n",
       "2734          thin,  0.130000    748.656705         5           False   \n",
       "2735  understanding  0.060000    748.716705        13           False   \n",
       "2736           that  0.269606    748.986311         4           False   \n",
       "\n",
       "      ends_in_comma  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3              True  \n",
       "4             False  \n",
       "...             ...  \n",
       "2732          False  \n",
       "2733          False  \n",
       "2734           True  \n",
       "2735          False  \n",
       "2736          False  \n",
       "\n",
       "[2737 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95556, 365)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_story.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in os.listdir('.'):\n",
    "#     if os.path.isdir(s):\n",
    "#         print(s)\n",
    "#         for seed in os.listdir(s):\n",
    "#             fname = os.path.join(s, seed, 'timings_processed.csv')\n",
    "#             t = pd.read_csv(fname)\n",
    "#             # remove rows with repeated word\n",
    "#             t = t[t['word'] != t['word'].shift(1)]\n",
    "#             t['time_running'] = np.cumsum(t[\"timing\"])\n",
    "#             t.to_csv(fname, index=False)\n",
    "\n",
    "\n",
    "paragraphs = [remove_repeated_words(p) for p in paragraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(24, 'me', 'love')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m start_indexes, end_indexes \u001b[39m=\u001b[39m analyze_helper\u001b[39m.\u001b[39;49mget_start_end_indexes_for_paragraphs(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     timing, paragraphs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(paragraphs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/01_check_alignment.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(timing[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/automated-explanations/sasc/analyze_helper.py:28\u001b[0m, in \u001b[0;36mget_start_end_indexes_for_paragraphs\u001b[0;34m(timing, paragraphs)\u001b[0m\n\u001b[1;32m     26\u001b[0m start_times\u001b[39m.\u001b[39mappend(timing[\u001b[39m\"\u001b[39m\u001b[39mtime_running\u001b[39m\u001b[39m\"\u001b[39m][idx])\n\u001b[1;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words:\n\u001b[0;32m---> 28\u001b[0m     \u001b[39massert\u001b[39;00m _remove_punc(timing[\u001b[39m\"\u001b[39m\u001b[39mword\u001b[39m\u001b[39m\"\u001b[39m][idx]) \u001b[39m==\u001b[39m _remove_punc(word), (\n\u001b[1;32m     29\u001b[0m         idx,\n\u001b[1;32m     30\u001b[0m         timing[\u001b[39m\"\u001b[39m\u001b[39mword\u001b[39m\u001b[39m\"\u001b[39m][idx],\n\u001b[1;32m     31\u001b[0m         word,\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m     idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(timing):\n\u001b[1;32m     35\u001b[0m         \u001b[39m# print('break!!!!')\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: (24, 'me', 'love')"
     ]
    }
   ],
   "source": [
    "start_indexes, end_indexes = analyze_helper.get_start_end_indexes_for_paragraphs(\n",
    "    timing, paragraphs)\n",
    "print(paragraphs[0].split())\n",
    "print(timing['word'].values.tolist())\n",
    "print(\n",
    "    f'should have {len(paragraphs)} paragraphs but only found {len(resp_chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
