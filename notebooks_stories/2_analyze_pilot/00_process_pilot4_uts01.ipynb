{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "# import story_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num, add_stability_score\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR\n",
    "from sasc import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the info from stories into a single pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stuff\n",
    "# double check all of these, intro paragraph may be the same...\n",
    "output_file = join(sasc.config.RESULTS_DIR,\n",
    "                   'processed', \"pilot4_story_data.pkl\")\n",
    "story_mapping = {\n",
    "    'default/uts01___may9___seed=5_top1': 'deeptune-story19.npy',\n",
    "    'default/uts01___may9___seed=2_top2': 'deeptune-story20.npy',\n",
    "\n",
    "    'interactions/uts01___may9___seed=3_top1': 'deeptune-story21.npy',\n",
    "    'interactions/uts01___may9___seed=6_top2': 'deeptune-story22.npy',\n",
    "}\n",
    "\n",
    "# custom timings because the story had to be slowed down\n",
    "story_timings_custom = {\n",
    "    'default/uts01___may9___seed=5_top1': 'UTS01_deeptune19.report',\n",
    "    'default/uts01___may9___seed=2_top2': 'UTS01_deeptune20.report',\n",
    "\n",
    "    'interactions/uts01___may9___seed=3_top1': 'UTS01_deeptune21.report',\n",
    "    'interactions/uts01___may9___seed=6_top2': 'UTS01_deeptune22.report',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add header line to report files\n",
    "header_line = \"time misc word misc\"\n",
    "for val in story_timings_custom.values():\n",
    "    original_file = join(config.PILOT_STORY_DATA_DIR,\n",
    "                         '20240509', val)\n",
    "    new_file = join(config.PILOT_STORY_DATA_DIR,\n",
    "                    '20240509', val.replace('.report', '_processed.txt'))\n",
    "    with open(original_file, 'r') as file:\n",
    "        s = file.read()\n",
    "    with open(new_file, 'w') as file:\n",
    "        file.write(header_line + '\\n' + s.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune19_processed.txt\n",
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune20_processed.txt\n",
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune21_processed.txt\n",
      "/home/chansingh/mntv1/deep-fMRI/brain_tune/story_data/20240509/UTS01_deeptune22_processed.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/chansingh/automated-explanations/results/processed/pilot4_story_data.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster_neighbors = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"cluster_neighbors_v1.pkl\"))\n",
    "perfs = joblib.load(join(sasc.config.FMRI_DIR, 'sasc', 'rj_models',\n",
    "                    'opt_model', 'new_setup_performance.jbl'))\n",
    "\n",
    "# add keys\n",
    "stories_data_dict = defaultdict(list)\n",
    "for story_idx, story_name in enumerate(story_mapping.keys()):\n",
    "    # add scalar story descriptions\n",
    "    stories_data_dict[\"story_name_original\"].append(story_name)\n",
    "    stories_data_dict[\"story_setting\"].append(story_name.split(\"/\")[0])\n",
    "    stories_data_dict[\"story_name_new\"].append(story_mapping[story_name])\n",
    "    stories_data_dict[\"story_text\"].append(\n",
    "        open(join(STORIES_DIR, story_name, \"story.txt\"), \"r\").read()\n",
    "    )\n",
    "    prompts_paragraphs = joblib.load(\n",
    "        join(STORIES_DIR, story_name, \"prompts_paragraphs.pkl\")\n",
    "    )\n",
    "\n",
    "    # add paragraph-level descriptions\n",
    "    timings_file = join(config.PILOT_STORY_DATA_DIR, '20240509',\n",
    "                        story_timings_custom[story_name]).replace('.report', '_processed.txt')\n",
    "    print(timings_file)\n",
    "    # , quotechar=None, quoting=3)\n",
    "    timings = pd.read_csv(timings_file, sep=' ')\n",
    "    timings = timings[timings.misc == 'word']\n",
    "    timings['time_running'] = timings['time']\n",
    "    timings = timings.reset_index()\n",
    "\n",
    "    timings_to_save = timings.copy()\n",
    "    # timings_to_save['time_running'] = timings_to_save['time_running'] - 10\n",
    "    timings_to_save['timing'] = np.diff(\n",
    "        timings_to_save['time_running']).tolist() + [0]\n",
    "\n",
    "    timings_to_save.to_csv(\n",
    "        join(STORIES_DIR, story_name, \"timings_processed_slowed.csv\")\n",
    "    )\n",
    "    # display(timings)\n",
    "    # timings['time_running'] = timings['time_running'] + 10\n",
    "\n",
    "    stories_data_dict[\"timing\"].append(\n",
    "        # pd.read_csv(join(STORIES_DIR, story_name, \"timings_processed.csv\"))\n",
    "        timings\n",
    "    )\n",
    "    stories_data_dict[\"prompts\"].append(prompts_paragraphs[\"prompts\"])\n",
    "    stories_data_dict[\"paragraphs\"].append(prompts_paragraphs[\"paragraphs\"])\n",
    "\n",
    "    # add paragraph-level metadata\n",
    "    # rows\n",
    "    # rows = pd.read_csv(join(STORIES_DIR, story_name, \"rows.csv\"))\n",
    "    story_metadata_per_paragraph = pd.read_pickle(\n",
    "        join(STORIES_DIR, story_name, \"rows.pkl\"))\n",
    "    story_metadata_per_paragraph[\"voxel_num\"] = story_metadata_per_paragraph.apply(\n",
    "        lambda row: convert_module_num_to_voxel_num(\n",
    "            row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    story_metadata_per_paragraph[\"stability_score\"] = story_metadata_per_paragraph.apply(\n",
    "        lambda row: add_stability_score(row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    story_metadata_per_paragraph = story_metadata_per_paragraph[\n",
    "        [\n",
    "            \"expl\",\n",
    "            \"module_num\",\n",
    "            \"top_explanation_init_strs\",\n",
    "            \"subject\",\n",
    "            \"fmri_test_corr\",\n",
    "            \"stability_score\",\n",
    "            # \"top_score_synthetic\",\n",
    "            \"top_score_normalized\",\n",
    "            \"roi_anat\",\n",
    "            \"roi_func\",\n",
    "            \"voxel_num\",\n",
    "        ]\n",
    "    ]\n",
    "    story_metadata_per_paragraph['test_corr_new'] = story_metadata_per_paragraph['voxel_num'].apply(\n",
    "        lambda x: perfs[x])\n",
    "    # rows['cluster_nums'] = rows['voxel_num'].map(cluster_neighbors)\n",
    "    stories_data_dict[\"rows\"].append(story_metadata_per_paragraph)\n",
    "\n",
    "    if \"interactions\" in list(story_mapping.keys())[story_idx]:\n",
    "        rows1 = pd.read_pickle(join(STORIES_DIR, story_name, \"rows1.pkl\"))\n",
    "        rows2 = pd.read_pickle(join(STORIES_DIR, story_name, \"rows2.pkl\"))\n",
    "        rows1[\"voxel_num\"] = rows1.apply(\n",
    "            lambda row: convert_module_num_to_voxel_num(\n",
    "                row[\"module_num\"], row[\"subject\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        rows2[\"voxel_num\"] = rows2.apply(\n",
    "            lambda row: convert_module_num_to_voxel_num(\n",
    "                row[\"module_num\"], row[\"subject\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        stories_data_dict['voxel_num1'].append(rows1['voxel_num'])\n",
    "        stories_data_dict['voxel_num2'].append(rows2['voxel_num'])\n",
    "        stories_data_dict['expl1'].append(rows1['expl'])\n",
    "        stories_data_dict['expl2'].append(rows2['expl'])\n",
    "    else:\n",
    "        stories_data_dict['voxel_num1'].append([])\n",
    "        stories_data_dict['voxel_num2'].append([])\n",
    "        stories_data_dict['expl1'].append([])\n",
    "        stories_data_dict['expl2'].append([])\n",
    "\n",
    "\n",
    "joblib.dump(stories_data_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full df\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "# display(stories_data_dict['timing'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Margot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings['word'].values[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
