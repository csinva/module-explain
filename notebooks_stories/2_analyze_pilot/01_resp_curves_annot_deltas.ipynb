{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "import re\n",
    "import sasc.viz\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from sasc import config\n",
    "import pandas as pd\n",
    "from sasc import analyze_helper\n",
    "\n",
    "pilot_name = 'pilot_story_data.pkl'\n",
    "# pilot_name = 'pilot3_story_data.pkl'\n",
    "# pilot_name = 'pilot4_story_data.pkl'\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(config.RESULTS_DIR, 'processed', pilot_name))\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20230504')\n",
    "elif pilot_name == 'pilot3_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20231106')\n",
    "elif pilot_name == 'pilot4_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20240509')\n",
    "\n",
    "# pilot_data_dir = join(sasc.config.FMRI_DIR, 'story_data/20230504')\n",
    "resp_np_files = os.listdir(pilot_data_dir)\n",
    "resps_dict = {k: np.load(join(pilot_data_dir, k)) for k in tqdm(resp_np_files)}\n",
    "stories_data_dict = joblib.load(\n",
    "    join(config.RESULTS_DIR, 'processed', pilot_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these function use absolute timing indexes rather than trimmed ones. This works out because they never have to reference the paragraph splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot annotated response curves and aggregate word_chunk_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_chunk_deltas = []\n",
    "for story_num in tqdm(range(6)):\n",
    "    paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "    prompts = stories_data_dict[\"prompts\"]\n",
    "    t = deepcopy(stories_data_dict[\"timing\"][story_num])\n",
    "    # t['time_running'] = t['time_running'] - 10\n",
    "\n",
    "    # these must be passed same timing\n",
    "    word_chunks = analyze_helper._get_word_chunks(t)\n",
    "    # word_chunks = word_chunks[5:-5]\n",
    "    start_times, end_times = analyze_helper.get_start_end_indexes_for_paragraphs(\n",
    "        t, paragraphs)\n",
    "\n",
    "    # example_ngrams and word_chunks\n",
    "    ps = prompts[story_num]\n",
    "    example_ngrams_list = sum(\n",
    "        [analyze_helper.find_all_examples_within_quotes(x) for x in ps], []\n",
    "    )\n",
    "    word_chunks_contain_example_ngrams = np.zeros(len(word_chunks))\n",
    "    for i, wc in enumerate(word_chunks):\n",
    "        for ngram in example_ngrams_list:\n",
    "            if any([ngram in w for w in wc]):\n",
    "                word_chunks_contain_example_ngrams[i] = 1\n",
    "                break\n",
    "\n",
    "    # get resp curves\n",
    "    rows = stories_data_dict[\"rows\"][story_num]\n",
    "    voxel_nums = rows[\"voxel_num\"]\n",
    "    expls = rows[\"expl\"]\n",
    "    r_curves = resps_dict[\n",
    "        stories_data_dict[\"story_name_new\"][story_num].replace('_resps', '')\n",
    "    ].T[voxel_nums]\n",
    "\n",
    "    for voxel_num in range(17):\n",
    "        expl_voxel = expls[voxel_num]\n",
    "        voxel_resp = r_curves[voxel_num]\n",
    "        word_chunk_deltas.append(\n",
    "            sasc.analyze_helper.compute_word_chunk_deltas_for_single_paragraph(\n",
    "                start_times,\n",
    "                end_times,\n",
    "                voxel_resp,\n",
    "                word_chunks_contain_example_ngrams,\n",
    "                voxel_num,\n",
    "            ))\n",
    "        sasc.viz.plot_annotated_resp(\n",
    "            voxel_num,\n",
    "            word_chunks,\n",
    "            voxel_resp,\n",
    "            expl_voxel,\n",
    "            start_times,\n",
    "            end_times,\n",
    "            stories_data_dict,\n",
    "            expls,\n",
    "            story_num,\n",
    "            word_chunks_contain_example_ngrams,\n",
    "            annotate_texts=False,\n",
    "            plot_key_ngrams=False,\n",
    "        )\n",
    "    analyze_helper.save_figs_to_single_pdf(\n",
    "        filename=join(sasc.config.RESULTS_DIR,\n",
    "                      'figs/curves',\n",
    "                      f'{stories_data_dict[\"story_name_new\"][story_num][3:-10]}_curves.pdf')\n",
    "    )\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "# Plot ngram delta\n",
    "means = []\n",
    "sems = []\n",
    "delta_offsets = [1, 2, 3, 4, 5]\n",
    "for i in delta_offsets:\n",
    "    deltas = sum([x[i] for x in word_chunk_deltas], [])\n",
    "    # plt.hist(deltas, label='Delta ' + str(i), alpha=0.5)\n",
    "    # plt.axvline(np.mean(deltas), linewidth=1, color=f'C{i - 1}')\n",
    "\n",
    "    means.append(np.mean(deltas))\n",
    "    sems.append(np.std(deltas) / np.sqrt(len(deltas)))\n",
    "    print(f'Delta {i} mean: {means[-1]:0.4f} +/- {sems[-1]:0.4f}')\n",
    "# plt.legend()\n",
    "delta_offsets = 2 * np.array(delta_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_chunk_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_chunk_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of means\n",
    "# sns.\n",
    "plt.grid(zorder=-100)\n",
    "plt.bar(delta_offsets, means, color='#9dc9e0', zorder=100, width=1.5, alpha=1)\n",
    "plt.errorbar(delta_offsets, means, yerr=sems,\n",
    "             fmt='o', color='black', zorder=101, capsize=4)\n",
    "plt.xticks(delta_offsets)\n",
    "\n",
    "plt.xlabel('Seconds after presentation of key ngram')\n",
    "plt.ylabel('Voxel response change ($\\sigma$)')\n",
    "plt.savefig(join(sasc.config.RESULTS_DIR, 'figs', 'misc',\n",
    "            'pilot_default_ngram_deltas.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown by explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_by_expl = pd.DataFrame({\n",
    "    'expl': np.tile(expls.values, 6),\n",
    "    'deltas': [x[3] for x in word_chunk_deltas]\n",
    "})\n",
    "# groupby expl and concatenate list values\n",
    "deltas_by_expl = deltas_by_expl.groupby(\n",
    "    'expl').agg(lambda x: sum(x, [])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_by_expl['delta_mean'] = deltas_by_expl['deltas'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expl</th>\n",
       "      <th>delta_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birthdays</td>\n",
       "      <td>0.741954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>communication</td>\n",
       "      <td>0.047994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>death</td>\n",
       "      <td>-0.130797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emotion</td>\n",
       "      <td>-0.060216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emotional expression</td>\n",
       "      <td>0.188610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>food preparation</td>\n",
       "      <td>0.272026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hair and clothing</td>\n",
       "      <td>0.244319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>laughter</td>\n",
       "      <td>0.504986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>locations</td>\n",
       "      <td>0.118016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>measurements</td>\n",
       "      <td>-0.167432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>moments</td>\n",
       "      <td>0.015150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>negativity</td>\n",
       "      <td>0.508052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>physical injury or trauma</td>\n",
       "      <td>-0.038101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rejection</td>\n",
       "      <td>0.011086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0.398949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.148393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         expl  delta_mean\n",
       "0                   birthdays    0.741954\n",
       "1               communication    0.047994\n",
       "2                       death   -0.130797\n",
       "3                     emotion   -0.060216\n",
       "4        emotional expression    0.188610\n",
       "5            food preparation    0.272026\n",
       "6           hair and clothing    0.244319\n",
       "7                    laughter    0.504986\n",
       "8                   locations    0.118016\n",
       "9                measurements   -0.167432\n",
       "10                    moments    0.015150\n",
       "11                 negativity    0.508052\n",
       "12  physical injury or trauma   -0.038101\n",
       "13                  rejection    0.011086\n",
       "14                   surprise    0.398949\n",
       "15                       time   -0.148393"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas_by_expl[['expl', 'delta_mean']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
