{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/automated-explanations/sasc/viz.py:35: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  plt.colorbar(label='Mean response ($\\sigma_f$)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:17<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "import re\n",
    "import sasc.viz\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from sasc import analyze_helper\n",
    "\n",
    "pilot_data_dir = join(sasc.config.FMRI_DIR, 'story_data/20230504')\n",
    "resp_np_files = os.listdir(pilot_data_dir)\n",
    "resps_dict = {k: np.load(join(pilot_data_dir, k)) for k in tqdm(resp_np_files)}\n",
    "stories_data_dict = joblib.load(join(sasc.config.RESULTS_DIR, 'pilot_story_data.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these function use absolute timing indexes rather than trimmed ones. This works out because they never have to reference the paragraph splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot annotated response curves and aggregate word_chunk_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [02:21<01:13, 36.82s/it]"
     ]
    }
   ],
   "source": [
    "word_chunk_deltas = []\n",
    "for story_num in tqdm(range(6)):\n",
    "    paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "    prompts = stories_data_dict[\"prompts\"]\n",
    "    t = deepcopy(stories_data_dict[\"timing\"][story_num])\n",
    "    # t['time_running'] = t['time_running'] - 10\n",
    "\n",
    "    # these must be passed same timing\n",
    "    word_chunks = analyze_helper._get_word_chunks(t)\n",
    "    # word_chunks = word_chunks[5:-5]\n",
    "    start_times, end_times = analyze_helper.get_start_end_indexes_for_paragraphs(\n",
    "        t, paragraphs)\n",
    "\n",
    "    # example_ngrams and word_chunks\n",
    "    ps = prompts[story_num]\n",
    "    example_ngrams_list = sum(\n",
    "        [analyze_helper.find_all_examples_within_quotes(x) for x in ps], []\n",
    "    )\n",
    "    word_chunks_contain_example_ngrams = np.zeros(len(word_chunks))\n",
    "    for i, wc in enumerate(word_chunks):\n",
    "        for ngram in example_ngrams_list:\n",
    "            if any([ngram in w for w in wc]):\n",
    "                word_chunks_contain_example_ngrams[i] = 1\n",
    "                break\n",
    "\n",
    "    # get resp curves\n",
    "    rows = stories_data_dict[\"rows\"][story_num]\n",
    "    voxel_nums = rows[\"voxel_num\"]\n",
    "    expls = rows[\"expl\"]\n",
    "    r_curves = resps_dict[\n",
    "        stories_data_dict[\"story_name_new\"][story_num].replace('_resps', '')\n",
    "    ].T[voxel_nums]\n",
    "\n",
    "    for voxel_num in range(17):\n",
    "        expl_voxel = expls[voxel_num]\n",
    "        voxel_resp = r_curves[voxel_num]\n",
    "        word_chunk_deltas.append(\n",
    "            sasc.analyze_helper.compute_word_chunk_deltas_for_single_paragraph(\n",
    "                start_times,\n",
    "                end_times,\n",
    "                voxel_resp,\n",
    "                word_chunks_contain_example_ngrams,\n",
    "                voxel_num,\n",
    "            ))\n",
    "        sasc.viz.plot_annotated_resp(\n",
    "            voxel_num,\n",
    "            word_chunks,\n",
    "            voxel_resp,\n",
    "            expl_voxel,\n",
    "            start_times,\n",
    "            end_times,\n",
    "            stories_data_dict,\n",
    "            expls,\n",
    "            story_num,\n",
    "            word_chunks_contain_example_ngrams,\n",
    "        )\n",
    "    analyze_helper.save_figs_to_single_pdf(\n",
    "        filename=join(sasc.config.RESULTS_DIR,\n",
    "                      f'pilot_plots/{stories_data_dict[\"story_name_new\"][story_num][3:-10]}_curves.pdf')\n",
    "    )\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "# Plot ngram delta\n",
    "means = []\n",
    "sems = []\n",
    "delta_offsets = [1, 2, 3, 4, 5]\n",
    "for i in delta_offsets:\n",
    "    deltas = sum([x[i] for x in word_chunk_deltas], [])\n",
    "    # plt.hist(deltas, label='Delta ' + str(i), alpha=0.5)\n",
    "    # plt.axvline(np.mean(deltas), linewidth=1, color=f'C{i - 1}')\n",
    "\n",
    "    means.append(np.mean(deltas))\n",
    "    sems.append(np.std(deltas) / np.sqrt(len(deltas)))\n",
    "    print(f'Delta {i} mean: {means[-1]:0.4f} +/- {sems[-1]:0.4f}')\n",
    "# plt.legend()\n",
    "\n",
    "# barplot of means\n",
    "delta_offsets = 2 * np.array(delta_offsets)\n",
    "plt.grid(zorder=-100)\n",
    "plt.bar(delta_offsets, means, color='C1', zorder=100, width=1.5)\n",
    "plt.errorbar(delta_offsets, means, yerr=sems,\n",
    "             fmt='o', color='black', zorder=101)\n",
    "plt.xticks(delta_offsets)\n",
    "plt.xlabel('Seconds after presentation of key ngram')\n",
    "plt.ylabel('Voxel response change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
