{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-21 18:44:59,208] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import sasc.viz\n",
    "from sasc import analyze_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num\n",
    "from sasc.config import FMRI_DIR, RESULTS_DIR\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "\n",
    "# pcs = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"loo_pc_UTS02.pkl\"))\n",
    "# pcs['good_voxels'].shape\n",
    "# pcs['pca_projections'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pilot_name = 'pilot_story_data.pkl'\n",
    "pilot_name = 'pilot3_story_data.pkl'\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(sasc.config.RESULTS_DIR, pilot_name))\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230504'\n",
    "elif pilot_name == 'pilot3_story_data.pkl':\n",
    "    pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20231106'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.87s/it]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(paragraphs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(rows)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m resp_chunks \u001b[39m=\u001b[39m analyze_helper\u001b[39m.\u001b[39mget_resps_for_paragraphs(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     timing, paragraphs, resp_story, offset\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(resp_chunks) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(paragraphs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# calculate mat\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrsandbox387.redmond.corp.microsoft.com/home/chansingh/automated-explanations/notebooks_stories/2_analyze_pilot/02_default.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(rows), \u001b[39mlen\u001b[39m(paragraphs)))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load responses\n",
    "default_story_idxs = np.where(\n",
    "    np.array(stories_data_dict['story_setting']) == 'default')[0]\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in default_story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}\n",
    "\n",
    "\n",
    "mats = defaultdict(list)\n",
    "use_clusters_list = [False, True]\n",
    "for use_clusters in use_clusters_list:\n",
    "    for story_num in default_story_idxs:\n",
    "        rows = stories_data_dict[\"rows\"][story_num]\n",
    "\n",
    "        # get resp_chunks\n",
    "        resp_story = resps_dict[\n",
    "            stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "                '_resps', '')\n",
    "        ].T  # (voxels, time)\n",
    "        timing = stories_data_dict[\"timing\"][story_num]\n",
    "        paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "        assert len(paragraphs) == len(rows)\n",
    "        resp_chunks = analyze_helper.get_resps_for_paragraphs(\n",
    "            timing, paragraphs, resp_story, offset=2)\n",
    "        assert len(resp_chunks) == len(paragraphs)\n",
    "\n",
    "        # calculate mat\n",
    "        mat = np.zeros((len(rows), len(paragraphs)))\n",
    "        for i in range(len(paragraphs)):\n",
    "            if use_clusters == False:\n",
    "                mat[:, i] = resp_chunks[i][rows[\"voxel_num\"].values].mean(\n",
    "                    axis=1)\n",
    "            elif use_clusters == True:\n",
    "                for r in range(len(rows)):\n",
    "                    cluster_nums = rows.iloc[r][\"cluster_nums\"]\n",
    "                    if isinstance(cluster_nums, np.ndarray):\n",
    "                        vals = resp_chunks[i][cluster_nums].flatten()\n",
    "                        mat[r, i] = np.nanmean(vals)\n",
    "                    else:\n",
    "                        # print(cluster_nums)\n",
    "                        mat[r, i] = np.nan\n",
    "        mat[:, 0] = np.nan  # ignore the first column\n",
    "        # print('mat', mat)\n",
    "\n",
    "        # sort by voxel_num\n",
    "        args = np.argsort(rows[\"voxel_num\"].values)\n",
    "        mat = mat[args, :][:, args]\n",
    "        mats[use_clusters].append(deepcopy(mat))\n",
    "\n",
    "        # plt.imshow(mat)\n",
    "        # plt.colorbar(label=\"Mean response\")\n",
    "        # plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "        # plt.ylabel(\"Voxel\")\n",
    "        # plt.title(f\"{story_data['story_name_new'][story_num][3:-10]}\")\n",
    "        # plt.show()\n",
    "rows = rows.sort_values(by=\"voxel_num\")\n",
    "expls = rows[\"expl\"].values\n",
    "\n",
    "\n",
    "m = {}\n",
    "for use_clusters in [False, True]:\n",
    "    mats[use_clusters] = np.array(mats[use_clusters])  # (6, 17, 17)\n",
    "    m[use_clusters] = np.nanmean(mats[use_clusters], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make average plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate means\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "\n",
    "n = m1.shape[0]\n",
    "diag_means = np.diag(m1)\n",
    "diag_mean = np.nanmean(diag_means)\n",
    "\n",
    "# get mean of each row excluding the diagonal\n",
    "off_diag_means = np.nanmean(m1, axis=1) - (diag_means / n)\n",
    "off_diag_mean = np.nanmean(off_diag_means)\n",
    "\n",
    "\n",
    "# make plot\n",
    "plt.figure(dpi=300)\n",
    "x = np.arange(n) - n / 2\n",
    "plt.bar(1, diag_mean, width=0.5, label='Diagonal', alpha=0.2, color='C0')\n",
    "plt.errorbar(1, diag_mean, yerr=np.nanstd(diag_means) / np.sqrt(len(diag_means)),\n",
    "             fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5, lw=1)\n",
    "plt.plot(1 + x/50, diag_means, '.', color='C0', alpha=0.9)\n",
    "\n",
    "plt.bar(2, off_diag_mean, width=0.5,\n",
    "        label='Off-diagonal', alpha=0.1, color='C1')\n",
    "plt.errorbar(2, off_diag_mean, yerr=np.nanstd(off_diag_means) / np.sqrt(len(off_diag_means)),\n",
    "             fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5)\n",
    "plt.plot(2 + x/50, off_diag_means, '.', color='C1')\n",
    "\n",
    "plt.xticks([1, 2], ['Driving paragraph', 'Baseline paragraphs'])\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# annotate the point with the highest mean\n",
    "kwargs = dict(\n",
    "    arrowprops=dict(arrowstyle='->', color='#333'), fontsize='x-small', color='#333'\n",
    ")\n",
    "idx = np.argmax(diag_means)\n",
    "print(expls[idx])\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]),\n",
    "             xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the second highest mean\n",
    "idx = np.argsort(diag_means)[-2]\n",
    "print(expls[idx])\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]),\n",
    "             xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the lowest mean\n",
    "idx = np.argmin(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]),\n",
    "             xytext=(1.1, diag_means[idx]), **kwargs)\n",
    "plt.tight_layout()\n",
    "print('mean', diag_mean - off_diag_mean)\n",
    "# plt.title(f'use_clusters={use_clusters}')\n",
    "plt.title('Single voxel')\n",
    "plt.savefig(join(RESULTS_DIR, 'figs',\n",
    "            pilot_name[:pilot_name.index('_')] + '_default_means.pdf'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between different voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: some voxels didn't have good clusters so they will be missing from these plots...\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "# cg = sns.clustermap(pd.DataFrame(m, columns=expls, index=expls), method='complete', cmap='viridis', figsize=(10, 10))\n",
    "# plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "# plt.xlabel('Driving paragraph')\n",
    "plt.figure(figsize=(6, 4), dpi=300)\n",
    "# m = softmax(m, axis=0)\n",
    "\n",
    "sasc.viz.outline_diagonal(m1.shape, color='black', lw=1, block_size=1)\n",
    "# for r in range(m1.shape[0]):\n",
    "#     for c in range(m1.shape[1]):\n",
    "#         # outline the diagonal\n",
    "#         if r == c:\n",
    "#             plt.plot([r - 0.5, r + 0.5], [c - 0.5, c - 0.5], color='gray', lw=1)\n",
    "#             plt.plot([r - 0.5, r + 0.5], [c + 0.5, c + 0.5], color='gray', lw=1)\n",
    "#             plt.plot([r - 0.5, r - 0.5], [c - 0.5, c + 0.5], color='gray', lw=1)\n",
    "#             plt.plot([r + 0.5, r + 0.5], [c - 0.5, c + 0.5], color='gray', lw=1)\n",
    "\n",
    "\n",
    "expls_order = analyze_helper.sort_expls_semantically(expls)\n",
    "m_plot = m1[expls_order][:, expls_order]  # [:, expls_order]\n",
    "# m_plot = m1\n",
    "sasc.viz.imshow_diverging(m_plot)\n",
    "plt.xlabel(\"Driving paragraph\\n(Ideally, diagonal should be brighter)\",\n",
    "           fontsize='x-small')\n",
    "plt.ylabel(\"Voxel\", fontsize='x-small')\n",
    "plt.yticks(labels=expls[expls_order], ticks=np.arange(\n",
    "    len(expls)), fontsize='x-small')\n",
    "plt.xticks(labels=expls[expls_order], ticks=np.arange(\n",
    "    len(expls)), rotation=90, fontsize='x-small')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(RESULTS_DIR, 'figs',\n",
    "            pilot_name[:pilot_name.index('_')] + '_default_heatmap.pdf'))\n",
    "plt.show()\n",
    "# plot correlations across all resps\n",
    "# resps_voxels = np.concatenate(\n",
    "#     [resps_dict[story_data[\"story_name_new\"][story_num]].T for story_num in [2, 3, 4]],\n",
    "#     axis=1,\n",
    "# )[rw[\"voxel_num\"].values]\n",
    "# corr = pd.DataFrame(resps_voxels.T, columns=expls).corr().round(2)\n",
    "# sns.clustermap(corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clusters = False\n",
    "mats1 = mats[use_clusters]\n",
    "\n",
    "d = defaultdict(list)\n",
    "for i in range(len(mats1)):\n",
    "    m = mats1[i]\n",
    "    d['driving'].append(np.nanmean(np.diag(m)))\n",
    "    d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "    d['story'].append(stories_data_dict['story_name_new'][i][3:-10])\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "# make barplot comparing driving and baseline\n",
    "df = df.melt(id_vars='story', value_vars=[\n",
    "             'driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "df = df.sort_values(by='story')\n",
    "sns.barplot(data=df, x='story', y='mean', hue='condition')\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.savefig(join(RESULTS_DIR, 'figs',\n",
    "            pilot_name[:pilot_name.index('_')] + '_default_story_breakdown.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stats\n",
    "rows[\"driving_score\"] = np.diag(m[False])\n",
    "rm = pd.read_pickle(join(RESULTS_DIR, \"fmri_results_merged.pkl\")).sort_values(\n",
    "    by=[\"stability_score\"], ascending=False\n",
    ")\n",
    "for k in [\"fmri_test_corr_llama\", \"top_score_normalized_llama\"]:\n",
    "    rows[k] = rows.apply(\n",
    "        lambda row: rm[\n",
    "            (rm.module_num == row.module_num) & (rm.subject == row.subject)\n",
    "        ].iloc[0][k],\n",
    "        axis=1,\n",
    "    ).values\n",
    "\n",
    "\n",
    "# make plot\n",
    "cols = [\n",
    "    \"driving_score\",\n",
    "    \"stability_score\",\n",
    "    \"top_score_normalized\",\n",
    "    \"top_score_normalized_llama\",\n",
    "    \"fmri_test_corr\",\n",
    "    \"fmri_test_corr_llama\",\n",
    "]\n",
    "sns.lmplot(data=rows, x=\"stability_score\", y=\"driving_score\")\n",
    "plt.text(\n",
    "    0.5,\n",
    "    0.8,\n",
    "    f\"p={rows[cols].corr().loc['stability_score', 'driving_score']:.2f}\",\n",
    "    transform=plt.gca().transAxes,\n",
    ")\n",
    "plt.ylabel(\"Driving score\")\n",
    "plt.xlabel(\"Stability score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(rows[cols + [\"expl\"]], kind=\"reg\")  # , hue='expl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
