{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import sasc.viz\n",
    "from sasc import analyze_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num\n",
    "from sasc import config\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "\n",
    "# pcs = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"loo_pc_UTS02.pkl\"))\n",
    "# pcs['good_voxels'].shape\n",
    "# pcs['pca_projections'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_name = 'pilot_story_data.pkl'\n",
    "# pilot_name = 'pilot3_story_data.pkl'\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(config.RESULTS_DIR, 'processed', pilot_name))\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20230504')\n",
    "elif pilot_name == 'pilot3_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20231106')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load responses\n",
    "default_story_idxs = np.where(\n",
    "    np.array(stories_data_dict['story_setting']) == 'default')[0]\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in default_story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}\n",
    "\n",
    "\n",
    "mats = defaultdict(list)\n",
    "if 'pilot3' in pilot_name:\n",
    "    use_clusters_list = [False]\n",
    "else:\n",
    "    use_clusters_list = [False, True]\n",
    "for use_clusters in use_clusters_list:\n",
    "    for story_num in default_story_idxs:\n",
    "        rows = stories_data_dict[\"rows\"][story_num]\n",
    "\n",
    "        # get resp_chunks\n",
    "        resp_story = resps_dict[\n",
    "            stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "                '_resps', '')\n",
    "        ].T  # (voxels, time)\n",
    "        timing = stories_data_dict[\"timing\"][story_num]\n",
    "        if 'paragraphs' in stories_data_dict.keys():\n",
    "            paragraphs = stories_data_dict[\"paragraphs\"][story_num]\n",
    "        else:\n",
    "            paragraphs = stories_data_dict[\"story_text\"][story_num].split(\n",
    "                \"\\n\\n\")\n",
    "        # paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "        if pilot_name in ['pilot3_story_data.pkl']:\n",
    "            paragraphs = [sasc.analyze_helper.remove_repeated_words(\n",
    "                p) for p in paragraphs]\n",
    "        assert len(paragraphs) == len(\n",
    "            rows), f\"{len(paragraphs)} != {len(rows)}\"\n",
    "        resp_chunks = analyze_helper.get_resps_for_paragraphs(\n",
    "            timing, paragraphs, resp_story, offset=2)\n",
    "        assert len(resp_chunks) <= len(paragraphs)\n",
    "\n",
    "        # calculate mat\n",
    "        mat = np.zeros((len(rows), len(paragraphs)))\n",
    "        for i in range(len(resp_chunks)):\n",
    "            if use_clusters == False:\n",
    "                mat[:, i] = resp_chunks[i][rows[\"voxel_num\"].values].mean(\n",
    "                    axis=1)\n",
    "            elif use_clusters == True:\n",
    "                for r in range(len(rows)):\n",
    "                    cluster_nums = rows.iloc[r][\"cluster_nums\"]\n",
    "                    if isinstance(cluster_nums, np.ndarray):\n",
    "                        vals = resp_chunks[i][cluster_nums].flatten()\n",
    "                        mat[r, i] = np.nanmean(vals)\n",
    "                    else:\n",
    "                        # print(cluster_nums)\n",
    "                        mat[r, i] = np.nan\n",
    "        mat[:, 0] = np.nan  # ignore the first column\n",
    "        # print('mat', mat)\n",
    "\n",
    "        # sort by voxel_num\n",
    "        args = np.argsort(rows[\"voxel_num\"].values)\n",
    "        mat = mat[args, :][:, args]\n",
    "        mats[use_clusters].append(deepcopy(mat))\n",
    "\n",
    "        # plt.imshow(mat)\n",
    "        # plt.colorbar(label=\"Mean response\")\n",
    "        # plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "        # plt.ylabel(\"Voxel\")\n",
    "        # plt.title(f\"{story_data['story_name_new'][story_num][3:-10]}\")\n",
    "        # plt.show()\n",
    "rows = rows.sort_values(by=\"voxel_num\")\n",
    "expls = rows[\"expl\"].values\n",
    "\n",
    "\n",
    "m = {}\n",
    "for use_clusters in [False, True]:\n",
    "    mats[use_clusters] = np.array(mats[use_clusters])  # (6, 17, 17)\n",
    "    m[use_clusters] = np.nanmean(mats[use_clusters], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make average plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate means\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "diag_means = np.diag(m1)\n",
    "off_diag_means = np.nanmean(m1, axis=1) - (diag_means / len(diag_means))\n",
    "sasc.viz.barplot_default([diag_means], [off_diag_means],\n",
    "                         pilot_name, expls, annot_points=False)\n",
    "joblib.dump({'diag_means': diag_means,\n",
    "            'off_diag_means': off_diag_means}, join(config.RESULTS_DIR, 'processed', pilot_name.replace('_story_data.pkl', '_default_means.pkl')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between different voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: some voxels didn't have good clusters so they will be missing from these plots...\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "\n",
    "sasc.viz.outline_diagonal(m1.shape, color='black', lw=1, block_size=1)\n",
    "\n",
    "s = 'small'\n",
    "expls_order = analyze_helper.sort_expls_semantically(expls, device='cuda')\n",
    "m_plot = m1[expls_order][:, expls_order]  # [:, expls_order]\n",
    "sasc.viz.imshow_diverging(m_plot, clab_size='medium')\n",
    "plt.xlabel(\"Driving paragraph\",  # \\n(Ideally, diagonal should be brighter)\",\n",
    "           fontsize='medium')\n",
    "\n",
    "# plt.ylabel(\"Voxel\", fontsize='x-small')\n",
    "# labs = expls[expls_order]\n",
    "\n",
    "plt.ylabel(\"Voxel number\", fontsize='medium')\n",
    "labs = [f'{i + 1:02d}' for i in range(len(expls_order))]\n",
    "for i in range(len(labs)):\n",
    "    print(labs[i], expls[expls_order[i]])\n",
    "\n",
    "plt.yticks(labels=labs, ticks=np.arange(\n",
    "    len(expls)), fontsize=s)\n",
    "plt.xticks(labels=labs, ticks=np.arange(\n",
    "    len(expls)), rotation=90, fontsize=s)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/main',\n",
    "            pilot_name[:pilot_name.index('_')] + '_default_heatmap.pdf'), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot correlations across all resps\n",
    "# resps_voxels = np.concatenate(\n",
    "#     [resps_dict[story_data[\"story_name_new\"][story_num]].T for story_num in [2, 3, 4]],\n",
    "#     axis=1,\n",
    "# )[rw[\"voxel_num\"].values]\n",
    "# corr = pd.DataFrame(resps_voxels.T, columns=expls).corr().round(2)\n",
    "# sns.clustermap(corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_df(mats1, melt=False):\n",
    "    d = defaultdict(list)\n",
    "    story_names = resp_np_files\n",
    "    for i in range(len(mats1)):\n",
    "        m = mats1[i]\n",
    "        d['driving'].append(np.nanmean(np.diag(m)))\n",
    "        d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "        d['story'].append(story_names[i].replace('.npy', ''))\n",
    "    d = pd.DataFrame.from_dict(d)\n",
    "    if melt:\n",
    "        d = d.melt(id_vars='story', value_vars=[\n",
    "            'driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "        d = d[d.condition == 'driving']\n",
    "    return d\n",
    "\n",
    "\n",
    "use_clusters = False\n",
    "mats1 = mats[use_clusters]\n",
    "story_scores_df = get_story_df(mats1)\n",
    "joblib.dump(story_scores_df, join(config.RESULTS_DIR, 'processed',\n",
    "            pilot_name.replace('_story_data.pkl', '_default_story_scores.pkl')))\n",
    "\n",
    "# sasc.viz.stories_barplot(story_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters vs non-clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"Blues\", 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pilot_name == 'pilot_story_data.pkl'\n",
    "df1 = get_story_df(mats[False], melt=True)\n",
    "df1['Setting'] = 'Single voxel'\n",
    "df2 = get_story_df(mats[True], melt=True)\n",
    "df2['Setting'] = 'Voxel cluster'\n",
    "df = pd.concat([df1, df2])\n",
    "df['story'] = df['story'].str.replace('GenStory', '')\n",
    "\n",
    "sns.barplot(data=df, x='story', y='mean',\n",
    "            hue='Setting',\n",
    "            width=0.8,\n",
    "            palette=[sns.color_palette(\"Blues\", 3)[0], 'lightgray'],\n",
    "            )\n",
    "plt.xlabel(\"Story\")\n",
    "plt.ylabel('Mean driving voxel response ($\\sigma_f$)')\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/misc',\n",
    "            'cluster_vs_single_default_story_breakdown.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good prompt vs bad prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pilot_name == 'pilot_story_data.pkl'\n",
    "df = get_story_df(mats[False], melt=True)\n",
    "good_prompt = ['GenStory2', 'GenStory3', 'GenStory4']\n",
    "df['Prompt'] = df.apply(lambda x: x['story'] in good_prompt, axis=1)\n",
    "df['Prompt'] = df['Prompt'].map(\n",
    "    {True: 'Prompt version 1', False: 'Prompt version 0'})\n",
    "df = df.sort_values(by='Prompt', ascending=False)\n",
    "df['story'] = df['story'].str.replace('GenStory', '')\n",
    "\n",
    "\n",
    "# shade bars by prompt version\n",
    "offset = 0\n",
    "xticklabels = []\n",
    "for i, prompt in enumerate(df['Prompt'].unique()):\n",
    "    d = df[df['Prompt'] == prompt]\n",
    "    d = d.sort_values('story')\n",
    "    plt.bar(np.arange(len(d)) + offset, d['mean'], label=prompt,\n",
    "            color=sns.color_palette(\"Blues\", 3)[0], hatch='' if i == 0 else '//')\n",
    "    xticklabels += d['story'].tolist()\n",
    "    offset += len(d)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Story\")\n",
    "plt.ylabel('Mean driving voxel response ($\\sigma_f$)')\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/misc',\n",
    "            'prompt_default_story_breakdown.pdf'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stats\n",
    "def save_voxel_scores(m, rows, pilot_name):\n",
    "    rows[\"driving_score\"] = np.diag(m[False])\n",
    "    rm = pd.read_pickle(join(config.RESULTS_DIR, 'sasc', \"fmri_results_merged.pkl\")).sort_values(\n",
    "        by=[\"stability_score\"], ascending=False\n",
    "    )\n",
    "    for k in [\"fmri_test_corr_llama\", \"top_score_normalized_llama\"]:\n",
    "        rows[k] = rows.apply(\n",
    "            lambda row: rm[\n",
    "                (rm.module_num == row.module_num) & (rm.subject == row.subject)\n",
    "            ].iloc[0][k],\n",
    "            axis=1,\n",
    "        ).values\n",
    "    cols = [\"expl\", \"driving_score\", \"stability_score\", \"top_score_normalized\", \"top_score_normalized_llama\",\n",
    "            \"fmri_test_corr\", \"fmri_test_corr_llama\"]\n",
    "    voxel_scores = rows[cols]\n",
    "    joblib.dump(voxel_scores, join(config.RESULTS_DIR, 'processed',\n",
    "                pilot_name.replace('_story_data.pkl', '_default_voxel_scores.pkl')))\n",
    "\n",
    "\n",
    "save_voxel_scores(m, rows, pilot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(rows[cols + [\"expl\"]], kind=\"reg\")  # , hue='expl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
