{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import sasc.analyze_helper\n",
    "# from sasc.modules.fmri_module import convert_module_num_to_voxel_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: not sure these are properly adjusted for the trim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_name = 'pilot2_story_data.pkl'\n",
    "# pilot_name = 'pilot3_story_data.pkl'\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(sasc.config.RESULTS_DIR, 'processed', pilot_name))\n",
    "if pilot_name == 'pilot2_story_data.pkl':\n",
    "    pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230702'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load responses\n",
    "interaction_story_idxs = np.where(\n",
    "    np.array(stories_data_dict['story_setting']) == 'interactions')[0]\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in interaction_story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp_chunks_list(stories_data_dict, resps_dict, interaction_story_idxs):\n",
    "    resp_chunks_list = []\n",
    "    for story_num in interaction_story_idxs:\n",
    "        story_metadata = stories_data_dict[\"rows\"][story_num]\n",
    "        resp_story = resps_dict[\n",
    "            stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "                '_resps', '')\n",
    "        ].T  # (voxels, time)\n",
    "        timing = stories_data_dict[\"timing\"][story_num]\n",
    "        if 'paragraphs' in stories_data_dict.keys():\n",
    "            paragraphs = stories_data_dict[\"paragraphs\"][story_num]\n",
    "        else:\n",
    "            paragraphs = stories_data_dict[\"story_text\"][story_num].split(\n",
    "                \"\\n\\n\")\n",
    "        # paragraphs = stories_data_dict[\"paragraphs\"][story_num]\n",
    "        assert len(paragraphs) == len(story_metadata)\n",
    "        resp_chunks = sasc.analyze_helper.get_resps_for_paragraphs(\n",
    "            timing, paragraphs, resp_story, offset=2, apply_offset=False)\n",
    "        resps_one = resp_chunks[1::3]\n",
    "        resps_both = resp_chunks[2::3]\n",
    "        resps_two = resp_chunks[3::3]\n",
    "\n",
    "        expl1 = np.array(stories_data_dict['expl1'][story_num].values)\n",
    "        expl2 = np.array(stories_data_dict['expl2'][story_num].values)\n",
    "        voxel_num1 = stories_data_dict['voxel_num1'][story_num].values\n",
    "        voxel_num2 = stories_data_dict['voxel_num2'][story_num].values\n",
    "        args = np.argsort(expl1)\n",
    "\n",
    "        print(args, expl1)\n",
    "        expl1 = expl1[args]\n",
    "        expl2 = expl2[args]\n",
    "        voxel_num1 = voxel_num1[args]\n",
    "        voxel_num2 = voxel_num2[args]\n",
    "        resps_one = [resps_one[a] for a in args]\n",
    "        resps_both = [resps_both[a] for a in args]\n",
    "        resps_two = [resps_two[a] for a in args]\n",
    "        resp_chunks_list.append(\n",
    "            (resps_one, resps_both, resps_two))\n",
    "\n",
    "    return resp_chunks_list, expl1, expl2, voxel_num1, voxel_num2\n",
    "\n",
    "\n",
    "resp_chunks_list_full, expl1, expl2, voxel_num1, voxel_num2 = get_resp_chunks_list(\n",
    "    stories_data_dict, resps_dict, interaction_story_idxs)\n",
    "# resp_chunks_arr = np.array(resp_chunks_list).mean(axis=0)\n",
    "# expls = stories_data_dict[\"rows\"][0]  # .sort_values(by=\"expl\")[\"expl\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(resp_chunks_list, expls):\n",
    "    resps_rep_means = []\n",
    "    resps_rep_all = []\n",
    "    C = 6\n",
    "    R = 3\n",
    "    viz_mean = True\n",
    "    # resp_chunks_list (n_stories, n_voxels (driving), n_voxels (resp), n_time)\n",
    "    n_voxels = len(resp_chunks_list[0])\n",
    "    n_stories = len(resp_chunks_list)\n",
    "    for voxel_num in range(n_voxels):\n",
    "        plt.subplot(R, C, voxel_num + 1)\n",
    "        resps_rep = []\n",
    "        for story_num in range(n_stories):\n",
    "            # print(resp_chunks_list[story_num][voxel_num])\n",
    "            resps_rep.append(resp_chunks_list[story_num][voxel_num][voxel_num])\n",
    "        resps_rep = sorted(resps_rep, key=lambda x: len(x))\n",
    "\n",
    "        # interpolate each story to 100 time points\n",
    "        resps_rep_interp = []\n",
    "        for resp_rep in resps_rep:\n",
    "            resps_rep_interp.append(\n",
    "                np.interp(np.linspace(0, 1, 100), np.linspace(0, 1, len(resp_rep)),\n",
    "                          resp_rep))\n",
    "        resps_rep_interp = np.array(resps_rep_interp)\n",
    "        resps_rep_mean = np.nanmean(resps_rep_interp, axis=0)\n",
    "\n",
    "        # print('shape', resps_rep_mean.shape)\n",
    "        if viz_mean:\n",
    "            plt.plot(resps_rep_mean, color='gray', alpha=0.5)\n",
    "            plt.axhline(0, color='gray', linestyle='--')\n",
    "            plt.ylim(-1, 1)\n",
    "\n",
    "            if voxel_num < C * (R - 1):\n",
    "                plt.xticks([])\n",
    "            else:\n",
    "                plt.xticks([0, 100], ['Start', 'End'])\n",
    "        else:\n",
    "            cmap = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "            for i, resp in enumerate(resps_rep):\n",
    "                plt.plot(resp, color=cmap(i / len(resps_rep)), alpha=0.5)\n",
    "            plt.ylim(-3, 3)\n",
    "\n",
    "        if voxel_num % C != 0:\n",
    "            plt.yticks([])\n",
    "        else:\n",
    "            plt.ylabel('Mean response')\n",
    "\n",
    "        resps_rep_means.append(resps_rep_mean)\n",
    "        resps_rep_all.append(resps_rep)\n",
    "        plt.title(expls[voxel_num], fontsize='small')\n",
    "\n",
    "    plt.subplot(R, C, voxel_num + 2)\n",
    "    plt.title('Mean', color='C0')\n",
    "    plt.plot(np.array(resps_rep_means).mean(axis=0), color='C0')\n",
    "    plt.grid()\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xticks([0, 100], ['Start', 'End'])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# n_stories = 1\n",
    "# plt.figure(figsize=(13, 6), dpi=300)\n",
    "# resp_chunks_list = [resp_chunks_list_full[i][0]\n",
    "#                     for i in range(len(resp_chunks_list_full))]\n",
    "# expls = expl1\n",
    "# resp_chunks_list = [resp_chunks_list_full[i][1]\n",
    "#                     for i in range(len(resp_chunks_list_full))]\n",
    "# expls = expl1\n",
    "# make_plot(resp_chunks_list, expls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_chunks(resp_chunks_list_full):\n",
    "    # interpolate each story to 100 time points\n",
    "    \n",
    "    # story_num x 3 x paragraph_num x voxel_num x time -> 3 x paragraph_num x voxel_num x time\n",
    "    resp_chunks_list = []\n",
    "    for \n",
    "    for paragraph_num in \n",
    "\n",
    "\n",
    "    resps_rep = []\n",
    "    for story_num in range(len(resp_chunks_list_full)):\n",
    "        #     # print(resp_chunks_list[story_num][voxel_num])\n",
    "        resps_rep.append(\n",
    "            resp_chunks_list_full[story_num][0][paragraph_num][v1])\n",
    "\n",
    "\n",
    "avg = average_chunks(resp_chunks_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_interpolated_lists(resps_rep):\n",
    "    resps_rep = sorted(resps_rep, key=lambda x: len(x))\n",
    "    resps_rep = [x for x in resps_rep if len(x) > 0]\n",
    "    resps_rep_interp = []\n",
    "    for resp_rep in resps_rep:\n",
    "        resps_rep_interp.append(\n",
    "            np.interp(np.linspace(0, 1, 100), np.linspace(0, 1, len(resp_rep)),\n",
    "                      resp_rep))\n",
    "    resps_rep_interp = np.array(resps_rep_interp)\n",
    "    resps_rep_mean = np.nanmean(resps_rep_interp, axis=0)\n",
    "    return resps_rep_mean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_num = 1\n",
    "paragraph_num = 2\n",
    "# for story_num in range(2):\n",
    "for paragraph_num in range(5):\n",
    "    plt.figure(figsize=(4, 2.5))\n",
    "    [one, both, two] = resp_chunks_list_full[story_num]\n",
    "    v1 = voxel_num1[paragraph_num]\n",
    "    v2 = voxel_num2[paragraph_num]\n",
    "\n",
    "    n = len(one[paragraph_num][v1])\n",
    "    c0 = 'C0'\n",
    "    c1 = 'salmon'\n",
    "    vals_v1 = [avg_interpolated_lists([resp_chunks_list_full[0][i][paragraph_num]\n",
    "                                      [v1], resp_chunks_list_full[1][i][paragraph_num][v1]]) for i in range(3)]\n",
    "    vals_v2 = [avg_interpolated_lists([resp_chunks_list_full[0][i][paragraph_num]\n",
    "                                       [v2], resp_chunks_list_full[1][i][paragraph_num][v2]]) for i in range(3)]\n",
    "\n",
    "    #\n",
    "    n = 0\n",
    "    plt.plot(np.concatenate(vals_v1), color=c0)\n",
    "    plt.plot(np.concatenate(vals_v2), color=c1)\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    for i in range(3):\n",
    "        offset = len(vals_v1[i])\n",
    "        kwargs = dict(\n",
    "            alpha=0.5,\n",
    "            lw=2\n",
    "        )\n",
    "        trim = 10\n",
    "        colors = ['C0', '#5D3F6A', 'salmon']\n",
    "        if trim > 0:\n",
    "            plt.plot([n + trim, n + offset - trim], [np.mean(vals_v1[i]),\n",
    "                     np.mean(vals_v1[i])], color=c0, **kwargs)\n",
    "            plt.plot([n + trim, n + offset - trim], [np.mean(vals_v2[i]),\n",
    "                     np.mean(vals_v2[i])], color=c1, **kwargs)\n",
    "            # fill range without changing ylim\n",
    "            # get current ylim\n",
    "\n",
    "            plt.fill_between([n + trim, n + offset - trim], -\n",
    "                             100, 100, color=colors[i], alpha=0.075)\n",
    "            # plt.ylim(ylim)\n",
    "        else:\n",
    "            plt.plot([n, n + offset], [np.mean(vals_v1[i]),\n",
    "                     np.mean(vals_v1[i])], color=c0, **kwargs)\n",
    "            plt.plot([n, n + offset], [np.mean(vals_v2[i]),\n",
    "                     np.mean(vals_v2[i])], color=c1, **kwargs)\n",
    "\n",
    "        n += offset\n",
    "    # plt.plot(sums, color='gray')\n",
    "    # plt.axhline(0, color='gray', linestyle='--')\n",
    "    plt.ylim(ylim)\n",
    "    # remove xticks and yticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # add all splines\n",
    "    plt.gca().spines['top'].set_visible(True)\n",
    "    plt.gca().spines['right'].set_visible(True)\n",
    "    # make splines thicker\n",
    "    for k in ['top', 'right', 'left', 'bottom']:\n",
    "        plt.gca().spines[k].set_linewidth(1.5)\n",
    "    plt.savefig(f'plot_{paragraph_num}.pdf', bbox_inches='tight')\n",
    "\n",
    "    # plt.title(\n",
    "    # f\"Story {story_num}, paragraph {paragraph_num} expl1 {expl1[paragraph_num]} expl2 {expl2[paragraph_num]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_interpolated_lists([resp_chunks_list_full[0][1][paragraph_num]\n",
    "                        [v1], resp_chunks_list_full[1][1][paragraph_num][v1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resps_list = sum(resps_rep_all, [])\n",
    "lens = np.array([len(x) for x in resps_list])\n",
    "print('mean resp', np.nanmean(np.concatenate(resps_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a couple for the intro fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2.5))\n",
    "plt.plot(resps_rep_means[5], '-', color='#08b47c', lw=3)\n",
    "plt.axhline(0, color='gray', linestyle='--', lw=3)\n",
    "plt.axhline(np.mean(resps_rep_means[5]), color='#08b47c', linestyle='--', lw=3)\n",
    "# plt.ylim(-2, 2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "# turn on all splines\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(True)\n",
    "\n",
    "    # make spline thick\n",
    "    spine.set_linewidth(3)\n",
    "plt.savefig(join(sasc.config.RESULTS_DIR, 'figs',\n",
    "            'misc', 'food_prep_avg_driving_resp.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2.5))\n",
    "plt.plot(resps_rep_means[7], '-', color='#705cac', lw=3)\n",
    "plt.axhline(0, color='gray', linestyle='--', lw=3)\n",
    "plt.axhline(np.mean(resps_rep_means[7]), color='#705cac', linestyle='--', lw=3)\n",
    "# plt.ylim(-2, 2)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "# turn on all splines\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(True)\n",
    "\n",
    "    # make spline thick\n",
    "    spine.set_linewidth(3)\n",
    "plt.savefig(join(sasc.config.RESULTS_DIR, 'figs',\n",
    "            'misc', 'laughter_avg_driving_resp.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis by TR length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_means_by_len = []\n",
    "counts_by_len = []\n",
    "resp_means_by_len_5 = []\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "for i, x in enumerate(np.unique(lens)):\n",
    "    resp_mean = np.zeros(x)\n",
    "    count = 0\n",
    "    for resp in resps_list:\n",
    "        if len(resp) == x:\n",
    "            resp_mean += resp\n",
    "            count += 1\n",
    "    counts_by_len.append(count)\n",
    "    resp_mean /= count\n",
    "    plt.plot(resp_mean, label=x, color=cmap(\n",
    "        i / len(np.unique(lens))), alpha=0.5, lw=3)\n",
    "    resp_means_by_len.append(np.mean(resp_mean))\n",
    "    resp_means_by_len_5.append(np.mean(resp_mean[5:]))\n",
    "plt.ylabel('Mean response')\n",
    "plt.xlabel('TRs')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(\n",
    "    {\"Paragraph length (TRs)\": np.unique(lens), \"Count\": counts_by_len, \"Response mean\": resp_means_by_len,\n",
    "     'Response mean (excluding 1st 5 TRs)': resp_means_by_len_5}\n",
    ").round(2)\n",
    "out.style.format(precision=2).background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Paragraph length (TRs)'] <\n",
    "    23]['Response mean (excluding 1st 5 TRs)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['Paragraph length (TRs)'] >=\n",
    "    23]['Response mean (excluding 1st 5 TRs)'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
