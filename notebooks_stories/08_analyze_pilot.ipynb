{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import story_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_mapping = {\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v4_noun___seed=1\": \"GenStory1_resps.npy\",\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v4_noun___seed=3\": \"GenStory2_resps.npy\",\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v4_noun___seed=4\": \"GenStory3_resps.npy\",\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v5_noun___seed=1\": \"GenStory4_resps.npy\",\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v5_noun___seed=2\": \"GenStory5_resps.npy\",\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v5_noun___seed=4\": \"GenStory6_resps.npy\",\n",
    "}\n",
    "\n",
    "STORIES_DIR = join(sasc.config.RESULTS_DIR, \"pilot_v1\")\n",
    "story_names = story_mapping.keys()  # os.listdir(STORIES_DIR)\n",
    "\n",
    "story_data = defaultdict(list)\n",
    "for story_name in story_names:\n",
    "    story_data[\"timing\"].append(\n",
    "        pd.read_csv(join(STORIES_DIR, story_name, \"timings_processed.csv\"))\n",
    "    )\n",
    "    story_data[\"story_name_original\"].append(story_name)\n",
    "    story_data[\"story_name_new\"].append(story_mapping[story_name])\n",
    "    story_data[\"story_text\"].append(\n",
    "        open(join(STORIES_DIR, story_name, \"story.txt\"), \"r\").read()\n",
    "    )\n",
    "    story_data[\"prompts\"].append(\n",
    "        open(join(STORIES_DIR, story_name, \"prompts.txt\"), \"r\").read().split(\"\\n\\n\")\n",
    "    )\n",
    "\n",
    "    # rows\n",
    "    rows = pd.read_csv(join(STORIES_DIR, story_name, \"rows.csv\"))\n",
    "    rows[\"voxel_num\"] = rows.apply(\n",
    "        lambda row: convert_module_num_to_voxel_num(row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    rows = rows[\n",
    "        [\n",
    "            \"expl\",\n",
    "            \"module_num\",\n",
    "            \"top_explanation_init_strs\",\n",
    "            \"subject\",\n",
    "            \"fmri_test_corr\",\n",
    "            \"top_score_synthetic\",\n",
    "            \"roi_anat\",\n",
    "            \"roi_func\",\n",
    "            \"voxel_num\",\n",
    "        ]\n",
    "    ]\n",
    "    story_data[\"rows\"].append(rows)\n",
    "joblib.dump(story_data, \"../results/pilot_story_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and corresponding resps\n",
    "pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230504'\n",
    "resp_np_files = sorted(os.listdir(pilot_data_dir))\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "\n",
    "for story_num in [0, 1, 2, 3, 4, 5]:\n",
    "    rows = story_data[\"rows\"][story_num]  \n",
    "\n",
    "    # get resp_chunks\n",
    "    resp_story = resps_dict[story_data[\"story_name_new\"][story_num]].T  # (voxels, time)\n",
    "    timing = story_data[\"timing\"][story_num]\n",
    "    paragraphs = story_data[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "    assert len(paragraphs) == len(rows)\n",
    "    resp_chunks = story_helper.get_resp_chunks(timing, paragraphs, resp_story)\n",
    "\n",
    "    # calculate mat\n",
    "    mat = np.zeros((len(rows), len(paragraphs)))\n",
    "    for i in range(len(paragraphs)):\n",
    "        mat[:, i] = resp_chunks[i][rows[\"voxel_num\"].values].mean(axis=1)\n",
    "    mat[:, 0] = np.nan # ignore the first column\n",
    "    \n",
    "    # sort by voxel_num\n",
    "    args = np.argsort(rows[\"voxel_num\"].values)\n",
    "    mat = mat[args, :][:, args]\n",
    "    mats.append(deepcopy(mat))\n",
    "\n",
    "    # plt.imshow(mat)\n",
    "    # plt.colorbar(label=\"Mean response\")\n",
    "    # plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "    # plt.ylabel(\"Voxel\")\n",
    "    # plt.title(f\"{story_data['story_name_new'][story_num][3:-10]}\")\n",
    "    # plt.show()\n",
    "expls = rows.sort_values(by=\"voxel_num\")[\"expl\"].values\n",
    "\n",
    "mats = np.array(mats)  # (6, 17, 17)\n",
    "m = np.nanmean(mats, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make average plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = m.shape[0]\n",
    "diag_means = np.diag(m)\n",
    "diag_mean = np.nanmean(diag_means)\n",
    "\n",
    "# get mean of each row excluding the diagonal\n",
    "off_diag_means = m.mean(axis=1) - (diag_means / n)\n",
    "off_diag_mean = off_diag_means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(n) - n / 2\n",
    "\n",
    "plt.bar(1, diag_mean, width=0.5, label='Diagonal', alpha=0.1, color='C0')\n",
    "plt.errorbar(1, diag_mean, yerr=diag_means.std() / np.sqrt(len(diag_means)), fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5, lw=1)\n",
    "plt.plot(1 + x/50, diag_means, '.', color='C0', alpha=0.5)\n",
    "\n",
    "plt.bar(2, off_diag_mean, width=0.5, label='Off-diagonal', alpha=0.1, color='C1')\n",
    "plt.errorbar(2, off_diag_mean, yerr=off_diag_means.std() / np.sqrt(len(off_diag_means)), fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5)\n",
    "plt.plot(2 + x/50, off_diag_means, '.', color='C1')\n",
    "\n",
    "plt.xticks([1, 2], ['Driving paragraph', 'Baseline paragraphs'])\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# annotate the point with the highest mean\n",
    "kwargs = dict(\n",
    "    arrowprops=dict(arrowstyle='->', color='#333'), fontsize='x-small', color='#333'\n",
    ")\n",
    "idx = np.argmax(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the second highest mean\n",
    "idx = np.argsort(diag_means)[-2]\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the lowest mean\n",
    "idx = np.argmin(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx]), **kwargs)\n",
    "plt.tight_layout()\n",
    "print('mean', diag_mean - off_diag_mean)\n",
    "plt.savefig('../results/pilot_means.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between different voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cg = sns.clustermap(pd.DataFrame(m, columns=expls, index=expls), method='complete', cmap='viridis', figsize=(10, 10))\n",
    "# plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "# plt.xlabel('Driving paragraph')\n",
    "plt.figure(figsize=(6, 6))\n",
    "# m = softmax(m, axis=0)\n",
    "\n",
    "\n",
    "for r in range(m.shape[0]):\n",
    "    for c in range(m.shape[1]):\n",
    "        # outline the diagonal\n",
    "        if r == c:\n",
    "            plt.plot([r - 0.5, r + 0.5], [c - 0.5, c - 0.5], color='gray', lw=1)\n",
    "            plt.plot([r - 0.5, r + 0.5], [c + 0.5, c + 0.5], color='gray', lw=1)\n",
    "            plt.plot([r - 0.5, r - 0.5], [c - 0.5, c + 0.5], color='gray', lw=1)\n",
    "            plt.plot([r + 0.5, r + 0.5], [c - 0.5, c + 0.5], color='gray', lw=1)\n",
    "        \n",
    "\n",
    "\n",
    "plt.imshow(m)\n",
    "plt.xlabel(\"Driving paragraph\\n(Ideally, diagonal should be brighter)\", fontsize='x-small')\n",
    "plt.ylabel(\"Voxel\", fontsize='x-small')\n",
    "plt.yticks(labels=expls, ticks=np.arange(len(expls)), fontsize='x-small')\n",
    "plt.xticks(labels=expls, ticks=np.arange(len(expls)), rotation=90, fontsize='x-small')\n",
    "plt.show()\n",
    "\n",
    "# plot correlations across all resps\n",
    "# resps_voxels = np.concatenate(\n",
    "#     [resps_dict[story_data[\"story_name_new\"][story_num]].T for story_num in [2, 3, 4]],\n",
    "#     axis=1,\n",
    "# )[rw[\"voxel_num\"].values]\n",
    "# corr = pd.DataFrame(resps_voxels.T, columns=expls).corr().round(2)\n",
    "# sns.clustermap(corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "for i in range(len(mats)):\n",
    "    m = mats[i]\n",
    "    d['driving'].append(np.nanmean(np.diag(m)))\n",
    "    d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "    d['story'].append(story_data['story_name_new'][i][3:-10])\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "# make barplot comparing driving and baseline\n",
    "df = df.melt(id_vars='story', value_vars=['driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "df = df.sort_values(by='story')\n",
    "sns.barplot(data=df, x='story', y='mean', hue='condition')\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = rw.sort_values(by=\"voxel_num\")\n",
    "rw['mean_resp_diff'] = diag_means # - off_diag_means\n",
    "\n",
    "# ax = sns.pairplot(rw, vars=['mean_resp_diff', 'top_score_synthetic', 'fmri_test_corr'], hue='expl')\n",
    "# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1.01, 1))\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rw['top_score_synthetic'], rw['mean_resp_diff'], 'o')\n",
    "plt.ylabel('Mean voxel response')\n",
    "plt.xlabel('Synthetic score')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rw['fmri_test_corr'], rw['mean_resp_diff'], 'o')\n",
    "plt.xlabel('Predicted test correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
