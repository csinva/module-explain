{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import story_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and corresponding resps\n",
    "pilot_data_dir = '/home/chansingh/mntv1/deep-fMRI/story_data/20230504'\n",
    "resp_np_files = os.listdir(pilot_data_dir)\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}\n",
    "\n",
    "story_mapping = {\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v4_noun___seed=3\": 'GenStory2_resps.npy',\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v5_noun___seed=4\": 'GenStory6_resps.npy',\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v5_noun___seed=1\": 'GenStory4_resps.npy',\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v5_noun___seed=2\": 'GenStory5_resps.npy',\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v4_noun___seed=4\": 'GenStory3_resps.npy',\n",
    "    \"uts02_pilot_gpt4_mar28___ver=v4_noun___seed=1\": 'GenStory1_resps.npy',\n",
    "}\n",
    "\n",
    "STORIES_DIR = join(sasc.config.RESULTS_DIR, 'pilot_v1')\n",
    "story_names = story_mapping.keys() # os.listdir(STORIES_DIR)\n",
    "\n",
    "story_data = defaultdict(list)\n",
    "for story_name in story_names:\n",
    "    story_data['timing'].append(pd.read_csv(join(STORIES_DIR, story_name, 'timings_processed.csv')))\n",
    "    story_data['story_name_original'].append(story_name)\n",
    "    story_data['story_name_new'].append(story_mapping[story_name])\n",
    "    story_data['story_text'].append(open(join(STORIES_DIR, story_name, 'story.txt'), 'r').read())    \n",
    "    story_data['rows'].append(pd.read_csv(join(STORIES_DIR, story_name, 'rows.csv')))\n",
    "joblib.dump(story_data, '../results/pilot_story_data.pkl')\n",
    "    # print(story_name, story_data['timing'][-1]['time_running'].round(1).max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "\n",
    "for story_num in [0, 1, 2, 3, 4, 5]:\n",
    "    rows = story_data[\"rows\"][story_num]\n",
    "    rw = rows[\n",
    "        [\n",
    "            \"expl\",\n",
    "            \"module_num\",\n",
    "            \"top_explanation_init_strs\",\n",
    "            \"subject\",\n",
    "            \"fmri_test_corr\",\n",
    "            \"top_score_synthetic\",\n",
    "            \"roi_anat\",\n",
    "            \"roi_func\",\n",
    "        ]\n",
    "    ]\n",
    "    rw[\"voxel_num\"] = rw.apply(\n",
    "        lambda row: convert_module_num_to_voxel_num(row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    paragraphs = story_data[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "    assert len(paragraphs) == len(rw), (len(paragraphs), len(rw))\n",
    "    timing = story_data[\"timing\"][story_num]\n",
    "\n",
    "    resp_story = resps_dict[story_data[\"story_name_new\"][story_num]].T  # (voxels, time)\n",
    "    resp_chunks = story_helper.get_resp_chunks(timing, paragraphs, resp_story)\n",
    "    voxel_nums = rw[\"voxel_num\"].values\n",
    "\n",
    "    mat = np.zeros((len(rw), len(paragraphs)))\n",
    "    for i in range(len(paragraphs)):\n",
    "        mat[:, i] = resp_chunks[i][voxel_nums].mean(axis=1)\n",
    "\n",
    "    # visualize (ignore the first column)\n",
    "    mat[:, 0] = np.nan\n",
    "    # mat = softmax(mat, axis=0)\n",
    "\n",
    "    args = np.argsort(rw[\"voxel_num\"].values)\n",
    "    mat = mat[args, :][:, args]\n",
    "    mats.append(deepcopy(mat))\n",
    "\n",
    "    plt.imshow(mat)\n",
    "    plt.colorbar(label=\"Mean response\")\n",
    "    plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "    plt.ylabel(\"Voxel\")\n",
    "    plt.title(f\"{story_data['story_name_new'][story_num][3:-10]}\")\n",
    "    plt.show()\n",
    "expls = rw.sort_values(by=\"voxel_num\")[\"expl\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make average plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = np.array(mats) # (6, 17, 17)\n",
    "m = np.nanmean(mats, axis=0)\n",
    "n = m.shape[0]\n",
    "diag_means = np.diag(m)\n",
    "diag_mean = np.nanmean(diag_means)\n",
    "\n",
    "# get mean of each row excluding the diagonal\n",
    "off_diag_means = m.mean(axis=1) - (diag_means / n)\n",
    "off_diag_mean = off_diag_means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(n) - n / 2\n",
    "\n",
    "plt.bar(1, diag_mean, width=0.5, label='Diagonal', alpha=0.1, color='C0')\n",
    "plt.errorbar(1, diag_mean, yerr=diag_means.std() / np.sqrt(len(diag_means)), fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5, lw=1)\n",
    "plt.plot(1 + x/50, diag_means, '.', color='C0', alpha=0.5)\n",
    "\n",
    "plt.bar(2, off_diag_mean, width=0.5, label='Off-diagonal', alpha=0.1, color='C1')\n",
    "plt.errorbar(2, off_diag_mean, yerr=off_diag_means.std() / np.sqrt(len(off_diag_means)), fmt='.', label='Diagonal', ms=0, color='black', elinewidth=3, capsize=5)\n",
    "plt.plot(2 + x/50, off_diag_means, '.', color='C1')\n",
    "\n",
    "plt.xticks([1, 2], ['Driving paragraph', 'Baseline paragraphs'])\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# annotate the point with the highest mean\n",
    "kwargs = dict(\n",
    "    arrowprops=dict(arrowstyle='->', color='#333'), fontsize='x-small', color='#333'\n",
    ")\n",
    "idx = np.argmax(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the second highest mean\n",
    "idx = np.argsort(diag_means)[-2]\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx] + 0.1), **kwargs)\n",
    "\n",
    "# annotate the point with the lowest mean\n",
    "idx = np.argmin(diag_means)\n",
    "plt.annotate(f\"{expls[idx]}\", (1 + x[idx]/50, diag_means[idx]), xytext=(1.1, diag_means[idx]), **kwargs)\n",
    "plt.tight_layout()\n",
    "print('mean', diag_mean - off_diag_mean)\n",
    "plt.savefig('../results/pilot_means.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({'mean_resp': diag_means, 'expl': expls}).sort_values('mean_resp')[::-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "for i in range(len(mats)):\n",
    "    m = mats[i]\n",
    "    d['driving'].append(np.nanmean(np.diag(m)))\n",
    "    d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "    d['story'].append(story_data['story_name_new'][i][3:-10])\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "# make barplot comparing driving and baseline\n",
    "df = df.melt(id_vars='story', value_vars=['driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "df = df.sort_values(by='story')\n",
    "sns.barplot(data=df, x='story', y='mean', hue='condition')\n",
    "plt.ylabel('Mean voxel response ($\\sigma_f$)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = rw.sort_values(by=\"voxel_num\")\n",
    "rw['mean_resp_diff'] = diag_means # - off_diag_means\n",
    "\n",
    "# ax = sns.pairplot(rw, vars=['mean_resp_diff', 'top_score_synthetic', 'fmri_test_corr'], hue='expl')\n",
    "# sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1.01, 1))\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rw['top_score_synthetic'], rw['mean_resp_diff'], 'o')\n",
    "plt.ylabel('Mean voxel response')\n",
    "plt.xlabel('Synthetic score')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rw['fmri_test_corr'], rw['mean_resp_diff'], 'o')\n",
    "plt.xlabel('Predicted test correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
