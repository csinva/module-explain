{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import joblib\n",
    "import dvu\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "from numpy import ceil\n",
    "sys.path.append('../notebooks')\n",
    "from tqdm import tqdm\n",
    "import sasc.viz\n",
    "from PIL import Image\n",
    "from flatmaps_helper import VOX_COUNTS, load_flatmaps, load_custom_rois, load_known_rois, ROI_EXPLANATIONS_S03\n",
    "from neuro.config import repo_dir, PROCESSED_DIR\n",
    "from neuro.features.qa_questions import get_questions, get_merged_questions_v3_boostexamples\n",
    "from sasc.config import FMRI_DIR, STORIES_DIR, RESULTS_DIR, CACHE_DIR, RESULTS_DIR, cache_ngrams_dir, regions_idxs_dir\n",
    "from sasc import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main load\n",
    "normalize_flatmaps = False\n",
    "# gemv_flatmaps_dict_S02, gemv_flatmaps_dict_S03 = load_flatmaps(\n",
    "# normalize_flatmaps)\n",
    "gemv_flatmaps_dict_S02, gemv_flatmaps_dict_S03, gemv_flatmaps_dict_S02_timecourse, gemv_flatmaps_dict_S03_timecourse = load_flatmaps(\n",
    "    normalize_flatmaps, load_timecourse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save spotlights driving scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject = 'S02'\n",
    "# subject = 'S03'\n",
    "for subject in ['S02', 'S03']:\n",
    "    if subject == 'S03':\n",
    "        gemv_flatmaps_dict = gemv_flatmaps_dict_S03\n",
    "        gemv_flatmaps_dict_timecourse = gemv_flatmaps_dict_S03_timecourse\n",
    "    elif subject == 'S02':\n",
    "        gemv_flatmaps_dict = gemv_flatmaps_dict_S02\n",
    "        gemv_flatmaps_dict_timecourse = gemv_flatmaps_dict_S02_timecourse\n",
    "\n",
    "    spotlights_expls = pd.read_csv(\n",
    "        f'../0_voxel_select/communication_explanations_{subject}_spotlights.csv')\n",
    "    spotlights_expls = spotlights_expls[~pd.isna(spotlights_expls['explanation'])].rename(\n",
    "        columns={'Unnamed: 0': 'spotlight_idx'}\n",
    "    ).drop(columns='top_ngrams')\n",
    "    spotlights_expls['spotlight_idx'] = spotlights_expls['spotlight_idx'].str.replace(\n",
    "        '_only', '').astype(int)\n",
    "\n",
    "    SPOTLIGHT_DICT = {\n",
    "        'name': [\n",
    "            'Clothing and Physical Appearance', 'Colors', 'Dialogue',\n",
    "            'Gruesome body imagery', 'Introspection', 'Measurements',\n",
    "            'Numbers', 'Relationships', 'Times', 'Years', 'Fear and Avoidance',\n",
    "            'Negative Emotional Reactions', 'Positive Emotional Reactions',\n",
    "            'Professions and Personal Backgrounds', 'Recognition', 'Secretive Or Covert Actions',\n",
    "            'Sexual and Romantic Interactions'],\n",
    "        'keywords': [\n",
    "            ['Cloth'], ['Color'], ['Dialogue', 'Conversation'],\n",
    "            ['Gruesome'], ['Introspection', 'Reflection'], ['Measurement'],\n",
    "            ['Numbers'], ['Relationships'], ['Time'], [\n",
    "                'Years'], ['Fear', 'Avoidance'],\n",
    "            ['Negative Emotional', 'negativity'], [\n",
    "                'Positive Emotional', 'positivity', 'joy', 'happiness'],\n",
    "            ['Professions'], ['Recognition'], ['Secretive'],\n",
    "            ['Sexual', 'Romantic']],\n",
    "        'explanation': [],\n",
    "        'spotlight_idx': [],\n",
    "    }\n",
    "    for i in range(len(SPOTLIGHT_DICT['name'])):\n",
    "        keywords = SPOTLIGHT_DICT['keywords'][i]\n",
    "        for keyword in keywords:\n",
    "            df_match = spotlights_expls[spotlights_expls['explanation'].str.contains(\n",
    "                keyword, case=False)]\n",
    "        SPOTLIGHT_DICT['explanation'].append(df_match['explanation'].values)\n",
    "        SPOTLIGHT_DICT['spotlight_idx'].append(\n",
    "            df_match['spotlight_idx'].values)\n",
    "    df = pd.DataFrame(SPOTLIGHT_DICT)\n",
    "\n",
    "    def zscore_to_pvalue_right_tailed(z):\n",
    "        \"\"\"Return the right-tailed p-value for a given z-score.\"\"\"\n",
    "        return 1 - norm.cdf(z)\n",
    "\n",
    "    rois_dict_spotlights = load_custom_rois(\n",
    "        subject, suffix_setting='_spotlights')\n",
    "    driving_scores = []\n",
    "    # flatmaps = []\n",
    "    zscores = []\n",
    "    pvals = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        driving_score = []\n",
    "        flatmap = gemv_flatmaps_dict[(row['name'], None)]\n",
    "        for spotlight_idx in row['spotlight_idx']:\n",
    "            spotlight_mask = rois_dict_spotlights[f'spot{spotlight_idx}'] > 0\n",
    "            driving_score.append(np.mean(flatmap[spotlight_mask]))\n",
    "            timecourse_roi = gemv_flatmaps_dict_timecourse[(\n",
    "                row['name'], None)][spotlight_mask]\n",
    "            stderr = timecourse_roi.mean(\n",
    "                axis=0).std() / np.sqrt(timecourse_roi.shape[1])\n",
    "            # .mean(axis=0).std()\n",
    "            # print(timecourse.shape)\n",
    "        driving_scores.append(driving_score)\n",
    "        zscore = driving_score / stderr\n",
    "        zscores.append(zscore)\n",
    "        pvals.append(zscore_to_pvalue_right_tailed(zscore))\n",
    "        # flatmaps.append(flatmap)\n",
    "    df['driving_score'] = driving_scores\n",
    "    df['zscore'] = zscores\n",
    "    df['pval'] = pvals\n",
    "    # df['flatmap'] = flatmaps\n",
    "\n",
    "    d = {\n",
    "        k: np.concatenate(df[k])\n",
    "        for k in ['explanation', 'spotlight_idx', 'driving_score', 'zscore', 'pval']\n",
    "    }\n",
    "    df_spotlights = pd.DataFrame(d)\n",
    "    d_rep = df.explode('spotlight_idx')\n",
    "    d_rep = d_rep[~d_rep['spotlight_idx'].isna()]\n",
    "    for k in ['name']:  # , 'flatmap']:\n",
    "        df_spotlights[k] = d_rep[k].values\n",
    "\n",
    "    # all_driving_scores = np.concatenate(df['driving_score'].values).flatten()\n",
    "    plot_val = 'driving_score'\n",
    "    # plot_val = 'pval'\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df_spotlights[plot_val], alpha=0.5)\n",
    "    plt.xlim(-0.6, 0.6)\n",
    "    # avg = np.mean(df_spotlights[plot_val])\n",
    "    # plt.axvline(avg, color='black')\n",
    "    # annotate with mean\n",
    "    # plt.text(avg + 0.01, 10, f'mean={avg:.2f}', color='black')\n",
    "    # median = np.median(df_spotlights[plot_val])\n",
    "    # plt.axvline(median, color='red')\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    # annotate with median\n",
    "    # plt.text(median + 0.01, 10, f'median={median:.2f}', color='red')\n",
    "    # plt.xlabel(f'GEM-V {plot_val} ($\\sigma$)')\n",
    "    plt.xlabel('Mean driving spotlight response ($\\sigma$)')\n",
    "    plt.ylabel(f'{subject} spotlight count')\n",
    "    # plt.title(subject)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'spotlights_driving_scores_{subject}.pdf')\n",
    "    plt.show()\n",
    "    # plt.axvline(np.mean(all_driving_scores), color='red')\n",
    "    df_spotlights.to_pickle(f'spotlights_driving_scores_{subject}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize spotlights driving scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotlights_S02 = pd.read_pickle('spotlights_driving_scores_S02.pkl')\n",
    "df_spotlights_S03 = pd.read_pickle('spotlights_driving_scores_S03.pkl')\n",
    "names_intersection_hypotheses = set(\n",
    "    df_spotlights_S02['name']).intersection(set(df_spotlights_S03['name']))\n",
    "df_spotlights_S02 = df_spotlights_S02[df_spotlights_S02['name'].isin(\n",
    "    names_intersection_hypotheses)]\n",
    "df_spotlights_S03 = df_spotlights_S03[df_spotlights_S03['name'].isin(\n",
    "    names_intersection_hypotheses)]\n",
    "\n",
    "alpha = 0.05\n",
    "df_spotlights_S02['pval_corrected'] = multipletests(\n",
    "    df_spotlights_S02['pval'], alpha=alpha, method='fdr_bh')[1]\n",
    "df_spotlights_S03['pval_corrected'] = multipletests(\n",
    "    df_spotlights_S03['pval'], alpha=alpha, method='fdr_bh')[1]\n",
    "df_spotlights_S02.to_pickle('spotlights_driving_scores_S02.pkl')\n",
    "df_spotlights_S03.to_pickle('spotlights_driving_scores_S03.pkl')\n",
    "print('num_hypotheses_S02:',\n",
    "      df_spotlights_S02.shape[0], 'num_hypotheses_S03:', df_spotlights_S03.shape[0])\n",
    "print('num_significant_S02:', np.sum(df_spotlights_S02['pval_corrected'] < alpha), 'num_significant_S03:', np.sum(\n",
    "    df_spotlights_S03['pval_corrected'] < alpha))\n",
    "for subject in ['S02', 'S03']:\n",
    "    rois_dict_spotlights = load_custom_rois(\n",
    "        subject, suffix_setting='_spotlights')\n",
    "    print('num_spotlights', subject, len(rois_dict_spotlights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotlights_S02 = pd.read_pickle('spotlights_driving_scores_S02.pkl')\n",
    "df_spotlights_S03 = pd.read_pickle('spotlights_driving_scores_S03.pkl')\n",
    "rois_dict_spotlights_S02 = load_custom_rois(\n",
    "    'S02', suffix_setting='_spotlights')\n",
    "rois_dict_spotlights_S03 = load_custom_rois(\n",
    "    'S03', suffix_setting='_spotlights')\n",
    "\n",
    "# threshold by driving_score\n",
    "# thresh = 0.05\n",
    "# df_spotlights_S02 = df_spotlights_S02[df_spotlights_S02['driving_score'] > thresh]\n",
    "# df_spotlights_S03 = df_spotlights_S03[df_spotlights_S03['driving_score'] > thresh]\n",
    "alpha = 0.05\n",
    "df_spotlights_S02 = df_spotlights_S02[df_spotlights_S02['pval_corrected'] < alpha]\n",
    "df_spotlights_S03 = df_spotlights_S03[df_spotlights_S03['pval_corrected'] < alpha]\n",
    "\n",
    "# visualize\n",
    "names_unique = set(df_spotlights_S02['name'].unique()).intersection(\n",
    "    df_spotlights_S03['name'].unique())\n",
    "names_unique = list(names_unique)\n",
    "print('num sig S02', len(df_spotlights_S02),\n",
    "      'num sig S03', len(df_spotlights_S03), 'num expls with sig region for both subjects', len(names_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gemv_flatmaps_dict_S02' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m spotlight_sum_S02 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(spotlights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# scores\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m flatmap \u001b[38;5;241m=\u001b[39m \u001b[43mgemv_flatmaps_dict_S02\u001b[49m[(name, \u001b[38;5;28;01mNone\u001b[39;00m)]\n\u001b[1;32m     11\u001b[0m spotlights_scores_S02 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(spotlight_sum_S02)\n\u001b[1;32m     12\u001b[0m spotlights_scores_S02[spotlight_sum_S02 \u001b[38;5;241m>\u001b[39m\n\u001b[1;32m     13\u001b[0m                       \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m flatmap[spotlight_sum_S02 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gemv_flatmaps_dict_S02' is not defined"
     ]
    }
   ],
   "source": [
    "spotlights_scores_dict = {}\n",
    "for name in tqdm(names_unique):\n",
    "    spotlights_idx_S02 = df_spotlights_S02[df_spotlights_S02['name']\n",
    "                                           == name]['spotlight_idx'].values.tolist()\n",
    "    spotlights = [\n",
    "        rois_dict_spotlights_S02[f'spot{spotlight_idx}'] for spotlight_idx in spotlights_idx_S02]\n",
    "    spotlight_sum_S02 = np.sum(spotlights, axis=0)\n",
    "\n",
    "    # scores\n",
    "    flatmap = gemv_flatmaps_dict_S02[(name, None)]\n",
    "    spotlights_scores_S02 = np.zeros_like(spotlight_sum_S02)\n",
    "    spotlights_scores_S02[spotlight_sum_S02 >\n",
    "                          0] = flatmap[spotlight_sum_S02 > 0]\n",
    "\n",
    "    spotlights_idx_S03 = df_spotlights_S03[df_spotlights_S03['name']\n",
    "                                           == name]['spotlight_idx'].values.tolist()\n",
    "    spotlights = [rois_dict_spotlights_S03[f'spot{spotlight_idx}']\n",
    "                  for spotlight_idx in spotlights_idx_S03]\n",
    "    spotlight_sum_S03 = np.sum(spotlights, axis=0)\n",
    "\n",
    "    # scores\n",
    "    flatmap = gemv_flatmaps_dict_S03[(name, None)]\n",
    "    spotlights_scores_S03 = np.zeros_like(spotlight_sum_S03)\n",
    "    spotlights_scores_S03[spotlight_sum_S03 >\n",
    "                          0] = flatmap[spotlight_sum_S03 > 0]\n",
    "\n",
    "    # print(name, 'S02', 'max', np.max(spotlights_scores_S02),\n",
    "    #       'min', np.min(spotlights_scores_S02))\n",
    "    # print(name, 'S03', 'max', np.max(spotlights_scores_S03),\n",
    "    #         'min', np.min(spotlights_scores_S03))\n",
    "\n",
    "    spotlights_scores_dict[name] = {\n",
    "        'S02': spotlights_scores_S02,\n",
    "        'S03': spotlights_scores_S03,\n",
    "    }\n",
    "\n",
    "    # sasc.viz._save_flatmap(\n",
    "    #     spotlights_scores_S02, 'S02', fname_save=f'rois_spotlights/{name}_scores_S02.png', vabs=0.6, clab='Difference from baseline ($\\sigma$)')\n",
    "    # sasc.viz._save_flatmap(\n",
    "    #     spotlights_scores_S03, 'S03', fname_save=f'rois_spotlights/{name}_scores_S03.png', vabs=0.6, clab='Difference from baseline ($\\sigma$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for suff in ['_scores']:\n",
    "    # read all plots and save as subplots on the same page\n",
    "    for subject in ['S02', 'S03']:\n",
    "        n = len(names_unique)\n",
    "        C = 5\n",
    "        R = int(ceil(n/C))\n",
    "        fig, axs = plt.subplots(R, C, figsize=(C * 3, R * 2))\n",
    "        axs = axs.ravel()\n",
    "        for i in range(n):\n",
    "            name = names_unique[i]\n",
    "            axs[i].imshow(Image.open(\n",
    "                f'rois_spotlights/{name}{suff}_{subject}.png'))\n",
    "            axs[i].axis('off')\n",
    "            if subject == 'S02':\n",
    "                axs[i].set_title(\n",
    "                    f'{name.replace(\"Times\", \"Time\")}', fontsize='xx-small')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'rois_spotlights/all_{subject}{suff}.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
