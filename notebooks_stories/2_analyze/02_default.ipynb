{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from scipy.special import softmax\n",
    "import sasc.config\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import sasc.viz\n",
    "from sasc import analyze_helper\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num\n",
    "from sasc import config\n",
    "from scipy.stats import false_discovery_control\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "\n",
    "# pcs = joblib.load(join(FMRI_DIR, \"voxel_neighbors_and_pcs\", \"loo_pc_UTS02.pkl\"))\n",
    "# pcs['good_voxels'].shape\n",
    "# pcs['pca_projections'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pilot_name = 'pilot_story_data.pkl'\n",
    "# pilot_name = 'pilot3_story_data.pkl'\n",
    "# pilot_name = 'pilot4_story_data.pkl'\n",
    "pilot_name = \"pilot6_story_data.pkl\"\n",
    "\n",
    "stories_data_dict = joblib.load(\n",
    "    join(config.RESULTS_DIR, 'processed', pilot_name))\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20230504')\n",
    "elif pilot_name == 'pilot3_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20231106')\n",
    "elif pilot_name == 'pilot4_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20240509')\n",
    "elif pilot_name == 'pilot6_story_data.pkl':\n",
    "    pilot_data_dir = join(config.PILOT_STORY_DATA_DIR, '20241202')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load responses\n",
    "default_story_idxs = np.where(\n",
    "    (np.array(stories_data_dict['story_setting']) == 'default') |\n",
    "    (np.array(stories_data_dict['story_setting']) == 'roi')\n",
    ")[0]\n",
    "resp_np_files = [stories_data_dict['story_name_new'][i].replace('_resps', '')\n",
    "                 for i in default_story_idxs]\n",
    "resps_dict = {\n",
    "    k: np.load(join(pilot_data_dir, k))\n",
    "    for k in tqdm(resp_np_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = defaultdict(list)\n",
    "resp_chunks = defaultdict(list)\n",
    "if pilot_name in ['pilot1']:\n",
    "    use_clusters_list = [False, True]\n",
    "else:\n",
    "    use_clusters_list = [False]\n",
    "for use_clusters in use_clusters_list:\n",
    "    for story_num in default_story_idxs:\n",
    "        rows = stories_data_dict[\"rows\"][story_num]\n",
    "\n",
    "        # get resp_chunks\n",
    "        resp_story = resps_dict[\n",
    "            stories_data_dict[\"story_name_new\"][story_num].replace(\n",
    "                '_resps', '')\n",
    "        ].T  # (voxels, time)\n",
    "        timing = stories_data_dict[\"timing\"][story_num]\n",
    "        if 'paragraphs' in stories_data_dict.keys():\n",
    "            paragraphs = stories_data_dict[\"paragraphs\"][story_num]\n",
    "        else:\n",
    "            paragraphs = stories_data_dict[\"story_text\"][story_num].split(\n",
    "                \"\\n\\n\")\n",
    "        # paragraphs = stories_data_dict[\"story_text\"][story_num].split(\"\\n\\n\")\n",
    "        if pilot_name in ['pilot3_story_data.pkl']:\n",
    "            paragraphs = [sasc.analyze_helper.remove_repeated_words(\n",
    "                p) for p in paragraphs]\n",
    "        assert len(paragraphs) == len(\n",
    "            rows), f\"{len(paragraphs)} != {len(rows)}\"\n",
    "        resp_chunks = analyze_helper.get_resps_for_paragraphs(\n",
    "            timing, paragraphs, resp_story, offset=2, validate=True,\n",
    "            split_hyphens=pilot_name == \"pilot6_story_data.pkl\")\n",
    "        assert len(resp_chunks) <= len(paragraphs)\n",
    "\n",
    "        # calculate mat\n",
    "        mat = np.zeros((len(rows), len(paragraphs)))\n",
    "        for i in range(len(resp_chunks)):\n",
    "            if use_clusters == False:\n",
    "                # driving single voxel\n",
    "                if 'voxel_num' in rows.columns:\n",
    "                    mat[:, i] = resp_chunks[i][rows[\"voxel_num\"].values].mean(\n",
    "                        axis=1).flatten()\n",
    "                elif 'voxel_nums' in rows.columns:\n",
    "                    mat[:, i] = [resp_chunks[i][x].mean()\n",
    "                                 for x in rows['voxel_nums']]\n",
    "                    # resp_chunks[i][rows[\"voxel_nums\"].values].mean(\n",
    "                    # axis=1).flatten()\n",
    "\n",
    "            elif use_clusters == True:\n",
    "                for r in range(len(rows)):\n",
    "                    cluster_nums = rows.iloc[r][\"cluster_nums\"]\n",
    "                    if isinstance(cluster_nums, np.ndarray):\n",
    "                        vals = resp_chunks[i][cluster_nums].flatten()\n",
    "                        mat[r, i] = np.nanmean(vals)\n",
    "                    else:\n",
    "                        # print(cluster_nums)\n",
    "                        mat[r, i] = np.nan\n",
    "        mat[:, 0] = np.nan  # ignore the first column\n",
    "        # print('mat', mat)\n",
    "\n",
    "        # sort by voxel_num\n",
    "        if 'voxel_num' in rows.columns:\n",
    "            args = np.argsort(rows[\"voxel_num\"].values)\n",
    "        elif pilot_name == 'pilot6_story_data.pkl':\n",
    "            args = np.argsort(rows[\"expl\"].values)\n",
    "        else:\n",
    "            args = np.argsort(rows[\"roi\"].values)\n",
    "        mat = mat[args, :][:, args]\n",
    "        mats[use_clusters].append(deepcopy(mat))\n",
    "\n",
    "        # plt.imshow(mat)\n",
    "        # plt.colorbar(label=\"Mean response\")\n",
    "        # plt.xlabel(\"Corresponding paragraph\\n(Ideally, diagonal should be brighter)\")\n",
    "        # plt.ylabel(\"Voxel\")\n",
    "        # plt.title(f\"{story_data['story_name_new'][story_num][3:-10]}\")\n",
    "        # plt.show()\n",
    "\n",
    "if 'voxel_num' in rows.columns:\n",
    "    rows = rows.sort_values(by=\"voxel_num\")\n",
    "elif pilot_name == 'pilot6_story_data.pkl':\n",
    "    rows = rows.sort_values(by=\"expl\")\n",
    "else:\n",
    "    rows = rows.sort_values(by=\"roi\")\n",
    "expls = rows[\"expl\"].values\n",
    "\n",
    "\n",
    "m = {}\n",
    "for use_clusters in [False, True]:\n",
    "    mats[use_clusters] = np.array(mats[use_clusters])  # (6, 17, 17)\n",
    "    m[use_clusters] = np.nanmean(mats[use_clusters], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make average plot\n",
    "# calculate means\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "diag_means = np.diag(m1)\n",
    "off_diag_means = np.nanmean(m1, axis=1) - (diag_means / len(diag_means))\n",
    "sasc.viz.barplot_default([diag_means], [off_diag_means],\n",
    "                         pilot_name, expls, annot_points=False)\n",
    "joblib.dump({'diag_means': diag_means,\n",
    "            'off_diag_means': off_diag_means}, join(config.RESULTS_DIR, 'processed', pilot_name.replace('_story_data.pkl', '_default_means.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expl</th>\n",
       "      <th>top_ngrams_module_correct</th>\n",
       "      <th>subject</th>\n",
       "      <th>prompt_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clothing and Physical Appearance</td>\n",
       "      <td>[in his beret, in a bathrobe, a red hoodie, bl...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Colors</td>\n",
       "      <td>[black chevy, a bumpy orange, and frosty pink,...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dialogue</td>\n",
       "      <td>[he said, she said, they whispered, he chimed ...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning the people involved in the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fear and Avoidance</td>\n",
       "      <td>[he screamed, always too scared, she steered c...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gruesome body imagery</td>\n",
       "      <td>[my scalp peeled, soaked with sweat, eyes were...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Introspection</td>\n",
       "      <td>[he reflected, she thought back, they thought ...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning conversations or dialogue int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Measurements</td>\n",
       "      <td>[two mile thick, eighty milligrams, two hundre...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning any numbers or times. (like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Negative Emotional Reactions</td>\n",
       "      <td>[mom started crying, started to cry, eyed her ...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numbers</td>\n",
       "      <td>[five, twenty, three hundred, a million, forty...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning any measurements or times.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Positive Emotional Reactions</td>\n",
       "      <td>[she started laughing, smiled and said, he gig...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Professions and Personal Backgrounds</td>\n",
       "      <td>[his cop training, other egghead phds, parents...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Recognition</td>\n",
       "      <td>[neighbor had recognized, officer heard me, fr...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relationships</td>\n",
       "      <td>[brother and sister, he was a good friend, a w...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning conversations or dialogue in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Secretive Or Covert Actions</td>\n",
       "      <td>[sneak out when, bribe the guards, of getting ...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sexual and Romantic Interactions</td>\n",
       "      <td>[tried to flirt, me a blowjob, to get laid, sa...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Times</td>\n",
       "      <td>[one o'clock, hours and hours, pocketwatch tic...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning any numbers, measurements, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Years</td>\n",
       "      <td>[of nineteen sixty, until nineteen sixty, unti...</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>Avoid mentioning any numbers, measurements, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    expl  \\\n",
       "8       Clothing and Physical Appearance   \n",
       "9                                 Colors   \n",
       "5                               Dialogue   \n",
       "16                    Fear and Avoidance   \n",
       "7                  Gruesome body imagery   \n",
       "6                          Introspection   \n",
       "3                           Measurements   \n",
       "14          Negative Emotional Reactions   \n",
       "0                                Numbers   \n",
       "13          Positive Emotional Reactions   \n",
       "15  Professions and Personal Backgrounds   \n",
       "12                           Recognition   \n",
       "4                          Relationships   \n",
       "11           Secretive Or Covert Actions   \n",
       "10      Sexual and Romantic Interactions   \n",
       "1                                  Times   \n",
       "2                                  Years   \n",
       "\n",
       "                            top_ngrams_module_correct subject  \\\n",
       "8   [in his beret, in a bathrobe, a red hoodie, bl...   UTS02   \n",
       "9   [black chevy, a bumpy orange, and frosty pink,...   UTS02   \n",
       "5   [he said, she said, they whispered, he chimed ...   UTS02   \n",
       "16  [he screamed, always too scared, she steered c...   UTS02   \n",
       "7   [my scalp peeled, soaked with sweat, eyes were...   UTS02   \n",
       "6   [he reflected, she thought back, they thought ...   UTS02   \n",
       "3   [two mile thick, eighty milligrams, two hundre...   UTS02   \n",
       "14  [mom started crying, started to cry, eyed her ...   UTS02   \n",
       "0   [five, twenty, three hundred, a million, forty...   UTS02   \n",
       "13  [she started laughing, smiled and said, he gig...   UTS02   \n",
       "15  [his cop training, other egghead phds, parents...   UTS02   \n",
       "12  [neighbor had recognized, officer heard me, fr...   UTS02   \n",
       "4   [brother and sister, he was a good friend, a w...   UTS02   \n",
       "11  [sneak out when, bribe the guards, of getting ...   UTS02   \n",
       "10  [tried to flirt, me a blowjob, to get laid, sa...   UTS02   \n",
       "1   [one o'clock, hours and hours, pocketwatch tic...   UTS02   \n",
       "2   [of nineteen sixty, until nineteen sixty, unti...   UTS02   \n",
       "\n",
       "                                        prompt_suffix  \n",
       "8                                                      \n",
       "9                                                      \n",
       "5    Avoid mentioning the people involved in the c...  \n",
       "16                                                     \n",
       "7                                                      \n",
       "6   Avoid mentioning conversations or dialogue int...  \n",
       "3    Avoid mentioning any numbers or times. (like ...  \n",
       "14                                                     \n",
       "0         Avoid mentioning any measurements or times.  \n",
       "13                                                     \n",
       "15                                                     \n",
       "12                                                     \n",
       "4    Avoid mentioning conversations or dialogue in...  \n",
       "11                                                     \n",
       "10                                                     \n",
       "1    Avoid mentioning any numbers, measurements, o...  \n",
       "2    Avoid mentioning any numbers, measurements, o...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between different voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: some voxels didn't have good clusters so they will be missing from these plots...\n",
    "use_clusters = False\n",
    "m1 = m[use_clusters]\n",
    "\n",
    "sasc.viz.outline_diagonal(m1.shape, color='black', lw=1, block_size=1)\n",
    "\n",
    "s = 'small'\n",
    "# expls_order = analyze_helper.sort_expls_semantically(expls, device='cuda')\n",
    "expls_order = np.argsort(expls)\n",
    "if pilot_name == 'pilot_story_data.pkl':\n",
    "    expls_order = expls_order[[15, 7, 11, 14, 3,\n",
    "                               12, 4, 1, 2, 0, 13, 6, 5, 16, 10, 9, 8]]\n",
    "m_plot = m1[expls_order][:, expls_order]  # [:, expls_order]\n",
    "sasc.viz.imshow_diverging(\n",
    "    m_plot, clab=\"Mean response ($\\sigma$)\", clab_size='large')\n",
    "plt.xlabel(\"Driving paragraph\",  # \\n(Ideally, diagonal should be brighter)\",\n",
    "           fontsize='large')\n",
    "\n",
    "# plt.ylabel(\"Voxel\", fontsize='x-small')\n",
    "# labs = expls[expls_order]\n",
    "\n",
    "plt.ylabel(\"Voxel number\", fontsize='large')\n",
    "labs = [f'{i + 1:02d}' for i in range(len(expls_order))]\n",
    "for i in range(len(labs)):\n",
    "    print(labs[i], expls[expls_order[i]])\n",
    "\n",
    "plt.yticks(labels=labs, ticks=np.arange(\n",
    "    len(expls)), fontsize=s)\n",
    "plt.xticks(labels=labs, ticks=np.arange(\n",
    "    len(expls)), rotation=90, fontsize=s)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/main',\n",
    "            pilot_name[:pilot_name.index('_')] + '_default_heatmap.pdf'), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot correlations across all resps\n",
    "# resps_voxels = np.concatenate(\n",
    "#     [resps_dict[story_data[\"story_name_new\"][story_num]].T for story_num in [2, 3, 4]],\n",
    "#     axis=1,\n",
    "# )[rw[\"voxel_num\"].values]\n",
    "# corr = pd.DataFrame(resps_voxels.T, columns=expls).corr().round(2)\n",
    "# sns.clustermap(corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_df(mats1, melt=False):\n",
    "    d = defaultdict(list)\n",
    "    story_names = resp_np_files\n",
    "    for i in range(len(mats1)):\n",
    "        m = mats1[i]\n",
    "        d['driving'].append(np.nanmean(np.diag(m)))\n",
    "        d['baseline'].append(np.nanmean(m[~np.eye(m.shape[0], dtype=bool)]))\n",
    "        d['story'].append(story_names[i].replace('.npy', ''))\n",
    "    d = pd.DataFrame.from_dict(d)\n",
    "    if melt:\n",
    "        d = d.melt(id_vars='story', value_vars=[\n",
    "            'driving', 'baseline'], var_name='condition', value_name='mean')\n",
    "        d = d[d.condition == 'driving']\n",
    "    return d\n",
    "\n",
    "\n",
    "use_clusters = False\n",
    "mats1 = mats[use_clusters]\n",
    "story_scores_df = get_story_df(mats1)\n",
    "joblib.dump(story_scores_df, join(config.RESULTS_DIR, 'processed',\n",
    "            pilot_name.replace('_story_data.pkl', '_default_story_scores.pkl')))\n",
    "\n",
    "sasc.viz.stories_barplot(story_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.shape\n",
    "diags = np.diag(m1)\n",
    "off_diags = m1[~np.eye(m1.shape[0], dtype=bool)]\n",
    "\n",
    "n_permutations = 10000\n",
    "n_pick = len(diags)\n",
    "baseline_distr = []\n",
    "rng = np.random.default_rng(42)\n",
    "for i in range(n_permutations):\n",
    "    sample = rng.choice(\n",
    "        off_diags, n_pick, replace=False)\n",
    "    baseline_distr.append(np.nanmean(sample))\n",
    "baseline_distr = np.array(baseline_distr)\n",
    "p = np.mean(baseline_distr > np.nanmean(diags))\n",
    "print(pilot_name, p)\n",
    "PS = {\n",
    "    'UTS01': 0.0202,\n",
    "    'UTS02': 0,\n",
    "    'UTS03': 0.0057,\n",
    "}\n",
    "false_discovery_control(list(PS.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test per voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_stories, n_voxels, driving_paragraph\n",
    "diag_means2 = []\n",
    "mats_list = mats[use_clusters]\n",
    "ps_per_voxel = []\n",
    "for vox_num in range(mats_list.shape[1]):\n",
    "    driving_paragraph_means = mats_list[:, vox_num, vox_num]\n",
    "    non_driving_paragraph_means = np.delete(\n",
    "        mats_list[:, vox_num, :], vox_num, axis=-1).flatten()\n",
    "\n",
    "    # permutation test per voxel\n",
    "    n_permutations = 1000\n",
    "    n_pick = len(driving_paragraph_means)\n",
    "    baseline_distr = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    for i in range(n_permutations):\n",
    "        sample = rng.choice(\n",
    "            non_driving_paragraph_means, n_pick, replace=False)\n",
    "        baseline_distr.append(np.nanmean(sample))\n",
    "    baseline_distr = np.array(baseline_distr)\n",
    "    p = np.mean(baseline_distr > np.nanmean(driving_paragraph_means))\n",
    "    ps_per_voxel.append(p)\n",
    "\n",
    "    # note: actual min should be 1 / num_possible_permutations\n",
    "print(ps_per_voxel)\n",
    "PS_PER_VOXEL_OUTPUT = {\n",
    "    'UTS01': [0.497, 0.123, 0.304, 0.113, 0.157, 0.478, 0.836, 0.072, 0.273, 0.325, 0.426, 0.251, 0.626, 0.04, 0.109, 0.664, 0.704],\n",
    "    'UTS02': [0.771, 0.835, 0.07, 0.113, 0.0, 0.167, 0.037, 0.112, 0.018, 0.351, 0.005, 0.0, 0.0, 0.0, 0.019, 0.775, 0.006],\n",
    "    'UTS03': [0.003, 0.485, 0.491, 0.074, 0.103, 0.318, 0.961, 0.103, 0.218, 0.182, 0.057, 0.282, 0.392, 0.699, 0.287, 0.37, 0.201],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra analysis for UTS02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters vs non-clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"Blues\", 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pilot_name == 'pilot_story_data.pkl'\n",
    "df1 = get_story_df(mats[False], melt=True)\n",
    "df1['Setting'] = 'Single voxel'\n",
    "df2 = get_story_df(mats[True], melt=True)\n",
    "df2['Setting'] = 'Voxel cluster'\n",
    "df = pd.concat([df1, df2])\n",
    "df['story'] = df['story'].str.replace('GenStory', '')\n",
    "\n",
    "sns.barplot(data=df, x='story', y='mean',\n",
    "            hue='Setting',\n",
    "            width=0.8,\n",
    "            palette=[sns.color_palette(\"Blues\", 3)[0], 'lightgray'],\n",
    "            )\n",
    "plt.xlabel(\"Story\")\n",
    "plt.ylabel('Mean driving voxel response ($\\sigma$)')\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/misc',\n",
    "            'cluster_vs_single_default_story_breakdown.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good prompt vs bad prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pilot_name == 'pilot_story_data.pkl'\n",
    "df = get_story_df(mats[False], melt=True)\n",
    "good_prompt = ['GenStory2', 'GenStory3', 'GenStory4']\n",
    "df['Prompt'] = df.apply(lambda x: x['story'] in good_prompt, axis=1)\n",
    "df['Prompt'] = df['Prompt'].map(\n",
    "    {True: 'Prompt version 1', False: 'Prompt version 0'})\n",
    "df = df.sort_values(by='Prompt', ascending=False)\n",
    "df['story'] = df['story'].str.replace('GenStory', '')\n",
    "\n",
    "\n",
    "# shade bars by prompt version\n",
    "offset = 0\n",
    "xticklabels = []\n",
    "for i, prompt in enumerate(df['Prompt'].unique()):\n",
    "    d = df[df['Prompt'] == prompt]\n",
    "    d = d.sort_values('story')\n",
    "    plt.bar(np.arange(len(d)) + offset, d['mean'], label=prompt,\n",
    "            color=sns.color_palette(\"Blues\", 3)[0], hatch='' if i == 0 else '//')\n",
    "    xticklabels += d['story'].tolist()\n",
    "    offset += len(d)\n",
    "plt.xticks(np.arange(len(xticklabels)), xticklabels)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Story\")\n",
    "plt.ylabel('Mean driving voxel response ($\\sigma$)')\n",
    "plt.savefig(join(config.RESULTS_DIR, 'figs/misc',\n",
    "            'prompt_default_story_breakdown.pdf'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel-level differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stats\n",
    "def save_voxel_scores(m, rows, pilot_name):\n",
    "    rows[\"driving_score\"] = np.diag(m[False])\n",
    "    rm = pd.read_pickle(join(config.RESULTS_DIR, 'sasc', \"fmri_results_merged.pkl\")).sort_values(\n",
    "        by=[\"stability_score\"], ascending=False\n",
    "    )\n",
    "    for k in [\"fmri_test_corr_llama\", \"top_score_normalized_llama\"]:\n",
    "        rows[k] = rows.apply(\n",
    "            lambda row: rm[\n",
    "                (rm.module_num == row.module_num) & (rm.subject == row.subject)\n",
    "            ].iloc[0][k],\n",
    "            axis=1,\n",
    "        ).values\n",
    "    cols = [\"expl\", \"driving_score\", \"stability_score\", \"top_score_normalized\", \"top_score_normalized_llama\",\n",
    "            \"fmri_test_corr\", \"fmri_test_corr_llama\", \"module_num\"]\n",
    "    voxel_scores = rows[cols]\n",
    "    joblib.dump(voxel_scores, join(config.RESULTS_DIR, 'processed',\n",
    "                pilot_name.replace('_story_data.pkl', '_default_voxel_scores.pkl')))\n",
    "\n",
    "\n",
    "save_voxel_scores(m, rows, pilot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(rows[cols + [\"expl\"]], kind=\"reg\")  # , hue='expl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
