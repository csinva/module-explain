{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "from typing import List\n",
    "from mprompt.modules.emb_diff_module import EmbDiffModule\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imodelsx.util\n",
    "from copy import deepcopy\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "import pandas as pd\n",
    "import joblib\n",
    "# from mprompt.config import RESULTS_DIR\n",
    "import torch.cuda\n",
    "import json\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import pandas as pd\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import adjustText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import joblib\n",
    "import os\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "RESULTS_DIR = '/home/chansingh/mprompt/results'\n",
    "df = pd.read_csv(join(RESULTS_DIR, 'bert', \"dict_learn_results - extracted factors_all.csv\"))\n",
    "expls_scores_bert = joblib.load(join(RESULTS_DIR, 'bert', 'wiki_normalized_syn_scores', 'wiki_our_syn_perc_score.pkl'))\n",
    "\n",
    "# BERT_RAW_RESULTS_DIR = '/home/chansingh/mntv1/aliyah/ah-module-prompt/results/'\n",
    "# for layer in tqdm(range(13)):\n",
    "#     layer_dir = f'dl_l{layer}'\n",
    "#     for factor in range(1500):\n",
    "#         factor_dir = f'i{factor}'\n",
    "#         extra_dir = os.listdir(join(BERT_RAW_RESULTS_DIR, layer_dir, factor_dir))[0]\n",
    "#         results = joblib.load(join(BERT_RAW_RESULTS_DIR, layer_dir, factor_dir, extra_dir, 'results.pkl'))\n",
    "#         expl = results['top_explanation_init_strs']\n",
    "#         expls.append(expl)\n",
    "# joblib.dump(join(RESULTS_DIR, 'bert', 'expls_bert.jbl'))\n",
    "expls_bert = joblib.load(join(RESULTS_DIR, 'bert', 'expls_bert.jbl'))\n",
    "\n",
    "\n",
    "df_f = pd.read_pickle(join(RESULTS_DIR, 'results_fmri_full.pkl'))\n",
    "expls_fmri = df_f['top_explanation_init_strs'].values.tolist()\n",
    "\n",
    "df_bert = pd.DataFrame.from_dict({\n",
    "    'layer': sum([[i] * 1500 for i in range(13)], []),\n",
    "    'score': expls_scores_bert.flatten(),\n",
    "    'expl': expls_bert,\n",
    "})\n",
    "df_fmri = pd.DataFrame.from_dict({\n",
    "    'layer': 'fmri',\n",
    "    'score': df_f['top_score_synthetic'].values,\n",
    "    'expl': expls_fmri,\n",
    "})\n",
    "\n",
    "# filter dfs\n",
    "df_bert = df_bert[df_bert['score'] > 3]\n",
    "df_fmri = df_fmri[df_fmri['score'] > 0]\n",
    "n_bert = len(df_bert)\n",
    "expls = df_bert['expl'].values.tolist() + df_fmri['expl'].values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tSNE Embeddings Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings\n",
    "embeddor = INSTRUCTOR('hkunlp/instructor-xl')\n",
    "instruction = \"Represent the short phrase for clustering:\"\n",
    "embs = embeddor.encode([[instruction, x_i] for x_i in expls], batch_size=32)\n",
    "tsne = TSNE(n_components=2, random_state=42, verbose=False)\n",
    "word_vectors_2d = tsne.fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert['x'] = word_vectors_2d[:, 0][:n_bert]\n",
    "df_bert['y'] = word_vectors_2d[:, 1][:n_bert]\n",
    "df_fmri['x'] = word_vectors_2d[:, 0][n_bert:]\n",
    "df_fmri['y'] = word_vectors_2d[:, 1][n_bert:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(df_bert, df_fmri, hue='layer', label_map_dict=None, adjust_text=True):\n",
    "    for lay in sorted(df_bert[hue].unique()):\n",
    "        df_plot_lay = df_bert[df_bert[hue] == lay]\n",
    "        if hue == 'layer':\n",
    "            label = f\"Layer {lay}\"\n",
    "        elif hue == 'topic_num':\n",
    "            label = label_map_dict[lay]\n",
    "        plt.plot(\n",
    "            df_plot_lay['x'],\n",
    "            df_plot_lay['y'],\n",
    "            marker=\".\",\n",
    "            alpha=0.25,\n",
    "            # markersize=1,\n",
    "            label=label,\n",
    "            color=sns.color_palette(\"viridis_r\", 26)[lay],\n",
    "            linestyle=\"None\",\n",
    "        )\n",
    "\n",
    "    plt.plot(\n",
    "            df_fmri['x'],\n",
    "            df_fmri['y'],\n",
    "            marker=\".\",\n",
    "            alpha=1,\n",
    "            # markersize=1,\n",
    "            label=f\"fMRI\",\n",
    "            color='pink',\n",
    "            linestyle=\"None\",\n",
    "        )\n",
    "    texts = []\n",
    "    for i, word in enumerate(df_bert['expl']):\n",
    "        if i % 100 == 0:\n",
    "            texts.append(\n",
    "                plt.annotate(word[:15], (word_vectors_2d[i, 0], word_vectors_2d[i, 1]), fontsize='xx-small'))\n",
    "    for i, word in enumerate(df_fmri['expl']):\n",
    "        if i % 100 == 0:\n",
    "            texts.append(\n",
    "                plt.annotate(word[:15], (word_vectors_2d[n_bert + i, 0], word_vectors_2d[n_bert + i, 1]), fontsize='xx-small'))\n",
    "\n",
    "    # make texts not overlap\n",
    "    if adjust_text:\n",
    "        print('adjusting texts...')\n",
    "        adjustText.adjust_text(texts) #, arrowprops=dict(arrowstyle='-', color='k', lw=0.5))\n",
    "\n",
    "    plt.xlabel(\"t-SNE dimension 1\")\n",
    "    plt.ylabel(\"t-SNE dimension 2\")\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plot_tsne(df_bert, df_fmri, adjust_text=False)\n",
    "plt.legend(bbox_to_anchor=(1.1, 0.9))\n",
    "plt.savefig(join(RESULTS_DIR, 'bert', 'tsne_unrestricted.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDAVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: remove numbers, special characters, and lowercase all words\n",
    "processed_docs = [re.sub(r'[^\\w\\s]', '', doc.lower()) for doc in expls]\n",
    "\n",
    "# Add custom stop words\n",
    "# additional_stop_words = ['dont', 'doesnt', 'didnt', 'couldnt', 'wont', 'cant']\n",
    "# stop_words = text.ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words='english',\n",
    "    max_df=0.95, min_df=2)\n",
    "dtm = vectorizer.fit_transform(processed_docs)\n",
    "\n",
    "# LDA model\n",
    "num_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Visualize clusters using PyLDAVis\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.lda_model.prepare(lda, dtm, vectorizer, mds='tsne')\n",
    "# pyLDAvis.save_html(vis, join(RESULTS_DIR, 'bert', 'lda.html'))\n",
    "\n",
    "# add topics to df\n",
    "words = vectorizer.get_feature_names_out()\n",
    "topic_names_dict = {\n",
    "    topic_idx: f\"{topic_idx + 1}: \" + \", \".join([words[i] for i in topic.argsort()[:-8:-1]])\n",
    "    for topic_idx, topic in enumerate(lda.components_)\n",
    "}\n",
    "topics = lda.transform(dtm).argmax(axis=1)\n",
    "df_bert['topic_num'] = topics[:n_bert]\n",
    "df_fmri['topic_num'] = topics[n_bert:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2771020/2506378069.py:14: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.savefig(join(RESULTS_DIR, 'bert', 'topic_proportions.png'), dpi=300, bbox_inches='tight')\n"
     ]
    }
   ],
   "source": [
    "counts = pd.merge(\n",
    "    (df_bert['topic_num'].value_counts() / len(df_bert)).reset_index(),\n",
    "    (df_fmri['topic_num'].value_counts() / len(df_fmri)).reset_index(),\n",
    "    on='topic_num',\n",
    ").rename(columns={'count_x': 'bert', 'count_y': 'fmri'})\n",
    "\n",
    "# make barplot from counts df with 'bert' and 'fmri' as the legend and topic_num as the ylabel\n",
    "plt.barh(counts['topic_num'] - 0.15, counts['bert'], color ='C0', label='BERT', height=0.3)\n",
    "plt.barh(counts['topic_num'] + 0.15, counts['fmri'], color='pink', label='fMRI', height=0.3)\n",
    "plt.yticks(counts['topic_num'], labels=counts['topic_num'].map(topic_names_dict))\n",
    "plt.xlabel('Topic proportion')\n",
    "plt.ylabel('Topic')\n",
    "plt.legend()\n",
    "plt.savefig(join(RESULTS_DIR, 'bert', 'topic_proportions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(join(RESULTS_DIR, 'bert', 'topic_proportions.pdf'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = lda.transform(dtm)\n",
    "coefs_bert = coefs[:n_bert].T\n",
    "coefs_fmri = coefs[n_bert:].T\n",
    "\n",
    "# sns.set_theme(style=\"ticks\")\n",
    "df_bert_box = pd.DataFrame.from_dict({\n",
    "    'topic': sum([[f'Topic {i}'] * coefs_bert.shape[1] for i in range(coefs_bert.shape[0])], []),\n",
    "    'coef': coefs_bert.flatten(),\n",
    "    'source': 'BERT',\n",
    "})\n",
    "df_fmri_box = pd.DataFrame.from_dict({\n",
    "    'topic': sum([[f'Topic {i}'] * coefs_fmri.shape[1] for i in range(coefs_fmri.shape[0])], []),\n",
    "    'coef': coefs_fmri.flatten(),\n",
    "    'source': 'fMRI',\n",
    "})\n",
    "df_box = pd.concat([df_bert_box, df_fmri_box])\n",
    "# df = df_bert\n",
    "f, ax = plt.subplots(figsize=(6, 6), dpi=300)\n",
    "sns.boxplot(x=\"coef\", y=\"topic\", data=df_box,\n",
    "            width=.6, palette=\"vlag\", whis=[0, 100], hue='source')\n",
    "# , whis=0, fliersize=0)\n",
    "plt.xlim(0, 0.1)\n",
    "\n",
    "# Add in points to show each observation\n",
    "# sns.stripplot(x=\"coef\", y=\"topic\", data=df,\n",
    "            #   size=2, color=\".5\", linewidth=0, alpha=0.1, hue='source',)\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "sns.despine(trim=True, left=True)\n",
    "plt.xlabel(\"Topic coefficient\")\n",
    "plt.show()\n",
    "# plt.savefig(join(RESULTS_DIR, 'bert', 'wiki_normalized_syn_scores', 'wiki_our_syn_perc_score_boxplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plot_tsne(\n",
    "    df_bert,\n",
    "    df_fmri,\n",
    "    hue=\"topic_num\",\n",
    "    label_map_dict=topic_names_dict,\n",
    "    adjust_text=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.1, 0.9), fontsize='xx-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
