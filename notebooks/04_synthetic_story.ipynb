{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "from typing import List\n",
    "from mprompt.modules.emb_diff_module import EmbDiffModule\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imodelsx.util\n",
    "import re\n",
    "import mprompt.viz\n",
    "import scipy.special\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from mprompt.methods.m4_evaluate import D5_Validator\n",
    "import openai\n",
    "openai.api_key_path = os.path.expanduser('~/.OPENAI_KEY')\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    assert n % 2 == 1, 'n should be odd'\n",
    "    diff = n // 2\n",
    "    vals = []\n",
    "    # calculate moving average in a window 2\n",
    "    # (1, 4)\n",
    "    for i in range(diff, len(a) + diff):\n",
    "        l = i - diff\n",
    "        r = i + diff + 1\n",
    "        vals.append(np.mean(a[l: r]))\n",
    "    return np.nan_to_num(vals)\n",
    "nlp = English()\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab, token_match=re.compile(r'\\S+').match) # only split on whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expls = [\n",
    "    'baseball',\n",
    "    'animals',\n",
    "    'water',\n",
    "    'movement',\n",
    "    'religion',\n",
    "    'technology',\n",
    "    'time'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning paragraph of a story about \"baseball\". Make sure it contains several references to \"baseball\".\n",
      "Write the next paragraph of the story, but now make it about \"animals\". Make sure it contains several references to \"animals\".\n",
      "Write the next paragraph of the story, but now make it about \"water\". Make sure it contains several references to \"water\".\n",
      "Write the next paragraph of the story, but now make it about \"movement\". Make sure it contains several references to \"movement\".\n",
      "Write the next paragraph of the story, but now make it about \"religion\". Make sure it contains several references to \"religion\".\n",
      "Write the next paragraph of the story, but now make it about \"technology\". Make sure it contains several references to \"technology\".\n",
      "Write the next paragraph of the story, but now make it about \"time\". Make sure it contains several references to \"time\".\n"
     ]
    }
   ],
   "source": [
    "prompt_init = 'Write the beginning paragraph of a story about \"{expl}\". Make sure it contains several references to \"{expl}\".'\n",
    "prompt_continue = 'Write the next paragraph of the story, but now make it about \"{expl}\". Make sure it contains several references to \"{expl}\".'\n",
    "prompts = [prompt_init.format(expl=expls[0])] + [prompt_continue.format(expl=expl) for expl in expls[1:]]\n",
    "for p in prompts:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n"
     ]
    }
   ],
   "source": [
    "def get_paragraphs(\n",
    "        prompts,\n",
    "        checkpoint='gpt-3.5-turbo',\n",
    "        PROMPT_FIRST_PREFIX='Write the next paragraph of the story, but now make it about',\n",
    "        PROMPT_NEXT_PREFIX='Write the beginning paragraph of a story about'\n",
    "):\n",
    "    # example messages\n",
    "    # [\n",
    "    #   {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "    #   {'role': 'user', 'content': 'Write the beginning paragraph of a story about \"baseball\". Make sure it contains several references to \"baseball\".'},\n",
    "    #   {'role': 'assistant', 'content': 'The crack of the bat echoed through the stadium as the ball soared over the outfield fence. The crowd erupted into cheers, their excitement palpable. It was a beautiful day for baseball, with the sun shining down on the field and the smell of freshly cut grass filling the air. The players on the field were focused and determined, each one ready to give their all for their team. Baseball was more than just a game to them; it was a passion, a way of life. And as they took their positions on the field, they knew that anything was possible in this great game of baseball.'},\n",
    "    #   {'role': 'user', 'content': 'Write the next paragraph of the story, but now make it about \"animals\". Make sure it contains several references to \"animals\".'},\n",
    "    # ]\n",
    "\n",
    "    llm = mprompt.llm.get_llm(checkpoint)\n",
    "    response = None\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    all_content = []\n",
    "    for i in range(len(prompts)):\n",
    "        messages.append({\"role\": \"user\", \"content\": prompts[i]})\n",
    "        all_content.append(messages[-1])\n",
    "        # for message in messages:\n",
    "            # print(message)\n",
    "        response = llm(messages)\n",
    "\n",
    "        if response is not None:\n",
    "            response_text = response['choices'][0]['message']['content']\n",
    "            messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "            all_content.append(messages[-1])\n",
    "\n",
    "        # need to drop beginning of story whenever we approach the tok limit\n",
    "        # gpt-3.5.turbo has a limit of 4096, and it cant generate beyond that\n",
    "        num_tokens = response['usage']['total_tokens']\n",
    "        # print('num_tokens', num_tokens)\n",
    "        if num_tokens >= 3200:\n",
    "            # drop the first (assistant, user) pair in messages\n",
    "            messages = [messages[0]] + messages[3:]\n",
    "\n",
    "            # rewrite the original prompt to now say beginning paragraph rather than next paragraph\n",
    "            messages[1]['content'] = messages[1]['content'].replace(PROMPT_FIRST_PREFIX, PROMPT_NEXT_PREFIX)\n",
    "    \n",
    "    # extract out paragraphs\n",
    "    paragraphs = [d['content'] for d in all_content if d['role'] == 'assistant']\n",
    "    paragraphs\n",
    "    assert len(paragraphs) == len(prompts)\n",
    "    return paragraphs\n",
    "paragraphs = get_paragraphs(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The crack of the bat echoed through the stadium as the ball soared over the outfield fence. The crowd erupted into cheers, their excitement palpable. It was a beautiful day for baseball, with the sun shining down on the field and the smell of freshly cut grass filling the air. The players on the field were focused and determined, each one ready to give their all for their team. Baseball was more than just a game to them; it was a passion, a way of life. And as they took their positions on the field, they knew that anything was possible in this great game of baseball.\n",
      "As the game continued, a group of animals gathered outside the stadium, drawn by the sounds and smells of the game. A family of raccoons peered through a hole in the fence, their curious eyes watching as the players ran back and forth across the field. A pack of stray dogs barked excitedly, tails wagging as they caught whiffs of hot dogs and popcorn. Even a few birds had flown in to catch a glimpse of the action, perching on the edge of the scoreboard and chirping along with the crowd. It was clear that baseball wasn't just for humans; animals loved it too.\n",
      "Suddenly, the sky darkened, and a loud clap of thunder echoed through the stadium. The crowd gasped as rain began to pour down, drenching everything in sight. The players scrambled to cover the field with tarps, but it was too late; the damage had been done. Puddles formed on the infield, and the outfield turned into a swampy mess. The water was ankle-deep in some places, making it difficult for the players to run and slide. But despite the challenging conditions, they soldiered on, determined to finish the game no matter what. The water may have slowed them down, but it couldn't stop them from playing their beloved game of baseball.\n",
      "The players continued to move across the field, their movements fluid and graceful despite the waterlogged conditions. They slid into bases, dove for fly balls, and made lightning-fast throws to catch runners off guard. Every movement was calculated and precise, a testament to the hours of practice they had put in. Even the fans in the stands were in constant motion, jumping up and down and waving their arms as they cheered on their favorite team. Baseball was a game of movement, of speed and agility, and these players were masters of their craft.\n",
      "As the game entered its final innings, a group of nuns arrived at the stadium, their habits flapping in the wind. They took their seats in the front row, clutching rosaries and praying for their team to win. The players on the field seemed to sense their presence, and they played with renewed vigor and determination. The crowd joined in, chanting and singing songs of victory as if it were a religious ritual. For many of them, baseball was more than just a game; it was a religion, a way of life. And as the final out was made and the stadium erupted into cheers, it was clear that their faith had been rewarded.\n",
      "As the players celebrated their hard-fought victory, a group of tech enthusiasts gathered in a nearby parking lot, huddled around a laptop and analyzing the game's statistics. They had been tracking every pitch, every hit, and every play using advanced software and sensors placed throughout the stadium. They discussed the data excitedly, debating the merits of different strategies and analyzing the players' movements with precision. For them, baseball was not just a game of skill and athleticism; it was also a game of technology, where data and analytics played a crucial role in determining the outcome. And as they packed up their equipment and headed home, they knew that they had witnessed something truly special: the intersection of sports and technology at its finest.\n",
      "As the stadium emptied out and the lights were turned off, the players and coaches lingered on the field, savoring the moment. They knew that time was fleeting, that this victory would soon be just a memory. But for now, they basked in the glory of their triumph, reliving every moment in their minds. Time had seemed to stand still during the game, each inning stretching out into eternity as they battled it out on the field. But now, as they walked off into the night, they knew that time would continue to march on, and that they would have to start preparing for their next game soon. For them, baseball was a constant race against time, a never-ending battle to stay ahead of the clock and come out on top.\n"
     ]
    }
   ],
   "source": [
    "for para in paragraphs:\n",
    "    print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embedding dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = EmbDiffModule()\n",
    "val = D5_Validator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_running = ''\n",
    "scores = {}\n",
    "for i in range(len(expls)):\n",
    "# for i in range(1):\n",
    "    expl = expls[i].lower()\n",
    "    text = paragraphs[i]\n",
    "    words = text.split()\n",
    "    prompt = prompts[i]\n",
    "\n",
    "    ngrams = imodelsx.util.generate_ngrams_list(text.lower(), ngrams=3, tokenizer_ngrams=nlp.tokenizer)\n",
    "    ngrams = [words[0], words[0] + ' ' + words[1]] + ngrams\n",
    "\n",
    "    # # embdiff-based viz\n",
    "    # mod._init_task(expl)    \n",
    "    # neg_dists = mod(ngrams)\n",
    "    # assert len(ngrams) == len(words) == len(neg_dists)\n",
    "    # # neg_dists = scipy.special.softmax(neg_dists)\n",
    "    # plt.plot(neg_dists)\n",
    "    # plt.plot(moving_average(neg_dists, n=5))\n",
    "    # neg_dists = moving_average(neg_dists, n=3)\n",
    "    # neg_dists = (neg_dists - neg_dists.min()) / (neg_dists.max() - neg_dists.min())\n",
    "    # neg_dists = neg_dists / 2 + 0.5 # shift to 0.5-1 range\n",
    "    # s = mprompt.viz.colorize(words, neg_dists, title=expl, subtitle=prompt)\n",
    "\n",
    "    # validator-based viz\n",
    "    probs = np.array(val.validate_w_scores(expl, ngrams))\n",
    "    probs_disp = moving_average(probs, n=3)\n",
    "    probs_disp = probs_disp / 2 + 0.5 # shift to 0.5-1 range\n",
    "    s = mprompt.viz.colorize(words, probs_disp, title=expl, subtitle=prompt)\n",
    "    \n",
    "    # viz\n",
    "    display(HTML(s))\n",
    "    story_running += ' ' + s\n",
    "\n",
    "with open('../results/story_running.html', 'w') as f:\n",
    "    f.write(story_running)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify synthetic data\n",
    "Calculate mean match for each paragraph to each explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story_running = ''\n",
    "n = len(expls)\n",
    "scores = np.zeros((n, n))\n",
    "for i in tqdm(range(n)):\n",
    "    expl = expls[i]\n",
    "    for j in range(n):\n",
    "        text = paragraphs[j].lower()\n",
    "        words = text.split()\n",
    "\n",
    "        ngrams = imodelsx.util.generate_ngrams_list(text, ngrams=3, tokenizer_ngrams=nlp.tokenizer)\n",
    "        ngrams = [words[0], words[0] + ' ' + words[1]] + ngrams\n",
    "\n",
    "        # validator-based viz\n",
    "        probs = np.array(val.validate_w_scores(expl, ngrams)) > 0.5\n",
    "        scores[i, j] = probs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scores\n",
    "# s = scipy.special.softmax(scores, axis=1)\n",
    "# s = (s - s.min()) / (s.max() - s.min())\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(s)\n",
    "plt.xticks(range(n), expls, rotation=90)\n",
    "plt.yticks(range(n), expls)\n",
    "plt.ylabel('Explanation for generation')\n",
    "plt.xlabel('Explanation for matching')\n",
    "plt.colorbar(label='Fraction of matching ngrams')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
