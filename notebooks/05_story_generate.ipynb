{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import notebook_helper\n",
    "import mprompt.viz\n",
    "import openai\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from mprompt.config import RESULTS_DIR\n",
    "from typing import Tuple\n",
    "import mprompt.llm\n",
    "import json\n",
    "openai.api_key_path = os.path.expanduser('~/.OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expl</th>\n",
       "      <th>subject</th>\n",
       "      <th>module_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moments</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>measurements</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>locations</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>locations</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>emotional expression</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>surprise</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>communication</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>food preparation</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     expl subject  module_num\n",
       "0                 moments   UTS02         337\n",
       "61           measurements   UTS02         171\n",
       "83              locations   UTS02         368\n",
       "85              locations   UTS02         122\n",
       "110  emotional expression   UTS02         398\n",
       "137              surprise   UTS02         168\n",
       "142         communication   UTS02         299\n",
       "228      food preparation   UTS02          79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample_frac</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>checkpoint_module</th>\n",
       "      <th>noise_ngram_scores</th>\n",
       "      <th>module_num_restrict</th>\n",
       "      <th>seed</th>\n",
       "      <th>save_dir</th>\n",
       "      <th>module_name</th>\n",
       "      <th>module_num</th>\n",
       "      <th>subject</th>\n",
       "      <th>...</th>\n",
       "      <th>top_ngrams_module_25</th>\n",
       "      <th>top_ngrams_module_50</th>\n",
       "      <th>top_ngrams_module_75</th>\n",
       "      <th>top_ngrams_module_100</th>\n",
       "      <th>roi_anat</th>\n",
       "      <th>roi_func</th>\n",
       "      <th>top_ngrams_module_correct</th>\n",
       "      <th>frac_top_ngrams_module_correct</th>\n",
       "      <th>id</th>\n",
       "      <th>expl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1.0</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/chansingh/mntv1/mprompt/mar13</td>\n",
       "      <td>fmri</td>\n",
       "      <td>168</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>...</td>\n",
       "      <td>[i provoked gasps, real this time, fathers fee...</td>\n",
       "      <td>[i provoked gasps, real this time, fathers fee...</td>\n",
       "      <td>[i provoked gasps, real this time, fathers fee...</td>\n",
       "      <td>[i provoked gasps, real this time, fathers fee...</td>\n",
       "      <td>[middletemporal]</td>\n",
       "      <td>[ATFP, AC]</td>\n",
       "      <td>[i provoked gasps, asked i laughed, felt so be...</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>('surprise,_shock,_dis', 'UTS02', 168)</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1.0</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/chansingh/mntv1/mprompt/mar13</td>\n",
       "      <td>fmri</td>\n",
       "      <td>79</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>...</td>\n",
       "      <td>[sliced cucumber, some sliced cucumber, butter...</td>\n",
       "      <td>[sliced cucumber, some sliced cucumber, butter...</td>\n",
       "      <td>[sliced cucumber, some sliced cucumber, butter...</td>\n",
       "      <td>[sliced cucumber, some sliced cucumber, butter...</td>\n",
       "      <td>[fusiform, inferiortemporal]</td>\n",
       "      <td>[ATFP]</td>\n",
       "      <td>[sliced cucumber, some sliced cucumber, butter...</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>('food_preparation', 'UTS02', 79)</td>\n",
       "      <td>food preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1.0</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/chansingh/mntv1/mprompt/mar13</td>\n",
       "      <td>fmri</td>\n",
       "      <td>398</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>...</td>\n",
       "      <td>[and mimed crying, she started laughing, face ...</td>\n",
       "      <td>[and mimed crying, she started laughing, face ...</td>\n",
       "      <td>[and mimed crying, she started laughing, face ...</td>\n",
       "      <td>[and mimed crying, she started laughing, face ...</td>\n",
       "      <td>[inferiorparietal, middletemporal]</td>\n",
       "      <td>[PMvh]</td>\n",
       "      <td>[and mimed crying, she started laughing, block...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>('emotional_expression', 'UTS02', 398)</td>\n",
       "      <td>emotional expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1.0</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/chansingh/mntv1/mprompt/mar13</td>\n",
       "      <td>fmri</td>\n",
       "      <td>299</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>...</td>\n",
       "      <td>[housewarming gift, writing his obituary, i go...</td>\n",
       "      <td>[housewarming gift, writing his obituary, i go...</td>\n",
       "      <td>[housewarming gift, writing his obituary, i go...</td>\n",
       "      <td>[housewarming gift, writing his obituary, i go...</td>\n",
       "      <td>[inferiorparietal]</td>\n",
       "      <td>[ATFP]</td>\n",
       "      <td>[writing his obituary, explain the joke, read ...</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>('communication', 'UTS02', 299)</td>\n",
       "      <td>communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1.0</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/chansingh/mntv1/mprompt/mar13</td>\n",
       "      <td>fmri</td>\n",
       "      <td>122</td>\n",
       "      <td>UTS02</td>\n",
       "      <td>...</td>\n",
       "      <td>[onto the railing, them fly overhead, against ...</td>\n",
       "      <td>[onto the railing, them fly overhead, against ...</td>\n",
       "      <td>[onto the railing, them fly overhead, against ...</td>\n",
       "      <td>[onto the railing, them fly overhead, against ...</td>\n",
       "      <td>[inferiorparietal]</td>\n",
       "      <td>[OPA, ATFP]</td>\n",
       "      <td>[them fly overhead, stand in front, across the...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>('location_or_movement', 'UTS02', 122)</td>\n",
       "      <td>locations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subsample_frac        checkpoint checkpoint_module  noise_ngram_scores  \\\n",
       "401             1.0  text-davinci-003           gpt2-xl                   0   \n",
       "431             1.0  text-davinci-003           gpt2-xl                   0   \n",
       "742             1.0  text-davinci-003           gpt2-xl                   0   \n",
       "574             1.0  text-davinci-003           gpt2-xl                   0   \n",
       "439             1.0  text-davinci-003           gpt2-xl                   0   \n",
       "\n",
       "     module_num_restrict  seed                             save_dir  \\\n",
       "401                   -1     1  /home/chansingh/mntv1/mprompt/mar13   \n",
       "431                   -1     1  /home/chansingh/mntv1/mprompt/mar13   \n",
       "742                   -1     1  /home/chansingh/mntv1/mprompt/mar13   \n",
       "574                   -1     1  /home/chansingh/mntv1/mprompt/mar13   \n",
       "439                   -1     1  /home/chansingh/mntv1/mprompt/mar13   \n",
       "\n",
       "    module_name  module_num subject  ...  \\\n",
       "401        fmri         168   UTS02  ...   \n",
       "431        fmri          79   UTS02  ...   \n",
       "742        fmri         398   UTS02  ...   \n",
       "574        fmri         299   UTS02  ...   \n",
       "439        fmri         122   UTS02  ...   \n",
       "\n",
       "                                  top_ngrams_module_25  \\\n",
       "401  [i provoked gasps, real this time, fathers fee...   \n",
       "431  [sliced cucumber, some sliced cucumber, butter...   \n",
       "742  [and mimed crying, she started laughing, face ...   \n",
       "574  [housewarming gift, writing his obituary, i go...   \n",
       "439  [onto the railing, them fly overhead, against ...   \n",
       "\n",
       "                                  top_ngrams_module_50  \\\n",
       "401  [i provoked gasps, real this time, fathers fee...   \n",
       "431  [sliced cucumber, some sliced cucumber, butter...   \n",
       "742  [and mimed crying, she started laughing, face ...   \n",
       "574  [housewarming gift, writing his obituary, i go...   \n",
       "439  [onto the railing, them fly overhead, against ...   \n",
       "\n",
       "                                  top_ngrams_module_75  \\\n",
       "401  [i provoked gasps, real this time, fathers fee...   \n",
       "431  [sliced cucumber, some sliced cucumber, butter...   \n",
       "742  [and mimed crying, she started laughing, face ...   \n",
       "574  [housewarming gift, writing his obituary, i go...   \n",
       "439  [onto the railing, them fly overhead, against ...   \n",
       "\n",
       "                                 top_ngrams_module_100  \\\n",
       "401  [i provoked gasps, real this time, fathers fee...   \n",
       "431  [sliced cucumber, some sliced cucumber, butter...   \n",
       "742  [and mimed crying, she started laughing, face ...   \n",
       "574  [housewarming gift, writing his obituary, i go...   \n",
       "439  [onto the railing, them fly overhead, against ...   \n",
       "\n",
       "                               roi_anat     roi_func  \\\n",
       "401                    [middletemporal]   [ATFP, AC]   \n",
       "431        [fusiform, inferiortemporal]       [ATFP]   \n",
       "742  [inferiorparietal, middletemporal]       [PMvh]   \n",
       "574                  [inferiorparietal]       [ATFP]   \n",
       "439                  [inferiorparietal]  [OPA, ATFP]   \n",
       "\n",
       "                             top_ngrams_module_correct  \\\n",
       "401  [i provoked gasps, asked i laughed, felt so be...   \n",
       "431  [sliced cucumber, some sliced cucumber, butter...   \n",
       "742  [and mimed crying, she started laughing, block...   \n",
       "574  [writing his obituary, explain the joke, read ...   \n",
       "439  [them fly overhead, stand in front, across the...   \n",
       "\n",
       "    frac_top_ngrams_module_correct                                      id  \\\n",
       "401                       0.360000  ('surprise,_shock,_dis', 'UTS02', 168)   \n",
       "431                       0.440000       ('food_preparation', 'UTS02', 79)   \n",
       "742                       0.613333  ('emotional_expression', 'UTS02', 398)   \n",
       "574                       0.626667         ('communication', 'UTS02', 299)   \n",
       "439                       0.333333  ('location_or_movement', 'UTS02', 122)   \n",
       "\n",
       "                     expl  \n",
       "401              surprise  \n",
       "431      food preparation  \n",
       "742  emotional expression  \n",
       "574         communication  \n",
       "439             locations  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning paragraph of an interesting story told in first person. The story should have a plot and characters. The story should be about \"surprise\". Make sure it contains several words related to \"surprise\", such as \"i provoked gasps\", \"asked i laughed\", \"felt so betrayed\", \"suddenly seemed unlikely\".\n",
      "Write the next paragraph of the story, but now make it about \"food preparation\". Make sure it contains several words related to \"food preparation\", such as \"sliced cucumber\", \"some sliced cucumber\", \"buttered slices\", \"thinly sliced\".\n",
      "Write the next paragraph of the story, but now make it about \"emotional expression\". Make sure it contains several words related to \"emotional expression\", such as \"and mimed crying\", \"she started laughing\", \"blocks while screaming\", \"looked around scared\".\n",
      "Write the next paragraph of the story, but now make it about \"communication\". Make sure it contains several words related to \"communication\", such as \"writing his obituary\", \"explain the joke\", \"read my letter\", \"who showed me\".\n",
      "Write the next paragraph of the story, but now make it about \"locations\". Make sure it contains several words related to \"locations\", such as \"them fly overhead\", \"stand in front\", \"across the couch\", \"onto the sidewalk\".\n",
      "Write the next paragraph of the story, but now make it about \"measurements\". Make sure it contains several words related to \"measurements\", such as \"fifty feet underwater\", \"twenty feet above\", \"hundred feet up\", \"seventy five foot\".\n",
      "Write the next paragraph of the story, but now make it about \"moments\". Make sure it contains several words related to \"moments\", such as \"the doorbell rang\", \"leaves the room\", \"enters the room\", \"moment later\".\n",
      "Write the next paragraph of the story, but now make it about \"locations\". Make sure it contains several words related to \"locations\", such as \"towards the river\", \"facing the beach\", \"against the railing\", \"towards the doors\".\n"
     ]
    }
   ],
   "source": [
    "def get_rows_voxels(seed, n_voxels_per_category=4):\n",
    "    '''Select rows from fitted voxels\n",
    "    '''\n",
    "    r = (pd.read_pickle('../results/results_fmri.pkl')\n",
    "        .sort_values(by=['top_score_synthetic'], ascending=False))\n",
    "    r['id'] = \"('\" + r['top_explanation_init_strs'].str.replace(' ', '_').str.slice(stop=20) + \"', '\" + r['subject'] + \"', \" + r['module_num'].astype(str) + \")\"\n",
    "\n",
    "    def _voxels_to_rows(voxels: List[Tuple]) -> pd.DataFrame:\n",
    "        # put all voxel data into rows DataFrame\n",
    "        rows = []\n",
    "        expls = []\n",
    "        for vox in voxels:\n",
    "            expl, subj, vox_num = vox\n",
    "            vox_num = int(vox_num)\n",
    "            try:\n",
    "                rows.append(r[(r.subject == subj) & (r.module_num == vox_num)].iloc[0])\n",
    "                expls.append(expl)\n",
    "            except:\n",
    "                print('skipping', vox)\n",
    "        rows = pd.DataFrame(rows)\n",
    "        rows['expl'] = expls\n",
    "        # with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', 200):\n",
    "            # display(rows[['subject', 'module_num', 'expl', 'top_explanation_init_strs', 'top_ngrams_module_correct']])\n",
    "        return rows\n",
    "\n",
    "    # manually pick some voxels\n",
    "    # with pd.option_context('display.max_rows', None, 'display.max_colwidth', 200):\n",
    "    #     display(r.sort_values(by=['top_score_synthetic'], ascending=False)[\n",
    "    #         ['top_explanation_init_strs', 'subject', 'module_num', 'top_score_synthetic', 'frac_top_ngrams_module_correct', 'id', 'top_ngrams_module_correct']\n",
    "    #     ].round(3).reset_index(drop=True).head(50))\n",
    "\n",
    "\n",
    "    # expls = ['baseball','animals','water','movement','religion','time','technology']\n",
    "    # interesting_expls = ['food', 'numbers', 'physical contact', 'time', 'laughter', 'age', 'clothing']\n",
    "    # voxels = [('movement', 'UTS01',\t7), ('numbers', 'UTS03', 55), ('time', 'UTS03', 19), ('relationships', 'UTS01', 21),\n",
    "            #   ('sounds', 'UTS03', 35), ('emotion', 'UTS03', 23), ('food', 'UTS03', 46)]\n",
    "    # voxels = [('numbers', 'UTS03', 55), ('time', 'UTS03', 19),\n",
    "            #   ('sounds', 'UTS03', 35), ('emotion', 'UTS03', 23), ('food', 'UTS03', 46)]\n",
    "    # voxels = [('movement', 'UTS01',\t7),('relationships', 'UTS01', 21) ('passing of time\tUTS02\t4)]\n",
    "    # voxels = [('relationships', 'UTS02', 9), ('time', 'UTS02', 4), ('looking or staring', 'UTS03', 57), ('food and drinks', 'UTS01', 52), ('hands and arms', 'UTS01', 46)]\n",
    "    # rows = _voxels_to_rows(voxels)\n",
    "    # return rows\n",
    "\n",
    "    # mar 21 - voxels spread across categories\n",
    "    # voxels = [\n",
    "    #     # belong to previous categories\n",
    "    #     ('hands and arms', 'UTS01', 46),\n",
    "    #     ('measurements and numbers', 'UTS02', 48),\n",
    "    #     ('locations', 'UTS03', 87),\n",
    "    #     ('time', 'UTS02', 4),\n",
    "    #     ('physical injury or discomfort', 'UTS01', 35),\n",
    "    #     ('feelings and emotions', 'UTS02', 104),\n",
    "    #     ('relationships', 'UTS02', 9),\n",
    "\n",
    "    #     # new voxels\n",
    "    #     ('food and drinks', 'UTS01', 52),\n",
    "    #     ('sound', 'UTS02', 81),\n",
    "    #     ('hands and arms', 'UTS01', 46),\n",
    "    # ]\n",
    "    # rows = _voxels_to_rows(voxels)\n",
    "    # return rows\n",
    "\n",
    "    # mar 22 - UTS02 voxels in different categories\n",
    "    voxels_dict = json.load(open(f'voxel_select/uts02_concepts_pilot_mar22.json', 'r'))\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    # randomly shuffle the categories order + voxels within each category\n",
    "    # return n_voxels_per_category per category\n",
    "    # rng = np.random.default_rng(seed)\n",
    "    # voxels_dict_keys = list(voxels_dict.keys())\n",
    "    # rng.shuffle(voxels_dict_keys)\n",
    "    # print(voxels_dict_keys)\n",
    "    # idxs_list = [rng.choice(len(voxels_dict[k]), n_voxels_per_category, replace=False) for k in voxels_dict_keys]\n",
    "    # for i, k in enumerate(voxels_dict_keys):\n",
    "    #     idxs = idxs_list[i]\n",
    "    #     d['voxels'].extend([tuple(vox) for vox in np.array(voxels_dict[k])[idxs]])\n",
    "    #     d['category'].extend([k] * n_voxels_per_category)\n",
    "    # d = pd.DataFrame(d)\n",
    "    # # print(d.)\n",
    "    # voxels = d.voxels.values.tolist()\n",
    "    # rows = _voxels_to_rows(voxels)\n",
    "    # return rows, idxs_list, voxels\n",
    "\n",
    "    # mar 24 - UTS02 voxels after screening\n",
    "    vals = pd.DataFrame([tuple(x) for x in sum(list(voxels_dict.values()), [])])\n",
    "    vals.columns = ['expl', 'subject', 'module_num']\n",
    "    voxel_nums = [\n",
    "        337, 122, 168, 171, 79, 299, 368, 398\n",
    "    ]\n",
    "    vals = vals[vals['module_num'].isin(voxel_nums)]\n",
    "    display(vals)\n",
    "    voxels = vals.sample(frac=1, random_state=seed).values\n",
    "\n",
    "    rows = _voxels_to_rows(voxels)\n",
    "    return rows\n",
    "    \n",
    "\n",
    "def get_rows_huth():\n",
    "    '''Select rows corresponding to 2016 categories\n",
    "    '''\n",
    "    huth2016_categories = json.load(open('huth2016clusters.json', 'r'))\n",
    "    r = pd.DataFrame.from_dict({'expl': huth2016_categories.keys(), 'top_ngrams_module_correct': huth2016_categories.values()})\n",
    "    return r\n",
    "\n",
    "# version = 'v4'\n",
    "# EXPT_NAME = 'huth2016clusters_mar21_i_time_traveled'\n",
    "# rows = get_rows_huth()\n",
    "\n",
    "# EXPT_NAME = 'relationships_mar9'\n",
    "# EXPT_NAME, version = ('voxels_mar21_hands_arms_emergency', 'v4_noun')\n",
    "# rows = get_rows_voxels(seed=1)\n",
    "\n",
    "# seed = 10\n",
    "# EXPT_NAME, version = (f'uts02_concepts_pilot_mar22_seed={seed}', 'v4_noun')\n",
    "# rows, idxs_list, voxels = get_rows_voxels(seed=seed, n_voxels_per_category=4)\n",
    "\n",
    "seed = 3\n",
    "EXPT_NAME, version = (f'uts02_concepts_pilot_selected_mar24_seed={seed}', 'v4_noun')\n",
    "rows = get_rows_voxels(seed=seed, n_voxels_per_category=4)\n",
    "display(rows.head())\n",
    "\n",
    "expls = rows.expl.values\n",
    "examples_list = rows.top_ngrams_module_correct\n",
    "prompts = notebook_helper.get_prompts(expls, examples_list, version, n_examples=4)\n",
    "for p in prompts:\n",
    "    print(p)\n",
    "PV = notebook_helper.get_prompt_templates(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n",
      "cached!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 40970.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I never expected to be the one to provoke gasps from a room full of people. But that's exactly what happened when I walked into my surprise party. \"Surprise!\" they all yelled, and I couldn't help but laugh. I had no idea they were planning this. My best friend, Sarah, had been acting so strange lately, but I never suspected a thing. As I looked around the room, I felt so betrayed that they could keep such a big secret from me. But at the same time, I was thrilled to be surrounded by all my loved ones. It suddenly seemed unlikely that anything could ruin this perfect moment.\n",
      "As I made my way through the crowd, hugging and thanking everyone for coming, I couldn't help but notice the spread of food on the table. Some sliced cucumber and carrot sticks were arranged neatly next to a bowl of hummus. A platter of cheese and crackers sat next to a basket of buttered slices of bread. I could tell that Sarah had put a lot of thought into the food preparation. Everything was so beautifully presented, with each dish garnished with herbs and thinly sliced vegetables. I couldn't wait to try everything.\n",
      "As I reached for a plate to start filling up with food, I noticed Sarah standing in the corner, looking around scared. I walked over to her and asked if everything was okay. She started laughing and mimed crying at the same time. \"I'm just so happy for you,\" she said, wiping away imaginary tears. \"I wanted everything to be perfect.\" I could see the emotional expression on her face, and it made me feel grateful to have such a thoughtful friend. Suddenly, we both heard a loud crash from the other side of the room. We turned around to see one of the kids knocking over blocks while screaming with joy. The chaos only added to the excitement of the surprise party.\n",
      "As the party continued, I found myself in a deep conversation with my uncle, who showed me a letter he had written to his younger self. He explained that he had been going through a tough time and writing his obituary had helped him put things into perspective. We talked about the importance of communication and how it can help us process our emotions. Just then, my cousin came over and told us a joke that no one seemed to understand. I tried to explain the joke, but it fell flat. Instead, I decided to read my letter out loud, which was something I had been hesitant to do earlier. As I read my letter, I could feel the room quiet down and everyone listening intently. It was a moment of genuine communication that brought us all closer together.\n",
      "As the night wore on, people started to move around the room, mingling and chatting with each other. I noticed my little cousin had fallen asleep on the couch, so I gently picked her up and carried her to a quieter location. As I walked across the room, I saw a group of people standing in front of the window, pointing at something outside. I joined them and looked up to see a flock of birds flying overhead. We all stood there in awe, watching them fly overhead until they disappeared from sight. Later on, as the party started to wind down, I walked outside onto the sidewalk with a few friends. We sat on the curb and talked about our favorite locations in the city. It was a peaceful moment, and I felt grateful for all the different locations that had brought us together over the years.\n",
      "As the night drew to a close, I found myself in a conversation with a group of scuba divers who had just returned from a trip to the Caribbean. They were talking about the different measurements they had taken while diving, like how deep they had gone or how far they had swum. One of them mentioned that they had gone fifty feet underwater to see a shipwreck, while another said they had seen a school of fish twenty feet above them. It was fascinating to hear about their experiences and the different measurements they used to describe them. As we said our goodbyes, one of them mentioned that they were planning a trip to climb a seventy-five-foot rock face in the coming weeks. The idea of measuring their progress as they climbed was both exciting and daunting.\n",
      "Just as I was about to leave, the doorbell rang. I opened the door to find my friend who had left the party earlier. She had come back to say goodbye and give me a hug. It was a small moment, but it meant a lot to me. As she left, I turned around to see that most of the guests had already gone. I felt a twinge of sadness, knowing that the night was over and everyone would soon be gone. But then, my sister entered the room with a big smile on her face. She had been busy in the kitchen all night and had missed most of the party. We sat down together and talked about all the moments we had missed while she was cooking. It was a nice way to end the night, sharing those little moments with someone who understood their significance. A moment later, we both got up and started cleaning up the party decorations, feeling content and grateful for all the moments we had shared that night.\n",
      "As we finished cleaning up, my sister suggested we take a walk towards the river. We walked down the street, facing the beach, and soon found ourselves against the railing, looking out at the water. It was a peaceful location, with the sound of the waves lapping against the shore and the cool breeze blowing through our hair. We talked about our favorite locations in the city and how they had changed over time. I mentioned how much I loved walking towards the doors of my favorite coffee shop, while my sister talked about how much she enjoyed going to the park with her friends. As we walked back towards my apartment, I felt grateful for all the different locations that had brought us together over the years.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "paragraphs = mprompt.llm.get_paragraphs(prompts, prefix_first=PV['prefix_first'], prefix_next=PV['prefix_next'])\n",
    "rows['prompt'] = prompts\n",
    "rows['paragraph'] = paragraphs\n",
    "for i in tqdm(range(len(paragraphs))):\n",
    "    para = paragraphs[i]\n",
    "    print(para)\n",
    "    # pprint(para)\n",
    "\n",
    "# save\n",
    "STORIES_DIR = join(RESULTS_DIR, 'stories')\n",
    "EXPT_DIR = join(STORIES_DIR, EXPT_NAME)\n",
    "os.makedirs(EXPT_DIR, exist_ok=True)\n",
    "joblib.dump(rows, join(STORIES_DIR, EXPT_NAME, 'rows.pkl'))\n",
    "with open(join(EXPT_DIR, 'story.txt'), 'w') as f:\n",
    "    f.write('\\n\\n'.join(rows.paragraph.values))\n",
    "with open(join(EXPT_DIR, 'prompts.txt'), 'w') as f:\n",
    "    f.write('\\n\\n'.join(rows.prompt.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
