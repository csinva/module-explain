{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import notebook_helper\n",
    "import mprompt.viz\n",
    "import openai\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from mprompt.config import RESULTS_DIR\n",
    "import mprompt.llm\n",
    "import json\n",
    "openai.api_key_path = os.path.expanduser('~/.OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_voxels(seed=1, n_voxels_per_category=4):\n",
    "    '''Select rows from fitted voxels\n",
    "    '''\n",
    "    r = (pd.read_pickle('../results/results_fmri.pkl')\n",
    "        .sort_values(by=['top_score_synthetic'], ascending=False))\n",
    "    r['id'] = \"('\" + r['top_explanation_init_strs'].str.replace(' ', '_').str.slice(stop=20) + \"', '\" + r['subject'] + \"', \" + r['module_num'].astype(str) + \")\"\n",
    "\n",
    "    # manually pick some voxels\n",
    "    # with pd.option_context('display.max_rows', None, 'display.max_colwidth', 200):\n",
    "    #     display(r.sort_values(by=['top_score_synthetic'], ascending=False)[\n",
    "    #         ['top_explanation_init_strs', 'subject', 'module_num', 'top_score_synthetic', 'frac_top_ngrams_module_correct', 'id', 'top_ngrams_module_correct']\n",
    "    #     ].round(3).reset_index(drop=True).head(50))\n",
    "\n",
    "\n",
    "    # expls = ['baseball','animals','water','movement','religion','time','technology']\n",
    "    # interesting_expls = ['food', 'numbers', 'physical contact', 'time', 'laughter', 'age', 'clothing']\n",
    "    # voxels = [('movement', 'UTS01',\t7), ('numbers', 'UTS03', 55), ('time', 'UTS03', 19), ('relationships', 'UTS01', 21),\n",
    "            #   ('sounds', 'UTS03', 35), ('emotion', 'UTS03', 23), ('food', 'UTS03', 46)]\n",
    "    # voxels = [('numbers', 'UTS03', 55), ('time', 'UTS03', 19),\n",
    "            #   ('sounds', 'UTS03', 35), ('emotion', 'UTS03', 23), ('food', 'UTS03', 46)]\n",
    "    # voxels = [('movement', 'UTS01',\t7),('relationships', 'UTS01', 21) ('passing of time\tUTS02\t4)]\n",
    "    # voxels = [('relationships', 'UTS02', 9), ('time', 'UTS02', 4), ('looking or staring', 'UTS03', 57), ('food and drinks', 'UTS01', 52), ('hands and arms', 'UTS01', 46)]\n",
    "\n",
    "    # mar 21 - voxels spread across categories\n",
    "    # voxels = [\n",
    "    #     # belong to previous categories\n",
    "    #     ('hands and arms', 'UTS01', 46),\n",
    "    #     ('measurements and numbers', 'UTS02', 48),\n",
    "    #     ('locations', 'UTS03', 87),\n",
    "    #     ('time', 'UTS02', 4),\n",
    "    #     ('physical injury or discomfort', 'UTS01', 35),\n",
    "    #     ('feelings and emotions', 'UTS02', 104),\n",
    "    #     ('relationships', 'UTS02', 9),\n",
    "\n",
    "    #     # new voxels\n",
    "    #     ('food and drinks', 'UTS01', 52),\n",
    "    #     ('sound', 'UTS02', 81),\n",
    "    #     ('hands and arms', 'UTS01', 46),\n",
    "    # ]\n",
    "\n",
    "    # mar 22 - UTS02 voxels\n",
    "    voxels_dict = json.load(open(f'voxel_select/uts02_concepts_pilot_mar22.json', 'r'))\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    # randomly shuffle the categories order + voxels within each category\n",
    "    # return n_voxels_per_category per category\n",
    "    rng = np.random.default_rng(seed)\n",
    "    voxels_dict_keys = list(voxels_dict.keys())\n",
    "    rng.shuffle(voxels_dict_keys)\n",
    "    print(voxels_dict_keys)\n",
    "    idxs_list = [rng.choice(len(voxels_dict[k]), n_voxels_per_category, replace=False) for k in voxels_dict_keys]\n",
    "    for i, k in enumerate(voxels_dict_keys):\n",
    "        idxs = idxs_list[i]\n",
    "        d['voxels'].extend([tuple(vox) for vox in np.array(voxels_dict[k])[idxs]])\n",
    "        d['category'].extend([k] * n_voxels_per_category)\n",
    "    d = pd.DataFrame(d)\n",
    "    # print(d.)\n",
    "    voxels = d.voxels.values.tolist()\n",
    "\n",
    "    # put all voxel data into rows DataFrame\n",
    "    rows = []\n",
    "    expls = []\n",
    "    for vox in voxels:\n",
    "        expl, subj, vox_num = vox\n",
    "        vox_num = int(vox_num)\n",
    "        try:\n",
    "            rows.append(r[(r.subject == subj) & (r.module_num == vox_num)].iloc[0])\n",
    "            expls.append(expl)\n",
    "        except:\n",
    "            print('skipping', vox)\n",
    "    rows = pd.DataFrame(rows)\n",
    "    rows['expl'] = expls\n",
    "    # with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', 200):\n",
    "        # display(rows[['subject', 'module_num', 'expl', 'top_explanation_init_strs', 'top_ngrams_module_correct']])\n",
    "\n",
    "    return rows, idxs_list, voxels\n",
    "\n",
    "def get_rows_huth():\n",
    "    '''Select rows corresponding to 2016 categories\n",
    "    '''\n",
    "    huth2016_categories = json.load(open('huth2016clusters.json', 'r'))\n",
    "    r = pd.DataFrame.from_dict({'expl': huth2016_categories.keys(), 'top_ngrams_module_correct': huth2016_categories.values()})\n",
    "    return r\n",
    "\n",
    "# version = 'v4'\n",
    "# EXPT_NAME = 'huth2016clusters_mar21_i_time_traveled'\n",
    "# rows = get_rows_huth()\n",
    "\n",
    "# EXPT_NAME = 'relationships_mar9'\n",
    "# EXPT_NAME, version = ('voxels_mar21_hands_arms_emergency', 'v4_noun')\n",
    "# rows = get_rows_voxels(seed=1)\n",
    "\n",
    "seed = 1\n",
    "EXPT_NAME, version = (f'uts02_concepts_pilot_mar22_seed={seed}', 'v4_noun')\n",
    "rows, idxs_list, voxels = get_rows_voxels(seed=1, n_voxels_per_category=4)\n",
    "display(rows.head())\n",
    "\n",
    "expls = rows.expl.values\n",
    "examples_list = rows.top_ngrams_module_correct\n",
    "prompts = notebook_helper.get_prompts(expls, examples_list, version, n_examples=4)\n",
    "for p in prompts:\n",
    "    print(p)\n",
    "PV = notebook_helper.get_prompt_templates(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = mprompt.llm.get_paragraphs(prompts, prefix_first=PV['prefix_first'], prefix_next=PV['prefix_next'])\n",
    "rows['prompt'] = prompts\n",
    "rows['paragraph'] = paragraphs\n",
    "for para in tqdm(paragraphs):\n",
    "    print(para)\n",
    "    # pprint(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/chansingh/mprompt/results/stories/uts02_concepts_pilot_mar22_seed=1/rows.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STORIES_DIR = join(RESULTS_DIR, 'stories')\n",
    "os.makedirs(join(STORIES_DIR, EXPT_NAME), exist_ok=True)\n",
    "joblib.dump(rows, join(STORIES_DIR, EXPT_NAME, 'rows.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
